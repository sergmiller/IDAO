{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import utils\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "reload(utils)\n",
    "\n",
    "from utils import dataset, applier, domain, pipe, file\n",
    "\n",
    "reload(file)\n",
    "reload(dataset)\n",
    "reload(applier)\n",
    "reload(domain)\n",
    "reload(pipe)\n",
    "\n",
    "from utils.dataset import LabeledDataset\n",
    "from utils.file import read_all_png_in_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/sergmiller/Documents/my/IDAO-2021/data/idao_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_path, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = dataset.build_dataset(\n",
    "    [\n",
    "        os.path.join(train_path,'NR'),\n",
    "        os.path.join(train_path,'ER')], limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 576, 576)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_g = read_all_png_in_dirs(\n",
    "    [\n",
    "        os.path.join(data_path, 'public_test'),\n",
    "        os.path.join(data_path, 'private_test')\n",
    "    ], limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list([x for x in test_data_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0c2b855c9bbdd1513b826ebdbd157ee8afa3faa9.png',\n",
       "  array([[ 99, 105, 102, ..., 103, 102, 106],\n",
       "         [ 99, 104, 102, ..., 103, 108,  97],\n",
       "         [ 93, 101,  97, ..., 106,  98, 101],\n",
       "         ...,\n",
       "         [101,  97, 102, ..., 101, 102, 106],\n",
       "         [ 98,  99, 100, ..., 100, 100, 102],\n",
       "         [100,  99, 100, ...,  98,  98, 106]], dtype=uint8)),\n",
       " ('8f862af208004bc8f20501a122305ae9fff7d984.png',\n",
       "  array([[ 98,  98, 100, ..., 100, 102, 104],\n",
       "         [101, 105,  98, ...,  98,  98, 105],\n",
       "         [104, 100, 101, ...,  96, 101, 103],\n",
       "         ...,\n",
       "         [102, 100, 101, ..., 101, 104,  98],\n",
       "         [ 98, 103, 107, ...,  94, 105,  99],\n",
       "         [100, 108,  98, ..., 100, 103, 102]], dtype=uint8)),\n",
       " ('60f8f137f6c65b98e5f0908844c6d60522597cca.png',\n",
       "  array([[102,  98,  97, ...,  99, 101, 103],\n",
       "         [ 98, 105, 103, ...,  99, 104,  99],\n",
       "         [103,  99, 104, ...,  88, 102,  99],\n",
       "         ...,\n",
       "         [100,  97,  98, ..., 103,  98, 100],\n",
       "         [ 99,  98, 103, ...,  96, 101,  98],\n",
       "         [100,  98, 102, ..., 103, 101, 101]], dtype=uint8)),\n",
       " ('7c60c5e2b3be0ed88074bdfa611d66351183facd.png',\n",
       "  array([[104,  86, 102, ...,  98, 104,  98],\n",
       "         [101, 104, 100, ..., 111, 100, 100],\n",
       "         [ 99, 100, 100, ..., 102, 102,  99],\n",
       "         ...,\n",
       "         [102,  97,  99, ..., 101,  99,  97],\n",
       "         [100, 115,  98, ...,  97, 100, 100],\n",
       "         [101, 101,  98, ..., 100,  99,  96]], dtype=uint8)),\n",
       " ('ac46be871300a72f0cdeca4c886bad9d0e1f5770.png',\n",
       "  array([[101,  98,  98, ...,  98,  97, 105],\n",
       "         [ 98,  97,  95, ...,  98,  97, 104],\n",
       "         [ 96, 102, 103, ...,  95, 105, 102],\n",
       "         ...,\n",
       "         [101, 101, 100, ..., 104, 102, 101],\n",
       "         [ 99, 100,  98, ..., 111,  99, 101],\n",
       "         [102, 102, 101, ..., 105,  99, 102]], dtype=uint8)),\n",
       " ('ef672059428868eac111c7f4da92ab814540f0d2.png',\n",
       "  array([[102,  94, 104, ..., 104, 102,  96],\n",
       "         [102,  99, 102, ..., 101, 100, 103],\n",
       "         [103, 100, 100, ..., 110, 100, 101],\n",
       "         ...,\n",
       "         [ 97,  95, 100, ..., 102, 101,  99],\n",
       "         [102,  96,  99, ..., 104,  97, 100],\n",
       "         [102, 101,  97, ..., 105, 101, 103]], dtype=uint8)),\n",
       " ('7b2af06eddb9463c2cd93a4aa18527244a5bd726.png',\n",
       "  array([[100,  97,  98, ...,  98,  98, 102],\n",
       "         [103, 100, 100, ..., 102, 102, 104],\n",
       "         [103, 100, 102, ...,  96,  99, 104],\n",
       "         ...,\n",
       "         [ 97, 100,  98, ..., 105,  98, 102],\n",
       "         [100,  98, 103, ..., 105, 101, 100],\n",
       "         [100,  98, 100, ..., 107, 101, 100]], dtype=uint8)),\n",
       " ('d719502556e74d0f1d080557effc10658497f70b.png',\n",
       "  array([[100,  96, 101, ..., 102,  96,  98],\n",
       "         [102, 104, 102, ...,  99,  98,  99],\n",
       "         [103, 102, 101, ..., 105, 103, 104],\n",
       "         ...,\n",
       "         [ 98, 102, 103, ...,  99,  98,  97],\n",
       "         [102,  98, 103, ..., 103,  98,  99],\n",
       "         [ 99, 103,  99, ...,  99,  99, 102]], dtype=uint8)),\n",
       " ('a84ba7e18439755ee0d754101213c912b9291570.png',\n",
       "  array([[102, 109, 101, ...,  97, 101, 101],\n",
       "         [ 98, 103,  99, ..., 101, 103, 100],\n",
       "         [101, 100, 105, ..., 106,  99, 102],\n",
       "         ...,\n",
       "         [103, 100, 104, ...,  97,  99, 104],\n",
       "         [103,  98, 108, ..., 104, 104, 101],\n",
       "         [ 97, 106,  98, ..., 101, 102,  98]], dtype=uint8)),\n",
       " ('fffdd654bd60b81ffd51a723a8839b8f5381feba.png',\n",
       "  array([[ 99,  91, 103, ..., 114, 101,  96],\n",
       "         [ 95, 101,  95, ..., 100, 101, 100],\n",
       "         [ 97, 103, 102, ..., 110, 102,  98],\n",
       "         ...,\n",
       "         [101,  94, 102, ...,  99,  98,  99],\n",
       "         [ 98, 102, 100, ...,  98,  99,  99],\n",
       "         [101, 108,  98, ...,  97, 101, 105]], dtype=uint8)),\n",
       " ('b36fe90fa6463e49fee3c30a8ba1f045d3ed3dda.png',\n",
       "  array([[103, 105, 100, ..., 108,  97,  98],\n",
       "         [ 93,  98, 100, ..., 100, 101,  99],\n",
       "         [103, 103, 102, ...,  94, 102, 102],\n",
       "         ...,\n",
       "         [102, 104, 101, ..., 101, 102, 103],\n",
       "         [ 98, 109, 102, ..., 105, 102,  99],\n",
       "         [103,  98, 101, ...,  98, 102,  97]], dtype=uint8)),\n",
       " ('ab1b969d82858a495f196637ee9fb28a293a27f7.png',\n",
       "  array([[102, 103, 102, ...,  99,  99, 103],\n",
       "         [101,  98,  96, ...,  98,  99, 100],\n",
       "         [101, 102,  97, ..., 100, 101, 100],\n",
       "         ...,\n",
       "         [ 99, 101,  98, ...,  97, 101, 102],\n",
       "         [105, 104, 104, ...,  98,  98, 102],\n",
       "         [100,  97,  99, ..., 100,  96,  99]], dtype=uint8)),\n",
       " ('f139dcbb01fe085230e20136f4c115facf0681c3.png',\n",
       "  array([[ 95,  99, 103, ...,  98, 100,  97],\n",
       "         [ 96,  97, 104, ...,  96, 103,  98],\n",
       "         [103, 100, 103, ...,  90, 101,  98],\n",
       "         ...,\n",
       "         [ 95,  92, 105, ..., 101,  97,  98],\n",
       "         [ 98,  95,  98, ...,  95, 103, 100],\n",
       "         [102,  99, 100, ..., 101,  99,  99]], dtype=uint8)),\n",
       " ('2426658662138a6f761c7e4990e988dea6debde5.png',\n",
       "  array([[ 99,  98, 102, ..., 100, 101,  96],\n",
       "         [ 98, 104,  98, ...,  99, 103, 100],\n",
       "         [100, 101,  96, ..., 108,  98, 100],\n",
       "         ...,\n",
       "         [102, 105, 100, ..., 101, 100, 100],\n",
       "         [ 99, 103,  97, ..., 103, 101,  98],\n",
       "         [106, 101, 100, ...,  99, 100,  99]], dtype=uint8)),\n",
       " ('7a4022dee08523d932db64e3d1e1e8e570567e3d.png',\n",
       "  array([[103, 103,  99, ..., 102, 101,  98],\n",
       "         [103,  99, 105, ..., 103, 101,  98],\n",
       "         [103, 103,  99, ...,  99,  98,  99],\n",
       "         ...,\n",
       "         [102,  96, 104, ...,  97,  99, 102],\n",
       "         [103, 102, 100, ..., 101,  98, 102],\n",
       "         [ 98, 100, 100, ...,  98, 103, 102]], dtype=uint8)),\n",
       " ('fbb4d4a9c335c8656a8f81ef1d548ef3ea069d0a.png',\n",
       "  array([[ 99, 110,  99, ..., 107, 100,  97],\n",
       "         [102, 101,  96, ..., 100, 105,  98],\n",
       "         [102,  98, 100, ...,  93, 101,  99],\n",
       "         ...,\n",
       "         [ 98,  99, 100, ..., 100, 100, 101],\n",
       "         [104, 106,  99, ..., 103, 102,  97],\n",
       "         [105,  98, 101, ..., 102,  98, 100]], dtype=uint8)),\n",
       " ('39a52d9a421d129abed84de37ebf26ffff0707dd.png',\n",
       "  array([[100, 112, 102, ...,  97, 102, 102],\n",
       "         [106,  96, 106, ...,  97, 102, 101],\n",
       "         [103,  98, 101, ..., 100, 101,  99],\n",
       "         ...,\n",
       "         [102, 101, 101, ..., 100,  95,  98],\n",
       "         [ 98, 100, 104, ..., 100, 102,  98],\n",
       "         [ 97, 100, 102, ..., 100, 103,  99]], dtype=uint8)),\n",
       " ('d12a6c9569aab71271577cbad2ae9ec5c0b062c0.png',\n",
       "  array([[102, 113, 100, ...,  97, 103, 102],\n",
       "         [ 99, 101, 101, ..., 101, 102, 100],\n",
       "         [100, 104,  99, ...,  85, 101, 100],\n",
       "         ...,\n",
       "         [101, 103,  99, ..., 106, 101,  95],\n",
       "         [101, 107,  98, ..., 101,  99,  97],\n",
       "         [103,  99, 100, ..., 100,  96,  98]], dtype=uint8)),\n",
       " ('4ff0d762c4bf1208e0e7e2d962d2e95232ee8240.png',\n",
       "  array([[100, 106, 100, ..., 101,  98, 105],\n",
       "         [ 97, 100, 101, ..., 102,  96, 103],\n",
       "         [104, 102, 100, ..., 106,  95,  99],\n",
       "         ...,\n",
       "         [ 96, 100, 105, ...,  96, 102, 103],\n",
       "         [101,  99, 101, ...,  98,  94,  99],\n",
       "         [102, 103,  99, ..., 102, 101,  98]], dtype=uint8)),\n",
       " ('52a2e8a277028a7189d64ed24d3791bfcd2e3667.png',\n",
       "  array([[100,  94, 102, ..., 100,  99, 100],\n",
       "         [102, 100, 103, ...,  99, 100, 100],\n",
       "         [101, 100, 102, ..., 102,  99, 101],\n",
       "         ...,\n",
       "         [101, 100,  98, ..., 101,  96, 103],\n",
       "         [ 99,  96, 101, ..., 100, 100, 100],\n",
       "         [101, 100,  99, ..., 101,  98, 103]], dtype=uint8))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 119.57it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_2 = file.read_all_png_in_dir(os.path.join(data_path, 'public_test'), limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = np.array(255 * test_data_2[list(test_data_2.keys())[0]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0c2b855c9bbdd1513b826ebdbd157ee8afa3faa9.png',\n",
       " array([[ 99, 105, 102, ..., 103, 102, 106],\n",
       "        [ 99, 104, 102, ..., 103, 108,  97],\n",
       "        [ 93, 101,  97, ..., 106,  98, 101],\n",
       "        ...,\n",
       "        [101,  97, 102, ..., 101, 102, 106],\n",
       "        [ 98,  99, 100, ..., 100, 100, 102],\n",
       "        [100,  99, 100, ...,  98,  98, 106]], dtype=uint8))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]  # 0c2b855c9bbdd1513b826ebdbd157ee8afa3faa9.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(d2 == d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset.save('test.npz')\n",
    "sample_dataset = dataset.LabeledDataset.load('test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 576, 576)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "# resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "# resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "# model = models.mobilenet_v3_small(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "croped_mobilenet = torch.nn.Sequential(\n",
    "#     transforms.Resize(256),\n",
    "    transforms.CenterCrop(64),\n",
    "    applier.mobilenet_v3_small\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): CenterCrop(size=(64, 64))\n",
       "  (1): MobileNetV3(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ConvBNActivation(\n",
       "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): ConvBNActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): ConvBNActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3): ConvBNActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ConvBNActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=True)\n",
       "      (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croped_mobilenet.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.build_dataset([train_path + '/NR', train_path + '/ER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_dataset = applier.build_embd_dataset(train_dataset, croped_mobilenet_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_dataset.save('../data/center_crop_256_mobilenet_v3_small_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_dataset = LabeledDataset.load('../data/center_crop_64_mobilenet_v3_small_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13404, 1000)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_dataset.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2531.2258"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(train_emb_dataset.samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_projection_and_normalize(data : np.array, to_dim : int = 10, seed : int = 0):\n",
    "    assert 2 == len(data.shape)\n",
    "    np.random.seed(seed)\n",
    "    N = data.shape[1]\n",
    "    proj_matrix = np.random.randn(N, to_dim) / np.sqrt(N)\n",
    "#     print(np.mean(proj_matrix), np.std(proj_matrix))\n",
    "    data_proj = np.matmul(data, proj_matrix)\n",
    "    data_proj /= np.sum(np.abs(data_proj), axis=1, keepdims=True)\n",
    "    return data_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "proj_emb_dataset = copy.copy(train_emb_dataset)\n",
    "proj_emb_dataset.samples = apply_random_projection_and_normalize(\n",
    "    train_emb_dataset.samples, to_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(proj_emb_dataset.samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_fold = lambda seed: StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "params = {\n",
    "    \"penalty\": 'l1',\n",
    "    \"solver\": 'saga',\n",
    "    \"verbose\": 10,\n",
    "    \"max_iter\": 100,\n",
    "    \"tol\": 1e-5,\n",
    "    \"scoring\" : 'roc_auc',\n",
    "    \"random_state\": 0,\n",
    "    \"cv\": build_fold(0),\n",
    "    \"n_jobs\": 7,\n",
    "    \"refit\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10869  3245 13299 10980  1103  5091 10134  6859  4516  4422] [ 1057 10013  6979  7505    60  6173  4878    35 11686  7315]\n"
     ]
    }
   ],
   "source": [
    "ids = np.arange(len(proj_emb_dataset.samples))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(ids)\n",
    "N = int(len(ids) * 0.9)\n",
    "train_ids = ids[:N]\n",
    "val_ids = ids[N:]\n",
    "print(train_ids[:10], val_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.2.4-py3-none-any.whl (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning) (1.20.1)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning) (5.3.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning) (4.54.1)\n",
      "Collecting fsspec[http]>=0.8.1\n",
      "  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.25.0)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 3.2 MB/s eta 0:00:01    |███████████                     | 3.6 MB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (53.0.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.5)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.3-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.36.1-cp39-cp39-macosx_10_10_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 9.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (1.26.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp39-cp39-macosx_10_14_x86_64.whl (649 kB)\n",
      "\u001b[K     |████████████████████████████████| 649 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp39-cp39-macosx_10_14_x86_64.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp39-cp39-macosx_10_14_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyasn1-modules, oauthlib, multidict, cachetools, yarl, requests-oauthlib, google-auth, async-timeout, werkzeug, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, fsspec, aiohttp, absl-py, tensorboard, pytorch-lightning\n",
      "Successfully installed absl-py-0.12.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 cachetools-4.2.1 fsspec-0.8.7 google-auth-1.28.0 google-auth-oauthlib-0.4.3 grpcio-1.36.1 markdown-3.3.4 multidict-5.1.0 oauthlib-3.1.0 pyasn1-modules-0.2.8 pytorch-lightning-1.2.4 requests-oauthlib-1.3.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 werkzeug-1.0.1 yarl-1.6.3\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj_emb_dataset = proj_emb_dataset.subset(train_ids)\n",
    "val_proj_emb_dataset = proj_emb_dataset.subset(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Linear(32, 64), nn.Dropout(p=0.1), nn.ReLU())\n",
    "        self.model_learn = nn.Sequential(self.model, nn.Linear(64, 1))\n",
    "        self.model_forget = nn.Sequential(self.model, nn.Linear(64, 6))\n",
    "        self.alpha = 0.1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        x, y, forget = batch\n",
    "        x = x.float()\n",
    "        forget = forget.long()\n",
    "        z = self.model_learn(x).reshape(-1, 1)\n",
    "        logits = self.model_forget(x)\n",
    "        logits = logits.reshape(-1, 6)\n",
    "        forget = forget.reshape(-1)\n",
    "#         print(logits.shape, forget.shape)\n",
    "        loss_forget = CrossEntropyLoss()(input=logits, target=forget)\n",
    "        loss = BCEWithLogitsLoss()(input=z, target=y.float())\n",
    "        loss -= loss_forget * self.alpha\n",
    "        self.log('learn_loss', loss)\n",
    "        self.log('forget_loss ', loss_forget)\n",
    "        total = loss + loss_forget\n",
    "        return total\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         self.model.train(False)\n",
    "#         with torch.no_grad():\n",
    "#             z = self.model(x.float()).reshape(-1, 1)\n",
    "#             y = y.reshape(-1,1).float()\n",
    "#             loss = BCEWithLogitsLoss()(input=z, target=y)\n",
    "#         self.log('val_loss', loss)\n",
    "#         self.model.train(True)\n",
    "#         return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDataset(dataset.LabeledDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classes = [1, 10, 20, 3, 30, 6]\n",
    "        self.class2id = {str(c) : i for i,c in enumerate(self.classes)}\n",
    "\n",
    "    def init(self, d):\n",
    "        self.tags = d.tags\n",
    "        self.samples = d.samples\n",
    "        self.labels = d.labels\n",
    "        return self\n",
    "    def __len__(self):\n",
    "        return len(self.tags)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        s = i\n",
    "        f = (i + 1)\n",
    "        x = self.samples[s:f]\n",
    "        y = (self.labels[s:f, 0] == 'NR').astype(int)\n",
    "        z = np.array([self.class2id[self.labels[s][1]]]).astype(int)\n",
    "        return (x, y ,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | model        | Sequential | 2.1 K \n",
      "1 | model_learn  | Sequential | 2.2 K \n",
      "2 | model_forget | Sequential | 2.5 K \n",
      "--------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d237ed69acee4914b0de41044a484051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 32\n",
    "model1 = TrainableModel()\n",
    "trainer = pl.Trainer(max_epochs=1,)\n",
    "trainer.fit(model1, \n",
    "            DataLoader(LightningDataset().init(train_proj_emb_dataset),\n",
    "                       batch_size=B, shuffle=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "trainer.model.train(False)\n",
    "with torch.no_grad():\n",
    "    val_pred = F.sigmoid(trainer.model(\n",
    "    torch.Tensor(val_proj_emb_dataset.samples))).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(trainer.model.modules())[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14., 12.,  4., 66.,  8., 23.,  0.,  0.,  0.,  1.]),\n",
       " array([-2.9786417 , -2.0764499 , -1.1742581 , -0.27206632,  0.63012546,\n",
       "         1.5323173 ,  2.434509  ,  3.336701  ,  4.2388926 ,  5.1410847 ,\n",
       "         6.0432763 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM/UlEQVR4nO3dcaid9X3H8fdnic5h10bnXQhGdoWKImNquTjFUZhph2vE5I8iLVvJukAYdMWygovdX4P9ERm0FTYKQdtdmFuVtBLRrW2WWsZgdb2prlVjpwsRI4m53ZTaDiZpv/vjPlmuNye55957zn3ur3m/IJzzPOc59/nykLx58uScJ6kqJEnt+YW+B5AkLY8Bl6RGGXBJapQBl6RGGXBJatT61dzZFVdcUZOTk6u5S0lq3qFDh35YVRML169qwCcnJ5mZmVnNXUpS85K8Mmi9l1AkqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVGr+k1MtWFy95O97fvonq297VtqjWfgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjRoq4Ek2JNmX5MUkh5PcmuTyJAeSvNQ9XjbuYSVJZwx7Bv4A8LWqug64ATgM7AYOVtU1wMFuWZK0ShYNeJL3AO8HHgKoqrer6k1gGzDdbTYNbB/PiJKkQYY5A78amAW+lOSZJA8muRTYWFXHu21OABvHNaQk6WzDBHw98D7gC1V1E/ATFlwuqaoCatCbk+xKMpNkZnZ2dqXzSpI6wwT8GHCsqp7ulvcxF/TXk2wC6B5PDnpzVe2tqqmqmpqYmBjFzJIkhgh4VZ0AXk1ybbdqC/AC8Diwo1u3A9g/lgklSQMN+7/SfxJ4OMnFwBHg48zF/9EkO4FXgLvHM6IkaZChAl5VzwJTA17aMtJpJElD85uYktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSo9cNslOQo8BbwU+BUVU0luRx4BJgEjgJ3V9Ub4xlTkrTQUs7Af7uqbqyqqW55N3Cwqq4BDnbLkqRVspJLKNuA6e75NLB9xdNIkoY2bMAL+EaSQ0l2des2VtXx7vkJYOOgNybZlWQmyczs7OwKx5UknTbUNXDgt6rqtSS/ChxI8uL8F6uqktSgN1bVXmAvwNTU1MBtJElLN9QZeFW91j2eBB4DbgZeT7IJoHs8Oa4hJUlnWzTgSS5N8sunnwO/AzwHPA7s6DbbAewf15CSpLMNcwllI/BYktPb/11VfS3Jd4BHk+wEXgHuHt+YkqSFFg14VR0Bbhiw/r+ALeMYSpK0OL+JKUmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1KihA55kXZJnkjzRLV+d5OkkLyd5JMnF4xtTkrTQUs7A7wEOz1u+H/hcVb0XeAPYOcrBJEnnN1TAk2wGtgIPdssBbgf2dZtMA9vHMJ8k6RyGPQP/PHAv8LNu+VeAN6vqVLd8DLhy0BuT7Eoyk2RmdnZ2JbNKkuZZNOBJ7gROVtWh5eygqvZW1VRVTU1MTCznR0iSBlg/xDa3AXcl+RBwCfBu4AFgQ5L13Vn4ZuC18Y0pSVpo0TPwqrqvqjZX1STwEeCbVfV7wFPAh7vNdgD7xzalJOksK/kc+J8Cf5LkZeauiT80mpEkScMY5hLK/6uqbwHf6p4fAW4e/UiSpGH4TUxJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJatSiAU9ySZJ/S/LvSZ5P8ufd+quTPJ3k5SSPJLl4/ONKkk4b5gz8f4Hbq+oG4EbgjiS3APcDn6uq9wJvADvHNqUk6SyLBrzm/LhbvKj7VcDtwL5u/TSwfRwDSpIGG+oaeJJ1SZ4FTgIHgP8E3qyqU90mx4Arz/HeXUlmkszMzs6OYGRJEgwZ8Kr6aVXdCGwGbgauG3YHVbW3qqaqampiYmJ5U0qSzrKkT6FU1ZvAU8CtwIYk67uXNgOvjXY0SdL5DPMplIkkG7rnvwR8EDjMXMg/3G22A9g/phklSQOsX3wTNgHTSdYxF/xHq+qJJC8AX07yF8AzwENjnFOStMCiAa+q7wE3DVh/hLnr4ZKkHvhNTElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYN8z/ySD/3Jnc/2du+j+7Z2tu+1TbPwCWpUQZckhplwCWpUQZckhplwCWpUYsGPMlVSZ5K8kKS55Pc062/PMmBJC91j5eNf1xJ0mnDnIGfAj5dVdcDtwCfSHI9sBs4WFXXAAe7ZUnSKlk04FV1vKq+2z1/CzgMXAlsA6a7zaaB7WOaUZI0wJKugSeZBG4CngY2VtXx7qUTwMZzvGdXkpkkM7OzsyuZVZI0z9ABT/Iu4CvAp6rqR/Nfq6oCatD7qmpvVU1V1dTExMSKhpUknTFUwJNcxFy8H66qr3arX0+yqXt9E3ByPCNKkgYZ5lMoAR4CDlfVZ+e99Diwo3u+A9g/+vEkSecyzM2sbgM+Bnw/ybPdus8Ae4BHk+wEXgHuHsuEkqSBFg14Vf0LkHO8vGW040iShuU3MSWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUcPcTnZNmNz9ZC/7Pbpnay/7laTFeAYuSY0y4JLUKAMuSY0y4JLUKAMuSY1q5lMofenr0y/gJ2AknZ9n4JLUKAMuSY1aNOBJvpjkZJLn5q27PMmBJC91j5eNd0xJ0kLDnIH/DXDHgnW7gYNVdQ1wsFuWJK2iRQNeVf8M/PeC1duA6e75NLB9tGNJkhaz3GvgG6vqePf8BLDxXBsm2ZVkJsnM7OzsMncnSVpoxf+IWVUF1Hle31tVU1U1NTExsdLdSZI6yw3460k2AXSPJ0c3kiRpGMsN+OPAju75DmD/aMaRJA1rmI8R/j3wr8C1SY4l2QnsAT6Y5CXgA92yJGkVLfpV+qr66Dle2jLiWSRJS+A3MSWpUd7MSmtKnzcPk1rjGbgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcp7oaxh3hdE0vl4Bi5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjVrRNzGT3AE8AKwDHqyqPSOZSpLGoK9vNx/ds3UsP3fZZ+BJ1gF/DfwucD3w0STXj2owSdL5reQSys3Ay1V1pKreBr4MbBvNWJKkxazkEsqVwKvzlo8Bv7lwoyS7gF3d4o+T/GAF++zbFcAP+x5iDfF4nLHsY5H7RzxJ//x98U5X5P4VH49fG7Ry7HcjrKq9wN5x72c1JJmpqqm+51grPB5neCzO8Fi80ziPx0ouobwGXDVveXO3TpK0ClYS8O8A1yS5OsnFwEeAx0czliRpMcu+hFJVp5L8MfB15j5G+MWqen5kk61NPxeXgkbI43GGx+IMj8U7je14pKrG9bMlSWPkNzElqVEGXJIaZcCXKMlfJnkxyfeSPJZkQ98zrbYkdyT5QZKXk+zue54+JbkqyVNJXkjyfJJ7+p6pb0nWJXkmyRN9z9K3JBuS7OuacTjJraP8+QZ86Q4Av15VvwH8B3Bfz/OsKm+hcJZTwKer6nrgFuATF/jxALgHONz3EGvEA8DXquo64AZGfFwM+BJV1Teq6lS3+G3mPv9+IfEWCvNU1fGq+m73/C3m/oBe2e9U/UmyGdgKPNj3LH1L8h7g/cBDAFX1dlW9Ocp9GPCV+UPgH/seYpUNuoXCBRus+ZJMAjcBT/c8Sp8+D9wL/KznOdaCq4FZ4EvdJaUHk1w6yh0Y8AGS/FOS5wb82jZvmz9j7q/PD/c3qdaKJO8CvgJ8qqp+1Pc8fUhyJ3Cyqg71PcsasR54H/CFqroJ+Akw0n8zGvu9UFpUVR843+tJ/gC4E9hSF94H6b2FwgJJLmIu3g9X1Vf7nqdHtwF3JfkQcAnw7iR/W1W/3/NcfTkGHKuq038j28eIA+4Z+BJ1/4nFvcBdVfU/fc/TA2+hME+SMHeN83BVfbbvefpUVfdV1eaqmmTu98U3L+B4U1UngFeTXNut2gK8MMp9eAa+dH8F/CJwYO7PLt+uqj/qd6TVc4HeQuF8bgM+Bnw/ybPdus9U1T/0N5LWkE8CD3cnO0eAj4/yh/tVeklqlJdQJKlRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalR/wdtBQQ82jOW5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    list(trainer.model.modules())[1][2]._parameters['weight'].detach().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590775597383527"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=val_pred, y_true=val_proj_emb_dataset.labels[:, 0] == 'NR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "c_model = LogisticRegression(\n",
    "    verbose=1,\n",
    "    C=1000,\n",
    "    max_iter=100,\n",
    "    tol=1e-5,\n",
    "    intercept_scaling=10000,\n",
    "    solver='saga').fit(train_proj_emb_dataset.samples,\n",
    "            (train_proj_emb_dataset.labels[:, 0] == 'NR').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -89.39231764,  -62.35505648,  -21.38688895,   93.06853924,\n",
       "          54.32501979, -100.63990137,   89.1827941 ,   28.73811385,\n",
       "          48.93773794,   44.34177382, -118.24216216, -130.94426432,\n",
       "         -60.0413207 ,   31.77852078,  -53.66576434,    9.51406708,\n",
       "         -53.20438636,   69.44730909,  -30.38905744,    0.96624803,\n",
       "         -79.64019924,  -29.20501449,  -51.81416968,  100.04971752,\n",
       "         -83.76852194]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502514128064788"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_score=c_model.predict_proba(val_proj_emb_dataset.samples)[:, 1],\n",
    "              y_true=(val_proj_emb_dataset.labels[:, 0] == 'NR').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 500,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'saga',\n",
       " 'tol': 1e-300,\n",
       " 'verbose': 1,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.058618\n",
      "0:\tlearn: 0.6233149\ttest: 0.6237224\tbest: 0.6237224 (0)\ttotal: 25.4ms\tremaining: 25.3s\n",
      "1:\tlearn: 0.5684346\ttest: 0.5696975\tbest: 0.5696975 (1)\ttotal: 43.3ms\tremaining: 21.6s\n",
      "2:\tlearn: 0.5275043\ttest: 0.5288272\tbest: 0.5288272 (2)\ttotal: 60.9ms\tremaining: 20.2s\n",
      "3:\tlearn: 0.4946424\ttest: 0.4962000\tbest: 0.4962000 (3)\ttotal: 77.3ms\tremaining: 19.3s\n",
      "4:\tlearn: 0.4678804\ttest: 0.4700168\tbest: 0.4700168 (4)\ttotal: 93.4ms\tremaining: 18.6s\n",
      "5:\tlearn: 0.4451077\ttest: 0.4481566\tbest: 0.4481566 (5)\ttotal: 107ms\tremaining: 17.7s\n",
      "6:\tlearn: 0.4269370\ttest: 0.4301235\tbest: 0.4301235 (6)\ttotal: 125ms\tremaining: 17.7s\n",
      "7:\tlearn: 0.4133329\ttest: 0.4169449\tbest: 0.4169449 (7)\ttotal: 147ms\tremaining: 18.2s\n",
      "8:\tlearn: 0.3976501\ttest: 0.4017889\tbest: 0.4017889 (8)\ttotal: 162ms\tremaining: 17.9s\n",
      "9:\tlearn: 0.3829185\ttest: 0.3872968\tbest: 0.3872968 (9)\ttotal: 179ms\tremaining: 17.7s\n",
      "10:\tlearn: 0.3733749\ttest: 0.3780247\tbest: 0.3780247 (10)\ttotal: 194ms\tremaining: 17.4s\n",
      "11:\tlearn: 0.3655567\ttest: 0.3706435\tbest: 0.3706435 (11)\ttotal: 211ms\tremaining: 17.4s\n",
      "12:\tlearn: 0.3554332\ttest: 0.3601840\tbest: 0.3601840 (12)\ttotal: 227ms\tremaining: 17.2s\n",
      "13:\tlearn: 0.3480691\ttest: 0.3530987\tbest: 0.3530987 (13)\ttotal: 243ms\tremaining: 17.1s\n",
      "14:\tlearn: 0.3388644\ttest: 0.3438613\tbest: 0.3438613 (14)\ttotal: 257ms\tremaining: 16.9s\n",
      "15:\tlearn: 0.3300656\ttest: 0.3353487\tbest: 0.3353487 (15)\ttotal: 272ms\tremaining: 16.7s\n",
      "16:\tlearn: 0.3242796\ttest: 0.3303069\tbest: 0.3303069 (16)\ttotal: 287ms\tremaining: 16.6s\n",
      "17:\tlearn: 0.3163885\ttest: 0.3224559\tbest: 0.3224559 (17)\ttotal: 302ms\tremaining: 16.5s\n",
      "18:\tlearn: 0.3091218\ttest: 0.3161837\tbest: 0.3161837 (18)\ttotal: 333ms\tremaining: 17.2s\n",
      "19:\tlearn: 0.3035620\ttest: 0.3113786\tbest: 0.3113786 (19)\ttotal: 394ms\tremaining: 19.3s\n",
      "20:\tlearn: 0.2993120\ttest: 0.3076102\tbest: 0.3076102 (20)\ttotal: 426ms\tremaining: 19.8s\n",
      "21:\tlearn: 0.2960052\ttest: 0.3047727\tbest: 0.3047727 (21)\ttotal: 449ms\tremaining: 20s\n",
      "22:\tlearn: 0.2923523\ttest: 0.3011082\tbest: 0.3011082 (22)\ttotal: 470ms\tremaining: 20s\n",
      "23:\tlearn: 0.2889297\ttest: 0.2983112\tbest: 0.2983112 (23)\ttotal: 492ms\tremaining: 20s\n",
      "24:\tlearn: 0.2857925\ttest: 0.2958266\tbest: 0.2958266 (24)\ttotal: 512ms\tremaining: 20s\n",
      "25:\tlearn: 0.2825395\ttest: 0.2926287\tbest: 0.2926287 (25)\ttotal: 533ms\tremaining: 20s\n",
      "26:\tlearn: 0.2783767\ttest: 0.2888790\tbest: 0.2888790 (26)\ttotal: 554ms\tremaining: 20s\n",
      "27:\tlearn: 0.2747458\ttest: 0.2857206\tbest: 0.2857206 (27)\ttotal: 576ms\tremaining: 20s\n",
      "28:\tlearn: 0.2718102\ttest: 0.2831352\tbest: 0.2831352 (28)\ttotal: 598ms\tremaining: 20s\n",
      "29:\tlearn: 0.2688902\ttest: 0.2802992\tbest: 0.2802992 (29)\ttotal: 620ms\tremaining: 20s\n",
      "30:\tlearn: 0.2660143\ttest: 0.2781770\tbest: 0.2781770 (30)\ttotal: 640ms\tremaining: 20s\n",
      "31:\tlearn: 0.2643436\ttest: 0.2764568\tbest: 0.2764568 (31)\ttotal: 672ms\tremaining: 20.3s\n",
      "32:\tlearn: 0.2622214\ttest: 0.2744347\tbest: 0.2744347 (32)\ttotal: 706ms\tremaining: 20.7s\n",
      "33:\tlearn: 0.2601833\ttest: 0.2726851\tbest: 0.2726851 (33)\ttotal: 727ms\tremaining: 20.6s\n",
      "34:\tlearn: 0.2580516\ttest: 0.2711353\tbest: 0.2711353 (34)\ttotal: 743ms\tremaining: 20.5s\n",
      "35:\tlearn: 0.2562618\ttest: 0.2696357\tbest: 0.2696357 (35)\ttotal: 759ms\tremaining: 20.3s\n",
      "36:\tlearn: 0.2539693\ttest: 0.2679701\tbest: 0.2679701 (36)\ttotal: 776ms\tremaining: 20.2s\n",
      "37:\tlearn: 0.2516314\ttest: 0.2658855\tbest: 0.2658855 (37)\ttotal: 792ms\tremaining: 20.1s\n",
      "38:\tlearn: 0.2496297\ttest: 0.2642248\tbest: 0.2642248 (38)\ttotal: 811ms\tremaining: 20s\n",
      "39:\tlearn: 0.2479896\ttest: 0.2624153\tbest: 0.2624153 (39)\ttotal: 826ms\tremaining: 19.8s\n",
      "40:\tlearn: 0.2463700\ttest: 0.2610830\tbest: 0.2610830 (40)\ttotal: 843ms\tremaining: 19.7s\n",
      "41:\tlearn: 0.2449892\ttest: 0.2602911\tbest: 0.2602911 (41)\ttotal: 860ms\tremaining: 19.6s\n",
      "42:\tlearn: 0.2438841\ttest: 0.2595211\tbest: 0.2595211 (42)\ttotal: 875ms\tremaining: 19.5s\n",
      "43:\tlearn: 0.2425347\ttest: 0.2586280\tbest: 0.2586280 (43)\ttotal: 891ms\tremaining: 19.4s\n",
      "44:\tlearn: 0.2413045\ttest: 0.2580448\tbest: 0.2580448 (44)\ttotal: 908ms\tremaining: 19.3s\n",
      "45:\tlearn: 0.2398031\ttest: 0.2566071\tbest: 0.2566071 (45)\ttotal: 924ms\tremaining: 19.2s\n",
      "46:\tlearn: 0.2383450\ttest: 0.2557000\tbest: 0.2557000 (46)\ttotal: 944ms\tremaining: 19.1s\n",
      "47:\tlearn: 0.2369305\ttest: 0.2547692\tbest: 0.2547692 (47)\ttotal: 963ms\tremaining: 19.1s\n",
      "48:\tlearn: 0.2358677\ttest: 0.2539516\tbest: 0.2539516 (48)\ttotal: 981ms\tremaining: 19s\n",
      "49:\tlearn: 0.2349536\ttest: 0.2533025\tbest: 0.2533025 (49)\ttotal: 999ms\tremaining: 19s\n",
      "50:\tlearn: 0.2334937\ttest: 0.2521690\tbest: 0.2521690 (50)\ttotal: 1.02s\tremaining: 19s\n",
      "51:\tlearn: 0.2324264\ttest: 0.2515994\tbest: 0.2515994 (51)\ttotal: 1.04s\tremaining: 19s\n",
      "52:\tlearn: 0.2306315\ttest: 0.2503683\tbest: 0.2503683 (52)\ttotal: 1.06s\tremaining: 19s\n",
      "53:\tlearn: 0.2294862\ttest: 0.2494646\tbest: 0.2494646 (53)\ttotal: 1.08s\tremaining: 19s\n",
      "54:\tlearn: 0.2286585\ttest: 0.2488690\tbest: 0.2488690 (54)\ttotal: 1.1s\tremaining: 18.9s\n",
      "55:\tlearn: 0.2277644\ttest: 0.2484322\tbest: 0.2484322 (55)\ttotal: 1.12s\tremaining: 18.9s\n",
      "56:\tlearn: 0.2267508\ttest: 0.2477994\tbest: 0.2477994 (56)\ttotal: 1.14s\tremaining: 18.8s\n",
      "57:\tlearn: 0.2259071\ttest: 0.2473942\tbest: 0.2473942 (57)\ttotal: 1.16s\tremaining: 18.8s\n",
      "58:\tlearn: 0.2248563\ttest: 0.2469080\tbest: 0.2469080 (58)\ttotal: 1.18s\tremaining: 18.8s\n",
      "59:\tlearn: 0.2238784\ttest: 0.2463753\tbest: 0.2463753 (59)\ttotal: 1.2s\tremaining: 18.7s\n",
      "60:\tlearn: 0.2230855\ttest: 0.2458458\tbest: 0.2458458 (60)\ttotal: 1.22s\tremaining: 18.7s\n",
      "61:\tlearn: 0.2219224\ttest: 0.2445111\tbest: 0.2445111 (61)\ttotal: 1.23s\tremaining: 18.6s\n",
      "62:\tlearn: 0.2212251\ttest: 0.2441762\tbest: 0.2441762 (62)\ttotal: 1.25s\tremaining: 18.6s\n",
      "63:\tlearn: 0.2201232\ttest: 0.2433363\tbest: 0.2433363 (63)\ttotal: 1.27s\tremaining: 18.6s\n",
      "64:\tlearn: 0.2191210\ttest: 0.2425945\tbest: 0.2425945 (64)\ttotal: 1.28s\tremaining: 18.5s\n",
      "65:\tlearn: 0.2182959\ttest: 0.2419264\tbest: 0.2419264 (65)\ttotal: 1.3s\tremaining: 18.4s\n",
      "66:\tlearn: 0.2172980\ttest: 0.2411884\tbest: 0.2411884 (66)\ttotal: 1.32s\tremaining: 18.4s\n",
      "67:\tlearn: 0.2163916\ttest: 0.2407559\tbest: 0.2407559 (67)\ttotal: 1.33s\tremaining: 18.3s\n",
      "68:\tlearn: 0.2155024\ttest: 0.2404957\tbest: 0.2404957 (68)\ttotal: 1.35s\tremaining: 18.2s\n",
      "69:\tlearn: 0.2148080\ttest: 0.2400928\tbest: 0.2400928 (69)\ttotal: 1.37s\tremaining: 18.2s\n",
      "70:\tlearn: 0.2138704\ttest: 0.2396838\tbest: 0.2396838 (70)\ttotal: 1.38s\tremaining: 18.1s\n",
      "71:\tlearn: 0.2131917\ttest: 0.2394116\tbest: 0.2394116 (71)\ttotal: 1.4s\tremaining: 18s\n",
      "72:\tlearn: 0.2123959\ttest: 0.2388119\tbest: 0.2388119 (72)\ttotal: 1.41s\tremaining: 18s\n",
      "73:\tlearn: 0.2116884\ttest: 0.2383906\tbest: 0.2383906 (73)\ttotal: 1.43s\tremaining: 17.9s\n",
      "74:\tlearn: 0.2110069\ttest: 0.2379692\tbest: 0.2379692 (74)\ttotal: 1.45s\tremaining: 17.9s\n",
      "75:\tlearn: 0.2102628\ttest: 0.2376427\tbest: 0.2376427 (75)\ttotal: 1.47s\tremaining: 17.9s\n",
      "76:\tlearn: 0.2094358\ttest: 0.2371253\tbest: 0.2371253 (76)\ttotal: 1.48s\tremaining: 17.8s\n",
      "77:\tlearn: 0.2088333\ttest: 0.2367480\tbest: 0.2367480 (77)\ttotal: 1.5s\tremaining: 17.8s\n",
      "78:\tlearn: 0.2080725\ttest: 0.2364214\tbest: 0.2364214 (78)\ttotal: 1.52s\tremaining: 17.7s\n",
      "79:\tlearn: 0.2074688\ttest: 0.2360213\tbest: 0.2360213 (79)\ttotal: 1.54s\tremaining: 17.7s\n",
      "80:\tlearn: 0.2067017\ttest: 0.2359077\tbest: 0.2359077 (80)\ttotal: 1.56s\tremaining: 17.7s\n",
      "81:\tlearn: 0.2058485\ttest: 0.2352315\tbest: 0.2352315 (81)\ttotal: 1.57s\tremaining: 17.6s\n",
      "82:\tlearn: 0.2051409\ttest: 0.2347964\tbest: 0.2347964 (82)\ttotal: 1.59s\tremaining: 17.6s\n",
      "83:\tlearn: 0.2043428\ttest: 0.2342067\tbest: 0.2342067 (83)\ttotal: 1.61s\tremaining: 17.5s\n",
      "84:\tlearn: 0.2036284\ttest: 0.2340358\tbest: 0.2340358 (84)\ttotal: 1.62s\tremaining: 17.5s\n",
      "85:\tlearn: 0.2030782\ttest: 0.2337227\tbest: 0.2337227 (85)\ttotal: 1.64s\tremaining: 17.4s\n",
      "86:\tlearn: 0.2024218\ttest: 0.2333837\tbest: 0.2333837 (86)\ttotal: 1.65s\tremaining: 17.4s\n",
      "87:\tlearn: 0.2018556\ttest: 0.2331235\tbest: 0.2331235 (87)\ttotal: 1.67s\tremaining: 17.3s\n",
      "88:\tlearn: 0.2014454\ttest: 0.2330003\tbest: 0.2330003 (88)\ttotal: 1.69s\tremaining: 17.3s\n",
      "89:\tlearn: 0.2009361\ttest: 0.2327520\tbest: 0.2327520 (89)\ttotal: 1.7s\tremaining: 17.2s\n",
      "90:\tlearn: 0.2002261\ttest: 0.2323033\tbest: 0.2323033 (90)\ttotal: 1.72s\tremaining: 17.1s\n",
      "91:\tlearn: 0.1996470\ttest: 0.2319075\tbest: 0.2319075 (91)\ttotal: 1.73s\tremaining: 17.1s\n",
      "92:\tlearn: 0.1987820\ttest: 0.2313594\tbest: 0.2313594 (92)\ttotal: 1.75s\tremaining: 17.1s\n",
      "93:\tlearn: 0.1981828\ttest: 0.2309861\tbest: 0.2309861 (93)\ttotal: 1.77s\tremaining: 17s\n",
      "94:\tlearn: 0.1977676\ttest: 0.2307310\tbest: 0.2307310 (94)\ttotal: 1.78s\tremaining: 17s\n",
      "95:\tlearn: 0.1972476\ttest: 0.2305703\tbest: 0.2305703 (95)\ttotal: 1.79s\tremaining: 16.9s\n",
      "96:\tlearn: 0.1966362\ttest: 0.2299170\tbest: 0.2299170 (96)\ttotal: 1.81s\tremaining: 16.9s\n",
      "97:\tlearn: 0.1957483\ttest: 0.2293783\tbest: 0.2293783 (97)\ttotal: 1.83s\tremaining: 16.8s\n",
      "98:\tlearn: 0.1953833\ttest: 0.2292238\tbest: 0.2292238 (98)\ttotal: 1.84s\tremaining: 16.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99:\tlearn: 0.1948734\ttest: 0.2288419\tbest: 0.2288419 (99)\ttotal: 1.86s\tremaining: 16.7s\n",
      "100:\tlearn: 0.1941326\ttest: 0.2282836\tbest: 0.2282836 (100)\ttotal: 1.88s\tremaining: 16.8s\n",
      "101:\tlearn: 0.1935876\ttest: 0.2277832\tbest: 0.2277832 (101)\ttotal: 1.9s\tremaining: 16.7s\n",
      "102:\tlearn: 0.1930628\ttest: 0.2274017\tbest: 0.2274017 (102)\ttotal: 1.92s\tremaining: 16.7s\n",
      "103:\tlearn: 0.1925197\ttest: 0.2271114\tbest: 0.2271114 (103)\ttotal: 1.93s\tremaining: 16.7s\n",
      "104:\tlearn: 0.1918435\ttest: 0.2268061\tbest: 0.2268061 (104)\ttotal: 1.96s\tremaining: 16.7s\n",
      "105:\tlearn: 0.1912934\ttest: 0.2263004\tbest: 0.2263004 (105)\ttotal: 1.98s\tremaining: 16.7s\n",
      "106:\tlearn: 0.1910421\ttest: 0.2263067\tbest: 0.2263004 (105)\ttotal: 2s\tremaining: 16.7s\n",
      "107:\tlearn: 0.1906132\ttest: 0.2260196\tbest: 0.2260196 (107)\ttotal: 2.01s\tremaining: 16.6s\n",
      "108:\tlearn: 0.1900150\ttest: 0.2255853\tbest: 0.2255853 (108)\ttotal: 2.02s\tremaining: 16.5s\n",
      "109:\tlearn: 0.1893702\ttest: 0.2253203\tbest: 0.2253203 (109)\ttotal: 2.04s\tremaining: 16.5s\n",
      "110:\tlearn: 0.1887689\ttest: 0.2247848\tbest: 0.2247848 (110)\ttotal: 2.05s\tremaining: 16.4s\n",
      "111:\tlearn: 0.1882977\ttest: 0.2248692\tbest: 0.2247848 (110)\ttotal: 2.07s\tremaining: 16.4s\n",
      "112:\tlearn: 0.1876858\ttest: 0.2248031\tbest: 0.2247848 (110)\ttotal: 2.08s\tremaining: 16.4s\n",
      "113:\tlearn: 0.1872105\ttest: 0.2245469\tbest: 0.2245469 (113)\ttotal: 2.1s\tremaining: 16.3s\n",
      "114:\tlearn: 0.1867475\ttest: 0.2244963\tbest: 0.2244963 (114)\ttotal: 2.12s\tremaining: 16.3s\n",
      "115:\tlearn: 0.1862528\ttest: 0.2242292\tbest: 0.2242292 (115)\ttotal: 2.13s\tremaining: 16.3s\n",
      "116:\tlearn: 0.1856621\ttest: 0.2239368\tbest: 0.2239368 (116)\ttotal: 2.15s\tremaining: 16.2s\n",
      "117:\tlearn: 0.1852175\ttest: 0.2239285\tbest: 0.2239285 (117)\ttotal: 2.17s\tremaining: 16.2s\n",
      "118:\tlearn: 0.1848177\ttest: 0.2235810\tbest: 0.2235810 (118)\ttotal: 2.19s\tremaining: 16.2s\n",
      "119:\tlearn: 0.1842614\ttest: 0.2232218\tbest: 0.2232218 (119)\ttotal: 2.2s\tremaining: 16.1s\n",
      "120:\tlearn: 0.1839407\ttest: 0.2232105\tbest: 0.2232105 (120)\ttotal: 2.22s\tremaining: 16.1s\n",
      "121:\tlearn: 0.1833381\ttest: 0.2226756\tbest: 0.2226756 (121)\ttotal: 2.24s\tremaining: 16.1s\n",
      "122:\tlearn: 0.1828938\ttest: 0.2222578\tbest: 0.2222578 (122)\ttotal: 2.25s\tremaining: 16.1s\n",
      "123:\tlearn: 0.1824173\ttest: 0.2221314\tbest: 0.2221314 (123)\ttotal: 2.27s\tremaining: 16s\n",
      "124:\tlearn: 0.1818639\ttest: 0.2217531\tbest: 0.2217531 (124)\ttotal: 2.29s\tremaining: 16s\n",
      "125:\tlearn: 0.1815529\ttest: 0.2216145\tbest: 0.2216145 (125)\ttotal: 2.3s\tremaining: 16s\n",
      "126:\tlearn: 0.1809037\ttest: 0.2213769\tbest: 0.2213769 (126)\ttotal: 2.32s\tremaining: 15.9s\n",
      "127:\tlearn: 0.1803856\ttest: 0.2213797\tbest: 0.2213769 (126)\ttotal: 2.33s\tremaining: 15.9s\n",
      "128:\tlearn: 0.1800358\ttest: 0.2213143\tbest: 0.2213143 (128)\ttotal: 2.35s\tremaining: 15.9s\n",
      "129:\tlearn: 0.1795190\ttest: 0.2210891\tbest: 0.2210891 (129)\ttotal: 2.36s\tremaining: 15.8s\n",
      "130:\tlearn: 0.1790431\ttest: 0.2208700\tbest: 0.2208700 (130)\ttotal: 2.38s\tremaining: 15.8s\n",
      "131:\tlearn: 0.1787177\ttest: 0.2205653\tbest: 0.2205653 (131)\ttotal: 2.39s\tremaining: 15.7s\n",
      "132:\tlearn: 0.1782348\ttest: 0.2203945\tbest: 0.2203945 (132)\ttotal: 2.41s\tremaining: 15.7s\n",
      "133:\tlearn: 0.1779644\ttest: 0.2201077\tbest: 0.2201077 (133)\ttotal: 2.42s\tremaining: 15.7s\n",
      "134:\tlearn: 0.1774900\ttest: 0.2198611\tbest: 0.2198611 (134)\ttotal: 2.44s\tremaining: 15.6s\n",
      "135:\tlearn: 0.1771747\ttest: 0.2198183\tbest: 0.2198183 (135)\ttotal: 2.45s\tremaining: 15.6s\n",
      "136:\tlearn: 0.1766747\ttest: 0.2194912\tbest: 0.2194912 (136)\ttotal: 2.47s\tremaining: 15.6s\n",
      "137:\tlearn: 0.1762996\ttest: 0.2194782\tbest: 0.2194782 (137)\ttotal: 2.49s\tremaining: 15.6s\n",
      "138:\tlearn: 0.1759207\ttest: 0.2195820\tbest: 0.2194782 (137)\ttotal: 2.51s\tremaining: 15.5s\n",
      "139:\tlearn: 0.1754838\ttest: 0.2195144\tbest: 0.2194782 (137)\ttotal: 2.52s\tremaining: 15.5s\n",
      "140:\tlearn: 0.1751358\ttest: 0.2192999\tbest: 0.2192999 (140)\ttotal: 2.54s\tremaining: 15.5s\n",
      "141:\tlearn: 0.1746999\ttest: 0.2192061\tbest: 0.2192061 (141)\ttotal: 2.56s\tremaining: 15.5s\n",
      "142:\tlearn: 0.1743927\ttest: 0.2189181\tbest: 0.2189181 (142)\ttotal: 2.58s\tremaining: 15.4s\n",
      "143:\tlearn: 0.1739928\ttest: 0.2185803\tbest: 0.2185803 (143)\ttotal: 2.59s\tremaining: 15.4s\n",
      "144:\tlearn: 0.1736270\ttest: 0.2183822\tbest: 0.2183822 (144)\ttotal: 2.61s\tremaining: 15.4s\n",
      "145:\tlearn: 0.1731971\ttest: 0.2183577\tbest: 0.2183577 (145)\ttotal: 2.63s\tremaining: 15.4s\n",
      "146:\tlearn: 0.1727234\ttest: 0.2182413\tbest: 0.2182413 (146)\ttotal: 2.65s\tremaining: 15.4s\n",
      "147:\tlearn: 0.1722495\ttest: 0.2182654\tbest: 0.2182413 (146)\ttotal: 2.67s\tremaining: 15.4s\n",
      "148:\tlearn: 0.1719868\ttest: 0.2181700\tbest: 0.2181700 (148)\ttotal: 2.7s\tremaining: 15.4s\n",
      "149:\tlearn: 0.1713865\ttest: 0.2179008\tbest: 0.2179008 (149)\ttotal: 2.71s\tremaining: 15.4s\n",
      "150:\tlearn: 0.1709172\ttest: 0.2179261\tbest: 0.2179008 (149)\ttotal: 2.73s\tremaining: 15.3s\n",
      "151:\tlearn: 0.1705498\ttest: 0.2180924\tbest: 0.2179008 (149)\ttotal: 2.74s\tremaining: 15.3s\n",
      "152:\tlearn: 0.1700574\ttest: 0.2178892\tbest: 0.2178892 (152)\ttotal: 2.76s\tremaining: 15.3s\n",
      "153:\tlearn: 0.1696392\ttest: 0.2180425\tbest: 0.2178892 (152)\ttotal: 2.78s\tremaining: 15.3s\n",
      "154:\tlearn: 0.1692020\ttest: 0.2178906\tbest: 0.2178892 (152)\ttotal: 2.79s\tremaining: 15.2s\n",
      "155:\tlearn: 0.1688336\ttest: 0.2178445\tbest: 0.2178445 (155)\ttotal: 2.81s\tremaining: 15.2s\n",
      "156:\tlearn: 0.1682914\ttest: 0.2178399\tbest: 0.2178399 (156)\ttotal: 2.82s\tremaining: 15.2s\n",
      "157:\tlearn: 0.1678019\ttest: 0.2178339\tbest: 0.2178339 (157)\ttotal: 2.84s\tremaining: 15.1s\n",
      "158:\tlearn: 0.1674271\ttest: 0.2177006\tbest: 0.2177006 (158)\ttotal: 2.86s\tremaining: 15.1s\n",
      "159:\tlearn: 0.1671015\ttest: 0.2178155\tbest: 0.2177006 (158)\ttotal: 2.88s\tremaining: 15.1s\n",
      "160:\tlearn: 0.1668629\ttest: 0.2178075\tbest: 0.2177006 (158)\ttotal: 2.9s\tremaining: 15.1s\n",
      "161:\tlearn: 0.1665208\ttest: 0.2176577\tbest: 0.2176577 (161)\ttotal: 2.91s\tremaining: 15.1s\n",
      "162:\tlearn: 0.1661656\ttest: 0.2175416\tbest: 0.2175416 (162)\ttotal: 2.93s\tremaining: 15s\n",
      "163:\tlearn: 0.1659235\ttest: 0.2173186\tbest: 0.2173186 (163)\ttotal: 2.95s\tremaining: 15s\n",
      "164:\tlearn: 0.1655454\ttest: 0.2174325\tbest: 0.2173186 (163)\ttotal: 2.97s\tremaining: 15s\n",
      "165:\tlearn: 0.1650501\ttest: 0.2171831\tbest: 0.2171831 (165)\ttotal: 2.99s\tremaining: 15s\n",
      "166:\tlearn: 0.1647449\ttest: 0.2172242\tbest: 0.2171831 (165)\ttotal: 3.01s\tremaining: 15s\n",
      "167:\tlearn: 0.1642855\ttest: 0.2168285\tbest: 0.2168285 (167)\ttotal: 3.03s\tremaining: 15s\n",
      "168:\tlearn: 0.1637852\ttest: 0.2165647\tbest: 0.2165647 (168)\ttotal: 3.05s\tremaining: 15s\n",
      "169:\tlearn: 0.1635066\ttest: 0.2165698\tbest: 0.2165647 (168)\ttotal: 3.07s\tremaining: 15s\n",
      "170:\tlearn: 0.1630560\ttest: 0.2163628\tbest: 0.2163628 (170)\ttotal: 3.09s\tremaining: 15s\n",
      "171:\tlearn: 0.1626141\ttest: 0.2163413\tbest: 0.2163413 (171)\ttotal: 3.11s\tremaining: 15s\n",
      "172:\tlearn: 0.1621826\ttest: 0.2165056\tbest: 0.2163413 (171)\ttotal: 3.13s\tremaining: 15s\n",
      "173:\tlearn: 0.1617365\ttest: 0.2162270\tbest: 0.2162270 (173)\ttotal: 3.15s\tremaining: 15s\n",
      "174:\tlearn: 0.1613607\ttest: 0.2159420\tbest: 0.2159420 (174)\ttotal: 3.17s\tremaining: 14.9s\n",
      "175:\tlearn: 0.1609180\ttest: 0.2154965\tbest: 0.2154965 (175)\ttotal: 3.19s\tremaining: 14.9s\n",
      "176:\tlearn: 0.1604303\ttest: 0.2152712\tbest: 0.2152712 (176)\ttotal: 3.2s\tremaining: 14.9s\n",
      "177:\tlearn: 0.1599450\ttest: 0.2152525\tbest: 0.2152525 (177)\ttotal: 3.21s\tremaining: 14.8s\n",
      "178:\tlearn: 0.1595710\ttest: 0.2152881\tbest: 0.2152525 (177)\ttotal: 3.23s\tremaining: 14.8s\n",
      "179:\tlearn: 0.1591405\ttest: 0.2153153\tbest: 0.2152525 (177)\ttotal: 3.24s\tremaining: 14.8s\n",
      "180:\tlearn: 0.1587270\ttest: 0.2149187\tbest: 0.2149187 (180)\ttotal: 3.26s\tremaining: 14.7s\n",
      "181:\tlearn: 0.1583163\ttest: 0.2148728\tbest: 0.2148728 (181)\ttotal: 3.27s\tremaining: 14.7s\n",
      "182:\tlearn: 0.1577738\ttest: 0.2145978\tbest: 0.2145978 (182)\ttotal: 3.29s\tremaining: 14.7s\n",
      "183:\tlearn: 0.1573720\ttest: 0.2147806\tbest: 0.2145978 (182)\ttotal: 3.3s\tremaining: 14.6s\n",
      "184:\tlearn: 0.1568322\ttest: 0.2148122\tbest: 0.2145978 (182)\ttotal: 3.32s\tremaining: 14.6s\n",
      "185:\tlearn: 0.1564204\ttest: 0.2149791\tbest: 0.2145978 (182)\ttotal: 3.33s\tremaining: 14.6s\n",
      "186:\tlearn: 0.1560759\ttest: 0.2150470\tbest: 0.2145978 (182)\ttotal: 3.35s\tremaining: 14.6s\n",
      "187:\tlearn: 0.1557096\ttest: 0.2149050\tbest: 0.2145978 (182)\ttotal: 3.36s\tremaining: 14.5s\n",
      "188:\tlearn: 0.1552542\ttest: 0.2147315\tbest: 0.2145978 (182)\ttotal: 3.38s\tremaining: 14.5s\n",
      "189:\tlearn: 0.1548297\ttest: 0.2145476\tbest: 0.2145476 (189)\ttotal: 3.4s\tremaining: 14.5s\n",
      "190:\tlearn: 0.1544411\ttest: 0.2144005\tbest: 0.2144005 (190)\ttotal: 3.41s\tremaining: 14.5s\n",
      "191:\tlearn: 0.1539590\ttest: 0.2144189\tbest: 0.2144005 (190)\ttotal: 3.43s\tremaining: 14.4s\n",
      "192:\tlearn: 0.1534173\ttest: 0.2143209\tbest: 0.2143209 (192)\ttotal: 3.44s\tremaining: 14.4s\n",
      "193:\tlearn: 0.1529844\ttest: 0.2141595\tbest: 0.2141595 (193)\ttotal: 3.46s\tremaining: 14.4s\n",
      "194:\tlearn: 0.1524614\ttest: 0.2139078\tbest: 0.2139078 (194)\ttotal: 3.47s\tremaining: 14.3s\n",
      "195:\tlearn: 0.1521299\ttest: 0.2138276\tbest: 0.2138276 (195)\ttotal: 3.49s\tremaining: 14.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196:\tlearn: 0.1517613\ttest: 0.2135866\tbest: 0.2135866 (196)\ttotal: 3.5s\tremaining: 14.3s\n",
      "197:\tlearn: 0.1513046\ttest: 0.2135589\tbest: 0.2135589 (197)\ttotal: 3.52s\tremaining: 14.3s\n",
      "198:\tlearn: 0.1509085\ttest: 0.2136722\tbest: 0.2135589 (197)\ttotal: 3.53s\tremaining: 14.2s\n",
      "199:\tlearn: 0.1505057\ttest: 0.2136263\tbest: 0.2135589 (197)\ttotal: 3.55s\tremaining: 14.2s\n",
      "200:\tlearn: 0.1501960\ttest: 0.2133883\tbest: 0.2133883 (200)\ttotal: 3.56s\tremaining: 14.2s\n",
      "201:\tlearn: 0.1497334\ttest: 0.2134341\tbest: 0.2133883 (200)\ttotal: 3.58s\tremaining: 14.1s\n",
      "202:\tlearn: 0.1492741\ttest: 0.2132664\tbest: 0.2132664 (202)\ttotal: 3.59s\tremaining: 14.1s\n",
      "203:\tlearn: 0.1488329\ttest: 0.2130344\tbest: 0.2130344 (203)\ttotal: 3.61s\tremaining: 14.1s\n",
      "204:\tlearn: 0.1484407\ttest: 0.2129820\tbest: 0.2129820 (204)\ttotal: 3.62s\tremaining: 14.1s\n",
      "205:\tlearn: 0.1479583\ttest: 0.2128520\tbest: 0.2128520 (205)\ttotal: 3.64s\tremaining: 14s\n",
      "206:\tlearn: 0.1473753\ttest: 0.2125008\tbest: 0.2125008 (206)\ttotal: 3.65s\tremaining: 14s\n",
      "207:\tlearn: 0.1470140\ttest: 0.2123908\tbest: 0.2123908 (207)\ttotal: 3.67s\tremaining: 14s\n",
      "208:\tlearn: 0.1465401\ttest: 0.2123817\tbest: 0.2123817 (208)\ttotal: 3.69s\tremaining: 14s\n",
      "209:\tlearn: 0.1460932\ttest: 0.2123215\tbest: 0.2123215 (209)\ttotal: 3.7s\tremaining: 13.9s\n",
      "210:\tlearn: 0.1457605\ttest: 0.2122672\tbest: 0.2122672 (210)\ttotal: 3.72s\tremaining: 13.9s\n",
      "211:\tlearn: 0.1454256\ttest: 0.2120610\tbest: 0.2120610 (211)\ttotal: 3.73s\tremaining: 13.9s\n",
      "212:\tlearn: 0.1449536\ttest: 0.2121710\tbest: 0.2120610 (211)\ttotal: 3.75s\tremaining: 13.8s\n",
      "213:\tlearn: 0.1446664\ttest: 0.2122843\tbest: 0.2120610 (211)\ttotal: 3.76s\tremaining: 13.8s\n",
      "214:\tlearn: 0.1443749\ttest: 0.2122584\tbest: 0.2120610 (211)\ttotal: 3.78s\tremaining: 13.8s\n",
      "215:\tlearn: 0.1439898\ttest: 0.2121534\tbest: 0.2120610 (211)\ttotal: 3.79s\tremaining: 13.8s\n",
      "216:\tlearn: 0.1436991\ttest: 0.2121914\tbest: 0.2120610 (211)\ttotal: 3.81s\tremaining: 13.7s\n",
      "217:\tlearn: 0.1432566\ttest: 0.2119367\tbest: 0.2119367 (217)\ttotal: 3.82s\tremaining: 13.7s\n",
      "218:\tlearn: 0.1428418\ttest: 0.2116222\tbest: 0.2116222 (218)\ttotal: 3.83s\tremaining: 13.7s\n",
      "219:\tlearn: 0.1423758\ttest: 0.2117632\tbest: 0.2116222 (218)\ttotal: 3.85s\tremaining: 13.7s\n",
      "220:\tlearn: 0.1420600\ttest: 0.2117512\tbest: 0.2116222 (218)\ttotal: 3.86s\tremaining: 13.6s\n",
      "221:\tlearn: 0.1416904\ttest: 0.2115287\tbest: 0.2115287 (221)\ttotal: 3.88s\tremaining: 13.6s\n",
      "222:\tlearn: 0.1412475\ttest: 0.2116549\tbest: 0.2115287 (221)\ttotal: 3.89s\tremaining: 13.6s\n",
      "223:\tlearn: 0.1407516\ttest: 0.2114221\tbest: 0.2114221 (223)\ttotal: 3.91s\tremaining: 13.5s\n",
      "224:\tlearn: 0.1404521\ttest: 0.2113822\tbest: 0.2113822 (224)\ttotal: 3.93s\tremaining: 13.5s\n",
      "225:\tlearn: 0.1400567\ttest: 0.2113737\tbest: 0.2113737 (225)\ttotal: 3.94s\tremaining: 13.5s\n",
      "226:\tlearn: 0.1397953\ttest: 0.2110706\tbest: 0.2110706 (226)\ttotal: 3.95s\tremaining: 13.5s\n",
      "227:\tlearn: 0.1393059\ttest: 0.2108099\tbest: 0.2108099 (227)\ttotal: 3.97s\tremaining: 13.4s\n",
      "228:\tlearn: 0.1389350\ttest: 0.2106280\tbest: 0.2106280 (228)\ttotal: 3.99s\tremaining: 13.4s\n",
      "229:\tlearn: 0.1385801\ttest: 0.2105325\tbest: 0.2105325 (229)\ttotal: 4s\tremaining: 13.4s\n",
      "230:\tlearn: 0.1382384\ttest: 0.2104087\tbest: 0.2104087 (230)\ttotal: 4.02s\tremaining: 13.4s\n",
      "231:\tlearn: 0.1378988\ttest: 0.2103236\tbest: 0.2103236 (231)\ttotal: 4.03s\tremaining: 13.3s\n",
      "232:\tlearn: 0.1376996\ttest: 0.2101793\tbest: 0.2101793 (232)\ttotal: 4.05s\tremaining: 13.3s\n",
      "233:\tlearn: 0.1373249\ttest: 0.2102556\tbest: 0.2101793 (232)\ttotal: 4.06s\tremaining: 13.3s\n",
      "234:\tlearn: 0.1371043\ttest: 0.2101805\tbest: 0.2101793 (232)\ttotal: 4.08s\tremaining: 13.3s\n",
      "235:\tlearn: 0.1367341\ttest: 0.2100994\tbest: 0.2100994 (235)\ttotal: 4.1s\tremaining: 13.3s\n",
      "236:\tlearn: 0.1363694\ttest: 0.2100213\tbest: 0.2100213 (236)\ttotal: 4.11s\tremaining: 13.2s\n",
      "237:\tlearn: 0.1361435\ttest: 0.2100781\tbest: 0.2100213 (236)\ttotal: 4.13s\tremaining: 13.2s\n",
      "238:\tlearn: 0.1358336\ttest: 0.2101066\tbest: 0.2100213 (236)\ttotal: 4.14s\tremaining: 13.2s\n",
      "239:\tlearn: 0.1354474\ttest: 0.2099710\tbest: 0.2099710 (239)\ttotal: 4.16s\tremaining: 13.2s\n",
      "240:\tlearn: 0.1350537\ttest: 0.2099774\tbest: 0.2099710 (239)\ttotal: 4.17s\tremaining: 13.2s\n",
      "241:\tlearn: 0.1347449\ttest: 0.2099210\tbest: 0.2099210 (241)\ttotal: 4.19s\tremaining: 13.1s\n",
      "242:\tlearn: 0.1344082\ttest: 0.2097868\tbest: 0.2097868 (242)\ttotal: 4.21s\tremaining: 13.1s\n",
      "243:\tlearn: 0.1340831\ttest: 0.2098136\tbest: 0.2097868 (242)\ttotal: 4.22s\tremaining: 13.1s\n",
      "244:\tlearn: 0.1338300\ttest: 0.2100314\tbest: 0.2097868 (242)\ttotal: 4.23s\tremaining: 13s\n",
      "245:\tlearn: 0.1335223\ttest: 0.2099678\tbest: 0.2097868 (242)\ttotal: 4.25s\tremaining: 13s\n",
      "246:\tlearn: 0.1332173\ttest: 0.2099874\tbest: 0.2097868 (242)\ttotal: 4.26s\tremaining: 13s\n",
      "247:\tlearn: 0.1329156\ttest: 0.2100643\tbest: 0.2097868 (242)\ttotal: 4.28s\tremaining: 13s\n",
      "248:\tlearn: 0.1327375\ttest: 0.2100460\tbest: 0.2097868 (242)\ttotal: 4.29s\tremaining: 12.9s\n",
      "249:\tlearn: 0.1324274\ttest: 0.2100463\tbest: 0.2097868 (242)\ttotal: 4.31s\tremaining: 12.9s\n",
      "250:\tlearn: 0.1321795\ttest: 0.2099819\tbest: 0.2097868 (242)\ttotal: 4.32s\tremaining: 12.9s\n",
      "251:\tlearn: 0.1318730\ttest: 0.2098876\tbest: 0.2097868 (242)\ttotal: 4.34s\tremaining: 12.9s\n",
      "252:\tlearn: 0.1316124\ttest: 0.2097538\tbest: 0.2097538 (252)\ttotal: 4.35s\tremaining: 12.9s\n",
      "253:\tlearn: 0.1312837\ttest: 0.2095668\tbest: 0.2095668 (253)\ttotal: 4.37s\tremaining: 12.8s\n",
      "254:\tlearn: 0.1309094\ttest: 0.2094711\tbest: 0.2094711 (254)\ttotal: 4.38s\tremaining: 12.8s\n",
      "255:\tlearn: 0.1305767\ttest: 0.2092934\tbest: 0.2092934 (255)\ttotal: 4.4s\tremaining: 12.8s\n",
      "256:\tlearn: 0.1301846\ttest: 0.2092894\tbest: 0.2092894 (256)\ttotal: 4.41s\tremaining: 12.8s\n",
      "257:\tlearn: 0.1297008\ttest: 0.2092332\tbest: 0.2092332 (257)\ttotal: 4.43s\tremaining: 12.7s\n",
      "258:\tlearn: 0.1294576\ttest: 0.2090854\tbest: 0.2090854 (258)\ttotal: 4.44s\tremaining: 12.7s\n",
      "259:\tlearn: 0.1290543\ttest: 0.2088273\tbest: 0.2088273 (259)\ttotal: 4.46s\tremaining: 12.7s\n",
      "260:\tlearn: 0.1287082\ttest: 0.2088242\tbest: 0.2088242 (260)\ttotal: 4.48s\tremaining: 12.7s\n",
      "261:\tlearn: 0.1284596\ttest: 0.2086877\tbest: 0.2086877 (261)\ttotal: 4.49s\tremaining: 12.7s\n",
      "262:\tlearn: 0.1282317\ttest: 0.2085890\tbest: 0.2085890 (262)\ttotal: 4.51s\tremaining: 12.6s\n",
      "263:\tlearn: 0.1279677\ttest: 0.2087508\tbest: 0.2085890 (262)\ttotal: 4.52s\tremaining: 12.6s\n",
      "264:\tlearn: 0.1275068\ttest: 0.2085480\tbest: 0.2085480 (264)\ttotal: 4.54s\tremaining: 12.6s\n",
      "265:\tlearn: 0.1272667\ttest: 0.2085675\tbest: 0.2085480 (264)\ttotal: 4.56s\tremaining: 12.6s\n",
      "266:\tlearn: 0.1268798\ttest: 0.2086341\tbest: 0.2085480 (264)\ttotal: 4.57s\tremaining: 12.6s\n",
      "267:\tlearn: 0.1266119\ttest: 0.2085390\tbest: 0.2085390 (267)\ttotal: 4.59s\tremaining: 12.5s\n",
      "268:\tlearn: 0.1263488\ttest: 0.2085774\tbest: 0.2085390 (267)\ttotal: 4.6s\tremaining: 12.5s\n",
      "269:\tlearn: 0.1260883\ttest: 0.2085762\tbest: 0.2085390 (267)\ttotal: 4.62s\tremaining: 12.5s\n",
      "270:\tlearn: 0.1257465\ttest: 0.2085119\tbest: 0.2085119 (270)\ttotal: 4.63s\tremaining: 12.5s\n",
      "271:\tlearn: 0.1254830\ttest: 0.2084192\tbest: 0.2084192 (271)\ttotal: 4.64s\tremaining: 12.4s\n",
      "272:\tlearn: 0.1252181\ttest: 0.2082927\tbest: 0.2082927 (272)\ttotal: 4.66s\tremaining: 12.4s\n",
      "273:\tlearn: 0.1249007\ttest: 0.2083521\tbest: 0.2082927 (272)\ttotal: 4.67s\tremaining: 12.4s\n",
      "274:\tlearn: 0.1246847\ttest: 0.2083338\tbest: 0.2082927 (272)\ttotal: 4.69s\tremaining: 12.4s\n",
      "275:\tlearn: 0.1242906\ttest: 0.2083986\tbest: 0.2082927 (272)\ttotal: 4.7s\tremaining: 12.3s\n",
      "276:\tlearn: 0.1239567\ttest: 0.2079284\tbest: 0.2079284 (276)\ttotal: 4.72s\tremaining: 12.3s\n",
      "277:\tlearn: 0.1236711\ttest: 0.2080612\tbest: 0.2079284 (276)\ttotal: 4.73s\tremaining: 12.3s\n",
      "278:\tlearn: 0.1234046\ttest: 0.2078725\tbest: 0.2078725 (278)\ttotal: 4.75s\tremaining: 12.3s\n",
      "279:\tlearn: 0.1230440\ttest: 0.2077805\tbest: 0.2077805 (279)\ttotal: 4.76s\tremaining: 12.2s\n",
      "280:\tlearn: 0.1228270\ttest: 0.2075481\tbest: 0.2075481 (280)\ttotal: 4.78s\tremaining: 12.2s\n",
      "281:\tlearn: 0.1224514\ttest: 0.2073264\tbest: 0.2073264 (281)\ttotal: 4.79s\tremaining: 12.2s\n",
      "282:\tlearn: 0.1222750\ttest: 0.2073598\tbest: 0.2073264 (281)\ttotal: 4.8s\tremaining: 12.2s\n",
      "283:\tlearn: 0.1220870\ttest: 0.2075278\tbest: 0.2073264 (281)\ttotal: 4.82s\tremaining: 12.1s\n",
      "284:\tlearn: 0.1218969\ttest: 0.2075215\tbest: 0.2073264 (281)\ttotal: 4.83s\tremaining: 12.1s\n",
      "285:\tlearn: 0.1215832\ttest: 0.2074841\tbest: 0.2073264 (281)\ttotal: 4.85s\tremaining: 12.1s\n",
      "286:\tlearn: 0.1213721\ttest: 0.2072243\tbest: 0.2072243 (286)\ttotal: 4.86s\tremaining: 12.1s\n",
      "287:\tlearn: 0.1211310\ttest: 0.2071631\tbest: 0.2071631 (287)\ttotal: 4.87s\tremaining: 12.1s\n",
      "288:\tlearn: 0.1208161\ttest: 0.2072009\tbest: 0.2071631 (287)\ttotal: 4.89s\tremaining: 12s\n",
      "289:\tlearn: 0.1205916\ttest: 0.2072750\tbest: 0.2071631 (287)\ttotal: 4.9s\tremaining: 12s\n",
      "290:\tlearn: 0.1203867\ttest: 0.2072673\tbest: 0.2071631 (287)\ttotal: 4.92s\tremaining: 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291:\tlearn: 0.1200920\ttest: 0.2072322\tbest: 0.2071631 (287)\ttotal: 4.93s\tremaining: 12s\n",
      "292:\tlearn: 0.1197331\ttest: 0.2072490\tbest: 0.2071631 (287)\ttotal: 4.95s\tremaining: 11.9s\n",
      "293:\tlearn: 0.1194808\ttest: 0.2072443\tbest: 0.2071631 (287)\ttotal: 4.96s\tremaining: 11.9s\n",
      "294:\tlearn: 0.1191110\ttest: 0.2071185\tbest: 0.2071185 (294)\ttotal: 4.98s\tremaining: 11.9s\n",
      "295:\tlearn: 0.1188170\ttest: 0.2071568\tbest: 0.2071185 (294)\ttotal: 4.99s\tremaining: 11.9s\n",
      "296:\tlearn: 0.1185410\ttest: 0.2070931\tbest: 0.2070931 (296)\ttotal: 5.01s\tremaining: 11.9s\n",
      "297:\tlearn: 0.1182119\ttest: 0.2071433\tbest: 0.2070931 (296)\ttotal: 5.02s\tremaining: 11.8s\n",
      "298:\tlearn: 0.1178210\ttest: 0.2069327\tbest: 0.2069327 (298)\ttotal: 5.04s\tremaining: 11.8s\n",
      "299:\tlearn: 0.1175767\ttest: 0.2070701\tbest: 0.2069327 (298)\ttotal: 5.05s\tremaining: 11.8s\n",
      "300:\tlearn: 0.1173830\ttest: 0.2069804\tbest: 0.2069327 (298)\ttotal: 5.07s\tremaining: 11.8s\n",
      "301:\tlearn: 0.1170931\ttest: 0.2071936\tbest: 0.2069327 (298)\ttotal: 5.08s\tremaining: 11.8s\n",
      "302:\tlearn: 0.1168067\ttest: 0.2072056\tbest: 0.2069327 (298)\ttotal: 5.1s\tremaining: 11.7s\n",
      "303:\tlearn: 0.1165019\ttest: 0.2072843\tbest: 0.2069327 (298)\ttotal: 5.11s\tremaining: 11.7s\n",
      "304:\tlearn: 0.1161651\ttest: 0.2071288\tbest: 0.2069327 (298)\ttotal: 5.13s\tremaining: 11.7s\n",
      "305:\tlearn: 0.1157900\ttest: 0.2072541\tbest: 0.2069327 (298)\ttotal: 5.15s\tremaining: 11.7s\n",
      "306:\tlearn: 0.1155168\ttest: 0.2070845\tbest: 0.2069327 (298)\ttotal: 5.22s\tremaining: 11.8s\n",
      "307:\tlearn: 0.1152265\ttest: 0.2070623\tbest: 0.2069327 (298)\ttotal: 5.34s\tremaining: 12s\n",
      "308:\tlearn: 0.1149638\ttest: 0.2071472\tbest: 0.2069327 (298)\ttotal: 5.36s\tremaining: 12s\n",
      "309:\tlearn: 0.1146706\ttest: 0.2072788\tbest: 0.2069327 (298)\ttotal: 5.38s\tremaining: 12s\n",
      "310:\tlearn: 0.1144727\ttest: 0.2072995\tbest: 0.2069327 (298)\ttotal: 5.4s\tremaining: 12s\n",
      "311:\tlearn: 0.1141868\ttest: 0.2074424\tbest: 0.2069327 (298)\ttotal: 5.43s\tremaining: 12s\n",
      "312:\tlearn: 0.1139524\ttest: 0.2071656\tbest: 0.2069327 (298)\ttotal: 5.46s\tremaining: 12s\n",
      "313:\tlearn: 0.1136761\ttest: 0.2070065\tbest: 0.2069327 (298)\ttotal: 5.48s\tremaining: 12s\n",
      "314:\tlearn: 0.1134253\ttest: 0.2067802\tbest: 0.2067802 (314)\ttotal: 5.49s\tremaining: 11.9s\n",
      "315:\tlearn: 0.1132221\ttest: 0.2067182\tbest: 0.2067182 (315)\ttotal: 5.51s\tremaining: 11.9s\n",
      "316:\tlearn: 0.1130021\ttest: 0.2067390\tbest: 0.2067182 (315)\ttotal: 5.53s\tremaining: 11.9s\n",
      "317:\tlearn: 0.1127879\ttest: 0.2068535\tbest: 0.2067182 (315)\ttotal: 5.55s\tremaining: 11.9s\n",
      "318:\tlearn: 0.1125084\ttest: 0.2069181\tbest: 0.2067182 (315)\ttotal: 5.57s\tremaining: 11.9s\n",
      "319:\tlearn: 0.1122747\ttest: 0.2069454\tbest: 0.2067182 (315)\ttotal: 5.58s\tremaining: 11.9s\n",
      "320:\tlearn: 0.1120384\ttest: 0.2069954\tbest: 0.2067182 (315)\ttotal: 5.6s\tremaining: 11.9s\n",
      "321:\tlearn: 0.1117872\ttest: 0.2070639\tbest: 0.2067182 (315)\ttotal: 5.62s\tremaining: 11.8s\n",
      "322:\tlearn: 0.1114658\ttest: 0.2067757\tbest: 0.2067182 (315)\ttotal: 5.64s\tremaining: 11.8s\n",
      "323:\tlearn: 0.1111740\ttest: 0.2068866\tbest: 0.2067182 (315)\ttotal: 5.66s\tremaining: 11.8s\n",
      "324:\tlearn: 0.1109731\ttest: 0.2069587\tbest: 0.2067182 (315)\ttotal: 5.67s\tremaining: 11.8s\n",
      "325:\tlearn: 0.1108533\ttest: 0.2069506\tbest: 0.2067182 (315)\ttotal: 5.69s\tremaining: 11.8s\n",
      "326:\tlearn: 0.1105031\ttest: 0.2070202\tbest: 0.2067182 (315)\ttotal: 5.71s\tremaining: 11.8s\n",
      "327:\tlearn: 0.1102557\ttest: 0.2071122\tbest: 0.2067182 (315)\ttotal: 5.73s\tremaining: 11.7s\n",
      "328:\tlearn: 0.1099992\ttest: 0.2071434\tbest: 0.2067182 (315)\ttotal: 5.74s\tremaining: 11.7s\n",
      "329:\tlearn: 0.1096976\ttest: 0.2071121\tbest: 0.2067182 (315)\ttotal: 5.76s\tremaining: 11.7s\n",
      "330:\tlearn: 0.1094946\ttest: 0.2070578\tbest: 0.2067182 (315)\ttotal: 5.78s\tremaining: 11.7s\n",
      "331:\tlearn: 0.1092400\ttest: 0.2068840\tbest: 0.2067182 (315)\ttotal: 5.79s\tremaining: 11.7s\n",
      "332:\tlearn: 0.1089589\ttest: 0.2071203\tbest: 0.2067182 (315)\ttotal: 5.8s\tremaining: 11.6s\n",
      "333:\tlearn: 0.1086749\ttest: 0.2071704\tbest: 0.2067182 (315)\ttotal: 5.82s\tremaining: 11.6s\n",
      "334:\tlearn: 0.1084699\ttest: 0.2070657\tbest: 0.2067182 (315)\ttotal: 5.83s\tremaining: 11.6s\n",
      "335:\tlearn: 0.1083293\ttest: 0.2072152\tbest: 0.2067182 (315)\ttotal: 5.85s\tremaining: 11.6s\n",
      "336:\tlearn: 0.1080036\ttest: 0.2071569\tbest: 0.2067182 (315)\ttotal: 5.86s\tremaining: 11.5s\n",
      "337:\tlearn: 0.1077131\ttest: 0.2072983\tbest: 0.2067182 (315)\ttotal: 5.88s\tremaining: 11.5s\n",
      "338:\tlearn: 0.1074515\ttest: 0.2068969\tbest: 0.2067182 (315)\ttotal: 5.89s\tremaining: 11.5s\n",
      "339:\tlearn: 0.1072636\ttest: 0.2069170\tbest: 0.2067182 (315)\ttotal: 5.91s\tremaining: 11.5s\n",
      "340:\tlearn: 0.1070117\ttest: 0.2065233\tbest: 0.2065233 (340)\ttotal: 5.93s\tremaining: 11.5s\n",
      "341:\tlearn: 0.1068314\ttest: 0.2064639\tbest: 0.2064639 (341)\ttotal: 5.94s\tremaining: 11.4s\n",
      "342:\tlearn: 0.1066528\ttest: 0.2064753\tbest: 0.2064639 (341)\ttotal: 5.96s\tremaining: 11.4s\n",
      "343:\tlearn: 0.1063505\ttest: 0.2063652\tbest: 0.2063652 (343)\ttotal: 5.98s\tremaining: 11.4s\n",
      "344:\tlearn: 0.1060994\ttest: 0.2064617\tbest: 0.2063652 (343)\ttotal: 6s\tremaining: 11.4s\n",
      "345:\tlearn: 0.1058360\ttest: 0.2063273\tbest: 0.2063273 (345)\ttotal: 6.01s\tremaining: 11.4s\n",
      "346:\tlearn: 0.1056283\ttest: 0.2063153\tbest: 0.2063153 (346)\ttotal: 6.04s\tremaining: 11.4s\n",
      "347:\tlearn: 0.1054655\ttest: 0.2063454\tbest: 0.2063153 (346)\ttotal: 6.05s\tremaining: 11.3s\n",
      "348:\tlearn: 0.1051945\ttest: 0.2061117\tbest: 0.2061117 (348)\ttotal: 6.07s\tremaining: 11.3s\n",
      "349:\tlearn: 0.1050243\ttest: 0.2061977\tbest: 0.2061117 (348)\ttotal: 6.13s\tremaining: 11.4s\n",
      "350:\tlearn: 0.1047412\ttest: 0.2062279\tbest: 0.2061117 (348)\ttotal: 6.14s\tremaining: 11.4s\n",
      "351:\tlearn: 0.1045410\ttest: 0.2063227\tbest: 0.2061117 (348)\ttotal: 6.16s\tremaining: 11.3s\n",
      "352:\tlearn: 0.1043705\ttest: 0.2062674\tbest: 0.2061117 (348)\ttotal: 6.18s\tremaining: 11.3s\n",
      "353:\tlearn: 0.1041521\ttest: 0.2063125\tbest: 0.2061117 (348)\ttotal: 6.19s\tremaining: 11.3s\n",
      "354:\tlearn: 0.1039110\ttest: 0.2061628\tbest: 0.2061117 (348)\ttotal: 6.21s\tremaining: 11.3s\n",
      "355:\tlearn: 0.1036902\ttest: 0.2060447\tbest: 0.2060447 (355)\ttotal: 6.23s\tremaining: 11.3s\n",
      "356:\tlearn: 0.1035014\ttest: 0.2060986\tbest: 0.2060447 (355)\ttotal: 6.25s\tremaining: 11.3s\n",
      "357:\tlearn: 0.1033276\ttest: 0.2059328\tbest: 0.2059328 (357)\ttotal: 6.27s\tremaining: 11.2s\n",
      "358:\tlearn: 0.1031654\ttest: 0.2058206\tbest: 0.2058206 (358)\ttotal: 6.28s\tremaining: 11.2s\n",
      "359:\tlearn: 0.1029864\ttest: 0.2056786\tbest: 0.2056786 (359)\ttotal: 6.3s\tremaining: 11.2s\n",
      "360:\tlearn: 0.1027146\ttest: 0.2055352\tbest: 0.2055352 (360)\ttotal: 6.32s\tremaining: 11.2s\n",
      "361:\tlearn: 0.1025363\ttest: 0.2055039\tbest: 0.2055039 (361)\ttotal: 6.34s\tremaining: 11.2s\n",
      "362:\tlearn: 0.1022625\ttest: 0.2054760\tbest: 0.2054760 (362)\ttotal: 6.35s\tremaining: 11.2s\n",
      "363:\tlearn: 0.1020443\ttest: 0.2053062\tbest: 0.2053062 (363)\ttotal: 6.37s\tremaining: 11.1s\n",
      "364:\tlearn: 0.1019746\ttest: 0.2053391\tbest: 0.2053062 (363)\ttotal: 6.39s\tremaining: 11.1s\n",
      "365:\tlearn: 0.1017037\ttest: 0.2051758\tbest: 0.2051758 (365)\ttotal: 6.4s\tremaining: 11.1s\n",
      "366:\tlearn: 0.1014154\ttest: 0.2051058\tbest: 0.2051058 (366)\ttotal: 6.42s\tremaining: 11.1s\n",
      "367:\tlearn: 0.1011529\ttest: 0.2050088\tbest: 0.2050088 (367)\ttotal: 6.44s\tremaining: 11.1s\n",
      "368:\tlearn: 0.1010179\ttest: 0.2049412\tbest: 0.2049412 (368)\ttotal: 6.46s\tremaining: 11s\n",
      "369:\tlearn: 0.1009001\ttest: 0.2048844\tbest: 0.2048844 (369)\ttotal: 6.48s\tremaining: 11s\n",
      "370:\tlearn: 0.1006192\ttest: 0.2049614\tbest: 0.2048844 (369)\ttotal: 6.51s\tremaining: 11s\n",
      "371:\tlearn: 0.1004219\ttest: 0.2052134\tbest: 0.2048844 (369)\ttotal: 6.53s\tremaining: 11s\n",
      "372:\tlearn: 0.1002893\ttest: 0.2050571\tbest: 0.2048844 (369)\ttotal: 6.56s\tremaining: 11s\n",
      "373:\tlearn: 0.1000661\ttest: 0.2048940\tbest: 0.2048844 (369)\ttotal: 6.58s\tremaining: 11s\n",
      "374:\tlearn: 0.0997841\ttest: 0.2045077\tbest: 0.2045077 (374)\ttotal: 6.58s\tremaining: 11s\n",
      "375:\tlearn: 0.0995598\ttest: 0.2046018\tbest: 0.2045077 (374)\ttotal: 6.6s\tremaining: 10.9s\n",
      "376:\tlearn: 0.0993128\ttest: 0.2044138\tbest: 0.2044138 (376)\ttotal: 6.61s\tremaining: 10.9s\n",
      "377:\tlearn: 0.0990512\ttest: 0.2042342\tbest: 0.2042342 (377)\ttotal: 6.63s\tremaining: 10.9s\n",
      "378:\tlearn: 0.0987123\ttest: 0.2039230\tbest: 0.2039230 (378)\ttotal: 6.64s\tremaining: 10.9s\n",
      "379:\tlearn: 0.0984776\ttest: 0.2040551\tbest: 0.2039230 (378)\ttotal: 6.66s\tremaining: 10.9s\n",
      "380:\tlearn: 0.0982956\ttest: 0.2040586\tbest: 0.2039230 (378)\ttotal: 6.67s\tremaining: 10.8s\n",
      "381:\tlearn: 0.0981142\ttest: 0.2041117\tbest: 0.2039230 (378)\ttotal: 6.69s\tremaining: 10.8s\n",
      "382:\tlearn: 0.0978799\ttest: 0.2041804\tbest: 0.2039230 (378)\ttotal: 6.7s\tremaining: 10.8s\n",
      "383:\tlearn: 0.0976587\ttest: 0.2041641\tbest: 0.2039230 (378)\ttotal: 6.72s\tremaining: 10.8s\n",
      "384:\tlearn: 0.0974592\ttest: 0.2038782\tbest: 0.2038782 (384)\ttotal: 6.73s\tremaining: 10.8s\n",
      "385:\tlearn: 0.0972739\ttest: 0.2038804\tbest: 0.2038782 (384)\ttotal: 6.75s\tremaining: 10.7s\n",
      "386:\tlearn: 0.0971116\ttest: 0.2037126\tbest: 0.2037126 (386)\ttotal: 6.77s\tremaining: 10.7s\n",
      "387:\tlearn: 0.0969885\ttest: 0.2037358\tbest: 0.2037126 (386)\ttotal: 6.78s\tremaining: 10.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388:\tlearn: 0.0967582\ttest: 0.2036127\tbest: 0.2036127 (388)\ttotal: 6.79s\tremaining: 10.7s\n",
      "389:\tlearn: 0.0965262\ttest: 0.2036709\tbest: 0.2036127 (388)\ttotal: 6.81s\tremaining: 10.6s\n",
      "390:\tlearn: 0.0963683\ttest: 0.2035555\tbest: 0.2035555 (390)\ttotal: 6.82s\tremaining: 10.6s\n",
      "391:\tlearn: 0.0962184\ttest: 0.2035536\tbest: 0.2035536 (391)\ttotal: 6.83s\tremaining: 10.6s\n",
      "392:\tlearn: 0.0959652\ttest: 0.2034698\tbest: 0.2034698 (392)\ttotal: 6.84s\tremaining: 10.6s\n",
      "393:\tlearn: 0.0958087\ttest: 0.2035422\tbest: 0.2034698 (392)\ttotal: 6.86s\tremaining: 10.5s\n",
      "394:\tlearn: 0.0956353\ttest: 0.2036139\tbest: 0.2034698 (392)\ttotal: 6.87s\tremaining: 10.5s\n",
      "395:\tlearn: 0.0954303\ttest: 0.2036810\tbest: 0.2034698 (392)\ttotal: 6.88s\tremaining: 10.5s\n",
      "396:\tlearn: 0.0951723\ttest: 0.2036294\tbest: 0.2034698 (392)\ttotal: 6.89s\tremaining: 10.5s\n",
      "397:\tlearn: 0.0949784\ttest: 0.2034841\tbest: 0.2034698 (392)\ttotal: 6.91s\tremaining: 10.4s\n",
      "398:\tlearn: 0.0947173\ttest: 0.2035383\tbest: 0.2034698 (392)\ttotal: 6.92s\tremaining: 10.4s\n",
      "399:\tlearn: 0.0945417\ttest: 0.2037529\tbest: 0.2034698 (392)\ttotal: 6.93s\tremaining: 10.4s\n",
      "400:\tlearn: 0.0943506\ttest: 0.2035960\tbest: 0.2034698 (392)\ttotal: 6.94s\tremaining: 10.4s\n",
      "401:\tlearn: 0.0941864\ttest: 0.2036369\tbest: 0.2034698 (392)\ttotal: 6.96s\tremaining: 10.3s\n",
      "402:\tlearn: 0.0939306\ttest: 0.2036139\tbest: 0.2034698 (392)\ttotal: 6.97s\tremaining: 10.3s\n",
      "403:\tlearn: 0.0937566\ttest: 0.2035490\tbest: 0.2034698 (392)\ttotal: 6.98s\tremaining: 10.3s\n",
      "404:\tlearn: 0.0935457\ttest: 0.2032918\tbest: 0.2032918 (404)\ttotal: 6.99s\tremaining: 10.3s\n",
      "405:\tlearn: 0.0933572\ttest: 0.2032019\tbest: 0.2032019 (405)\ttotal: 7s\tremaining: 10.2s\n",
      "406:\tlearn: 0.0932011\ttest: 0.2031360\tbest: 0.2031360 (406)\ttotal: 7.02s\tremaining: 10.2s\n",
      "407:\tlearn: 0.0929820\ttest: 0.2031236\tbest: 0.2031236 (407)\ttotal: 7.03s\tremaining: 10.2s\n",
      "408:\tlearn: 0.0927808\ttest: 0.2033175\tbest: 0.2031236 (407)\ttotal: 7.04s\tremaining: 10.2s\n",
      "409:\tlearn: 0.0925596\ttest: 0.2033478\tbest: 0.2031236 (407)\ttotal: 7.05s\tremaining: 10.2s\n",
      "410:\tlearn: 0.0924152\ttest: 0.2033067\tbest: 0.2031236 (407)\ttotal: 7.07s\tremaining: 10.1s\n",
      "411:\tlearn: 0.0922324\ttest: 0.2033634\tbest: 0.2031236 (407)\ttotal: 7.08s\tremaining: 10.1s\n",
      "412:\tlearn: 0.0919474\ttest: 0.2035909\tbest: 0.2031236 (407)\ttotal: 7.09s\tremaining: 10.1s\n",
      "413:\tlearn: 0.0917040\ttest: 0.2037298\tbest: 0.2031236 (407)\ttotal: 7.11s\tremaining: 10.1s\n",
      "414:\tlearn: 0.0915300\ttest: 0.2034066\tbest: 0.2031236 (407)\ttotal: 7.12s\tremaining: 10s\n",
      "415:\tlearn: 0.0913861\ttest: 0.2035130\tbest: 0.2031236 (407)\ttotal: 7.14s\tremaining: 10s\n",
      "416:\tlearn: 0.0911722\ttest: 0.2033787\tbest: 0.2031236 (407)\ttotal: 7.15s\tremaining: 10s\n",
      "417:\tlearn: 0.0909888\ttest: 0.2032603\tbest: 0.2031236 (407)\ttotal: 7.17s\tremaining: 9.98s\n",
      "418:\tlearn: 0.0908204\ttest: 0.2032439\tbest: 0.2031236 (407)\ttotal: 7.18s\tremaining: 9.96s\n",
      "419:\tlearn: 0.0906257\ttest: 0.2031336\tbest: 0.2031236 (407)\ttotal: 7.2s\tremaining: 9.94s\n",
      "420:\tlearn: 0.0904715\ttest: 0.2030637\tbest: 0.2030637 (420)\ttotal: 7.22s\tremaining: 9.93s\n",
      "421:\tlearn: 0.0902678\ttest: 0.2030576\tbest: 0.2030576 (421)\ttotal: 7.23s\tremaining: 9.91s\n",
      "422:\tlearn: 0.0901112\ttest: 0.2030824\tbest: 0.2030576 (421)\ttotal: 7.25s\tremaining: 9.89s\n",
      "423:\tlearn: 0.0898511\ttest: 0.2028961\tbest: 0.2028961 (423)\ttotal: 7.27s\tremaining: 9.87s\n",
      "424:\tlearn: 0.0896899\ttest: 0.2027508\tbest: 0.2027508 (424)\ttotal: 7.28s\tremaining: 9.85s\n",
      "425:\tlearn: 0.0895493\ttest: 0.2027238\tbest: 0.2027238 (425)\ttotal: 7.3s\tremaining: 9.84s\n",
      "426:\tlearn: 0.0893749\ttest: 0.2027671\tbest: 0.2027238 (425)\ttotal: 7.32s\tremaining: 9.82s\n",
      "427:\tlearn: 0.0891774\ttest: 0.2027847\tbest: 0.2027238 (425)\ttotal: 7.33s\tremaining: 9.8s\n",
      "428:\tlearn: 0.0889437\ttest: 0.2028309\tbest: 0.2027238 (425)\ttotal: 7.34s\tremaining: 9.78s\n",
      "429:\tlearn: 0.0887894\ttest: 0.2028306\tbest: 0.2027238 (425)\ttotal: 7.36s\tremaining: 9.75s\n",
      "430:\tlearn: 0.0886049\ttest: 0.2029167\tbest: 0.2027238 (425)\ttotal: 7.37s\tremaining: 9.73s\n",
      "431:\tlearn: 0.0884754\ttest: 0.2030614\tbest: 0.2027238 (425)\ttotal: 7.39s\tremaining: 9.71s\n",
      "432:\tlearn: 0.0882882\ttest: 0.2029038\tbest: 0.2027238 (425)\ttotal: 7.4s\tremaining: 9.69s\n",
      "433:\tlearn: 0.0881295\ttest: 0.2028661\tbest: 0.2027238 (425)\ttotal: 7.42s\tremaining: 9.67s\n",
      "434:\tlearn: 0.0879745\ttest: 0.2027837\tbest: 0.2027238 (425)\ttotal: 7.43s\tremaining: 9.66s\n",
      "435:\tlearn: 0.0877533\ttest: 0.2027085\tbest: 0.2027085 (435)\ttotal: 7.45s\tremaining: 9.64s\n",
      "436:\tlearn: 0.0875648\ttest: 0.2027428\tbest: 0.2027085 (435)\ttotal: 7.47s\tremaining: 9.62s\n",
      "437:\tlearn: 0.0873467\ttest: 0.2029269\tbest: 0.2027085 (435)\ttotal: 7.48s\tremaining: 9.6s\n",
      "438:\tlearn: 0.0871764\ttest: 0.2029335\tbest: 0.2027085 (435)\ttotal: 7.5s\tremaining: 9.58s\n",
      "439:\tlearn: 0.0870471\ttest: 0.2030046\tbest: 0.2027085 (435)\ttotal: 7.51s\tremaining: 9.56s\n",
      "440:\tlearn: 0.0868832\ttest: 0.2030544\tbest: 0.2027085 (435)\ttotal: 7.53s\tremaining: 9.54s\n",
      "441:\tlearn: 0.0866895\ttest: 0.2030395\tbest: 0.2027085 (435)\ttotal: 7.54s\tremaining: 9.52s\n",
      "442:\tlearn: 0.0865318\ttest: 0.2029597\tbest: 0.2027085 (435)\ttotal: 7.55s\tremaining: 9.5s\n",
      "443:\tlearn: 0.0863703\ttest: 0.2028930\tbest: 0.2027085 (435)\ttotal: 7.57s\tremaining: 9.47s\n",
      "444:\tlearn: 0.0861545\ttest: 0.2028190\tbest: 0.2027085 (435)\ttotal: 7.58s\tremaining: 9.45s\n",
      "445:\tlearn: 0.0860128\ttest: 0.2027930\tbest: 0.2027085 (435)\ttotal: 7.59s\tremaining: 9.43s\n",
      "446:\tlearn: 0.0858286\ttest: 0.2028002\tbest: 0.2027085 (435)\ttotal: 7.6s\tremaining: 9.41s\n",
      "447:\tlearn: 0.0856719\ttest: 0.2025848\tbest: 0.2025848 (447)\ttotal: 7.62s\tremaining: 9.38s\n",
      "448:\tlearn: 0.0854097\ttest: 0.2024155\tbest: 0.2024155 (448)\ttotal: 7.63s\tremaining: 9.36s\n",
      "449:\tlearn: 0.0852113\ttest: 0.2024351\tbest: 0.2024155 (448)\ttotal: 7.64s\tremaining: 9.34s\n",
      "450:\tlearn: 0.0850763\ttest: 0.2024446\tbest: 0.2024155 (448)\ttotal: 7.65s\tremaining: 9.32s\n",
      "451:\tlearn: 0.0849595\ttest: 0.2022885\tbest: 0.2022885 (451)\ttotal: 7.66s\tremaining: 9.29s\n",
      "452:\tlearn: 0.0848548\ttest: 0.2023180\tbest: 0.2022885 (451)\ttotal: 7.68s\tremaining: 9.27s\n",
      "453:\tlearn: 0.0847172\ttest: 0.2023501\tbest: 0.2022885 (451)\ttotal: 7.69s\tremaining: 9.25s\n",
      "454:\tlearn: 0.0845121\ttest: 0.2021778\tbest: 0.2021778 (454)\ttotal: 7.7s\tremaining: 9.23s\n",
      "455:\tlearn: 0.0843464\ttest: 0.2021304\tbest: 0.2021304 (455)\ttotal: 7.71s\tremaining: 9.2s\n",
      "456:\tlearn: 0.0841184\ttest: 0.2019584\tbest: 0.2019584 (456)\ttotal: 7.73s\tremaining: 9.18s\n",
      "457:\tlearn: 0.0839022\ttest: 0.2020188\tbest: 0.2019584 (456)\ttotal: 7.74s\tremaining: 9.16s\n",
      "458:\tlearn: 0.0837748\ttest: 0.2020939\tbest: 0.2019584 (456)\ttotal: 7.75s\tremaining: 9.13s\n",
      "459:\tlearn: 0.0836358\ttest: 0.2020457\tbest: 0.2019584 (456)\ttotal: 7.76s\tremaining: 9.11s\n",
      "460:\tlearn: 0.0834891\ttest: 0.2020899\tbest: 0.2019584 (456)\ttotal: 7.77s\tremaining: 9.09s\n",
      "461:\tlearn: 0.0832800\ttest: 0.2021059\tbest: 0.2019584 (456)\ttotal: 7.78s\tremaining: 9.06s\n",
      "462:\tlearn: 0.0831042\ttest: 0.2019427\tbest: 0.2019427 (462)\ttotal: 7.79s\tremaining: 9.04s\n",
      "463:\tlearn: 0.0828688\ttest: 0.2017534\tbest: 0.2017534 (463)\ttotal: 7.8s\tremaining: 9.01s\n",
      "464:\tlearn: 0.0827181\ttest: 0.2017785\tbest: 0.2017534 (463)\ttotal: 7.82s\tremaining: 8.99s\n",
      "465:\tlearn: 0.0825056\ttest: 0.2018552\tbest: 0.2017534 (463)\ttotal: 7.83s\tremaining: 8.97s\n",
      "466:\tlearn: 0.0822622\ttest: 0.2018234\tbest: 0.2017534 (463)\ttotal: 7.84s\tremaining: 8.95s\n",
      "467:\tlearn: 0.0820731\ttest: 0.2017945\tbest: 0.2017534 (463)\ttotal: 7.85s\tremaining: 8.92s\n",
      "468:\tlearn: 0.0819633\ttest: 0.2016505\tbest: 0.2016505 (468)\ttotal: 7.86s\tremaining: 8.9s\n",
      "469:\tlearn: 0.0817374\ttest: 0.2016656\tbest: 0.2016505 (468)\ttotal: 7.87s\tremaining: 8.88s\n",
      "470:\tlearn: 0.0815653\ttest: 0.2018791\tbest: 0.2016505 (468)\ttotal: 7.88s\tremaining: 8.86s\n",
      "471:\tlearn: 0.0813840\ttest: 0.2019178\tbest: 0.2016505 (468)\ttotal: 7.9s\tremaining: 8.83s\n",
      "472:\tlearn: 0.0812270\ttest: 0.2016459\tbest: 0.2016459 (472)\ttotal: 7.91s\tremaining: 8.81s\n",
      "473:\tlearn: 0.0810182\ttest: 0.2015998\tbest: 0.2015998 (473)\ttotal: 7.92s\tremaining: 8.79s\n",
      "474:\tlearn: 0.0808099\ttest: 0.2015977\tbest: 0.2015977 (474)\ttotal: 7.93s\tremaining: 8.77s\n",
      "475:\tlearn: 0.0806377\ttest: 0.2016456\tbest: 0.2015977 (474)\ttotal: 7.95s\tremaining: 8.75s\n",
      "476:\tlearn: 0.0805085\ttest: 0.2015292\tbest: 0.2015292 (476)\ttotal: 7.96s\tremaining: 8.72s\n",
      "477:\tlearn: 0.0803874\ttest: 0.2016084\tbest: 0.2015292 (476)\ttotal: 7.97s\tremaining: 8.7s\n",
      "478:\tlearn: 0.0802099\ttest: 0.2015072\tbest: 0.2015072 (478)\ttotal: 7.98s\tremaining: 8.68s\n",
      "479:\tlearn: 0.0800586\ttest: 0.2015662\tbest: 0.2015072 (478)\ttotal: 7.99s\tremaining: 8.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480:\tlearn: 0.0798872\ttest: 0.2015010\tbest: 0.2015010 (480)\ttotal: 8.01s\tremaining: 8.64s\n",
      "481:\tlearn: 0.0796965\ttest: 0.2015882\tbest: 0.2015010 (480)\ttotal: 8.02s\tremaining: 8.62s\n",
      "482:\tlearn: 0.0795630\ttest: 0.2015307\tbest: 0.2015010 (480)\ttotal: 8.03s\tremaining: 8.6s\n",
      "483:\tlearn: 0.0794437\ttest: 0.2015904\tbest: 0.2015010 (480)\ttotal: 8.04s\tremaining: 8.58s\n",
      "484:\tlearn: 0.0792385\ttest: 0.2014489\tbest: 0.2014489 (484)\ttotal: 8.06s\tremaining: 8.55s\n",
      "485:\tlearn: 0.0790899\ttest: 0.2015613\tbest: 0.2014489 (484)\ttotal: 8.07s\tremaining: 8.53s\n",
      "486:\tlearn: 0.0789272\ttest: 0.2014133\tbest: 0.2014133 (486)\ttotal: 8.08s\tremaining: 8.51s\n",
      "487:\tlearn: 0.0788139\ttest: 0.2013732\tbest: 0.2013732 (487)\ttotal: 8.09s\tremaining: 8.49s\n",
      "488:\tlearn: 0.0786984\ttest: 0.2013810\tbest: 0.2013732 (487)\ttotal: 8.1s\tremaining: 8.46s\n",
      "489:\tlearn: 0.0784827\ttest: 0.2014014\tbest: 0.2013732 (487)\ttotal: 8.11s\tremaining: 8.44s\n",
      "490:\tlearn: 0.0783014\ttest: 0.2012525\tbest: 0.2012525 (490)\ttotal: 8.12s\tremaining: 8.42s\n",
      "491:\tlearn: 0.0780938\ttest: 0.2013033\tbest: 0.2012525 (490)\ttotal: 8.13s\tremaining: 8.39s\n",
      "492:\tlearn: 0.0779957\ttest: 0.2012173\tbest: 0.2012173 (492)\ttotal: 8.14s\tremaining: 8.37s\n",
      "493:\tlearn: 0.0779035\ttest: 0.2012381\tbest: 0.2012173 (492)\ttotal: 8.15s\tremaining: 8.35s\n",
      "494:\tlearn: 0.0777159\ttest: 0.2014490\tbest: 0.2012173 (492)\ttotal: 8.16s\tremaining: 8.32s\n",
      "495:\tlearn: 0.0775328\ttest: 0.2014246\tbest: 0.2012173 (492)\ttotal: 8.17s\tremaining: 8.3s\n",
      "496:\tlearn: 0.0773570\ttest: 0.2015723\tbest: 0.2012173 (492)\ttotal: 8.18s\tremaining: 8.28s\n",
      "497:\tlearn: 0.0771721\ttest: 0.2014485\tbest: 0.2012173 (492)\ttotal: 8.19s\tremaining: 8.26s\n",
      "498:\tlearn: 0.0770453\ttest: 0.2013398\tbest: 0.2012173 (492)\ttotal: 8.2s\tremaining: 8.23s\n",
      "499:\tlearn: 0.0768927\ttest: 0.2014726\tbest: 0.2012173 (492)\ttotal: 8.21s\tremaining: 8.21s\n",
      "500:\tlearn: 0.0766821\ttest: 0.2013059\tbest: 0.2012173 (492)\ttotal: 8.22s\tremaining: 8.19s\n",
      "501:\tlearn: 0.0765351\ttest: 0.2013240\tbest: 0.2012173 (492)\ttotal: 8.23s\tremaining: 8.17s\n",
      "502:\tlearn: 0.0764369\ttest: 0.2013282\tbest: 0.2012173 (492)\ttotal: 8.24s\tremaining: 8.14s\n",
      "503:\tlearn: 0.0762476\ttest: 0.2011528\tbest: 0.2011528 (503)\ttotal: 8.25s\tremaining: 8.12s\n",
      "504:\tlearn: 0.0760281\ttest: 0.2009221\tbest: 0.2009221 (504)\ttotal: 8.26s\tremaining: 8.1s\n",
      "505:\tlearn: 0.0758843\ttest: 0.2008017\tbest: 0.2008017 (505)\ttotal: 8.27s\tremaining: 8.08s\n",
      "506:\tlearn: 0.0757293\ttest: 0.2007169\tbest: 0.2007169 (506)\ttotal: 8.28s\tremaining: 8.05s\n",
      "507:\tlearn: 0.0756106\ttest: 0.2008168\tbest: 0.2007169 (506)\ttotal: 8.3s\tremaining: 8.04s\n",
      "508:\tlearn: 0.0754597\ttest: 0.2009012\tbest: 0.2007169 (506)\ttotal: 8.31s\tremaining: 8.01s\n",
      "509:\tlearn: 0.0752702\ttest: 0.2008048\tbest: 0.2007169 (506)\ttotal: 8.32s\tremaining: 7.99s\n",
      "510:\tlearn: 0.0750599\ttest: 0.2007874\tbest: 0.2007169 (506)\ttotal: 8.33s\tremaining: 7.97s\n",
      "511:\tlearn: 0.0749154\ttest: 0.2008688\tbest: 0.2007169 (506)\ttotal: 8.34s\tremaining: 7.95s\n",
      "512:\tlearn: 0.0747447\ttest: 0.2009201\tbest: 0.2007169 (506)\ttotal: 8.35s\tremaining: 7.92s\n",
      "513:\tlearn: 0.0745912\ttest: 0.2010447\tbest: 0.2007169 (506)\ttotal: 8.36s\tremaining: 7.91s\n",
      "514:\tlearn: 0.0744464\ttest: 0.2010002\tbest: 0.2007169 (506)\ttotal: 8.38s\tremaining: 7.89s\n",
      "515:\tlearn: 0.0743225\ttest: 0.2010295\tbest: 0.2007169 (506)\ttotal: 8.39s\tremaining: 7.87s\n",
      "516:\tlearn: 0.0741614\ttest: 0.2010371\tbest: 0.2007169 (506)\ttotal: 8.4s\tremaining: 7.84s\n",
      "517:\tlearn: 0.0739907\ttest: 0.2010443\tbest: 0.2007169 (506)\ttotal: 8.41s\tremaining: 7.83s\n",
      "518:\tlearn: 0.0738201\ttest: 0.2006286\tbest: 0.2006286 (518)\ttotal: 8.43s\tremaining: 7.81s\n",
      "519:\tlearn: 0.0736634\ttest: 0.2006141\tbest: 0.2006141 (519)\ttotal: 8.43s\tremaining: 7.79s\n",
      "520:\tlearn: 0.0735057\ttest: 0.2006031\tbest: 0.2006031 (520)\ttotal: 8.44s\tremaining: 7.76s\n",
      "521:\tlearn: 0.0733525\ttest: 0.2005894\tbest: 0.2005894 (521)\ttotal: 8.45s\tremaining: 7.74s\n",
      "522:\tlearn: 0.0732386\ttest: 0.2005417\tbest: 0.2005417 (522)\ttotal: 8.46s\tremaining: 7.72s\n",
      "523:\tlearn: 0.0730593\ttest: 0.2003504\tbest: 0.2003504 (523)\ttotal: 8.47s\tremaining: 7.69s\n",
      "524:\tlearn: 0.0729428\ttest: 0.2003738\tbest: 0.2003504 (523)\ttotal: 8.48s\tremaining: 7.67s\n",
      "525:\tlearn: 0.0728100\ttest: 0.2003985\tbest: 0.2003504 (523)\ttotal: 8.49s\tremaining: 7.65s\n",
      "526:\tlearn: 0.0726576\ttest: 0.2004832\tbest: 0.2003504 (523)\ttotal: 8.5s\tremaining: 7.63s\n",
      "527:\tlearn: 0.0725138\ttest: 0.2003866\tbest: 0.2003504 (523)\ttotal: 8.51s\tremaining: 7.61s\n",
      "528:\tlearn: 0.0724283\ttest: 0.2003666\tbest: 0.2003504 (523)\ttotal: 8.52s\tremaining: 7.58s\n",
      "529:\tlearn: 0.0723215\ttest: 0.2004097\tbest: 0.2003504 (523)\ttotal: 8.54s\tremaining: 7.57s\n",
      "530:\tlearn: 0.0721809\ttest: 0.2004297\tbest: 0.2003504 (523)\ttotal: 8.55s\tremaining: 7.55s\n",
      "531:\tlearn: 0.0719750\ttest: 0.2003707\tbest: 0.2003504 (523)\ttotal: 8.56s\tremaining: 7.53s\n",
      "532:\tlearn: 0.0718417\ttest: 0.2002255\tbest: 0.2002255 (532)\ttotal: 8.58s\tremaining: 7.52s\n",
      "533:\tlearn: 0.0717297\ttest: 0.2001638\tbest: 0.2001638 (533)\ttotal: 8.6s\tremaining: 7.5s\n",
      "534:\tlearn: 0.0715643\ttest: 0.2002607\tbest: 0.2001638 (533)\ttotal: 8.61s\tremaining: 7.48s\n",
      "535:\tlearn: 0.0714485\ttest: 0.2001108\tbest: 0.2001108 (535)\ttotal: 8.63s\tremaining: 7.47s\n",
      "536:\tlearn: 0.0713096\ttest: 0.2001238\tbest: 0.2001108 (535)\ttotal: 8.64s\tremaining: 7.45s\n",
      "537:\tlearn: 0.0712034\ttest: 0.2001347\tbest: 0.2001108 (535)\ttotal: 8.66s\tremaining: 7.43s\n",
      "538:\tlearn: 0.0710315\ttest: 0.2001256\tbest: 0.2001108 (535)\ttotal: 8.67s\tremaining: 7.42s\n",
      "539:\tlearn: 0.0709025\ttest: 0.2000718\tbest: 0.2000718 (539)\ttotal: 8.69s\tremaining: 7.4s\n",
      "540:\tlearn: 0.0706825\ttest: 0.2000656\tbest: 0.2000656 (540)\ttotal: 8.7s\tremaining: 7.38s\n",
      "541:\tlearn: 0.0705364\ttest: 0.1999673\tbest: 0.1999673 (541)\ttotal: 8.71s\tremaining: 7.36s\n",
      "542:\tlearn: 0.0703773\ttest: 0.2000476\tbest: 0.1999673 (541)\ttotal: 8.73s\tremaining: 7.34s\n",
      "543:\tlearn: 0.0702218\ttest: 0.2000011\tbest: 0.1999673 (541)\ttotal: 8.74s\tremaining: 7.33s\n",
      "544:\tlearn: 0.0700724\ttest: 0.2000304\tbest: 0.1999673 (541)\ttotal: 8.76s\tremaining: 7.31s\n",
      "545:\tlearn: 0.0699127\ttest: 0.1998079\tbest: 0.1998079 (545)\ttotal: 8.77s\tremaining: 7.29s\n",
      "546:\tlearn: 0.0697153\ttest: 0.1998881\tbest: 0.1998079 (545)\ttotal: 8.79s\tremaining: 7.28s\n",
      "547:\tlearn: 0.0695942\ttest: 0.1999008\tbest: 0.1998079 (545)\ttotal: 8.8s\tremaining: 7.26s\n",
      "548:\tlearn: 0.0694320\ttest: 0.1996582\tbest: 0.1996582 (548)\ttotal: 8.82s\tremaining: 7.25s\n",
      "549:\tlearn: 0.0693297\ttest: 0.1995750\tbest: 0.1995750 (549)\ttotal: 8.84s\tremaining: 7.23s\n",
      "550:\tlearn: 0.0692065\ttest: 0.1995624\tbest: 0.1995624 (550)\ttotal: 8.85s\tremaining: 7.21s\n",
      "551:\tlearn: 0.0690921\ttest: 0.1995537\tbest: 0.1995537 (551)\ttotal: 8.87s\tremaining: 7.2s\n",
      "552:\tlearn: 0.0689379\ttest: 0.1996063\tbest: 0.1995537 (551)\ttotal: 8.88s\tremaining: 7.18s\n",
      "553:\tlearn: 0.0688039\ttest: 0.1995506\tbest: 0.1995506 (553)\ttotal: 8.9s\tremaining: 7.16s\n",
      "554:\tlearn: 0.0686520\ttest: 0.1995130\tbest: 0.1995130 (554)\ttotal: 8.91s\tremaining: 7.15s\n",
      "555:\tlearn: 0.0685238\ttest: 0.1995733\tbest: 0.1995130 (554)\ttotal: 8.93s\tremaining: 7.13s\n",
      "556:\tlearn: 0.0683450\ttest: 0.1994290\tbest: 0.1994290 (556)\ttotal: 8.94s\tremaining: 7.11s\n",
      "557:\tlearn: 0.0682334\ttest: 0.1994749\tbest: 0.1994290 (556)\ttotal: 8.96s\tremaining: 7.09s\n",
      "558:\tlearn: 0.0681348\ttest: 0.1995092\tbest: 0.1994290 (556)\ttotal: 8.97s\tremaining: 7.08s\n",
      "559:\tlearn: 0.0679888\ttest: 0.1994452\tbest: 0.1994290 (556)\ttotal: 8.98s\tremaining: 7.06s\n",
      "560:\tlearn: 0.0678256\ttest: 0.1993843\tbest: 0.1993843 (560)\ttotal: 9s\tremaining: 7.04s\n",
      "561:\tlearn: 0.0676993\ttest: 0.1993350\tbest: 0.1993350 (561)\ttotal: 9.02s\tremaining: 7.03s\n",
      "562:\tlearn: 0.0675734\ttest: 0.1993094\tbest: 0.1993094 (562)\ttotal: 9.03s\tremaining: 7.01s\n",
      "563:\tlearn: 0.0674978\ttest: 0.1992224\tbest: 0.1992224 (563)\ttotal: 9.05s\tremaining: 6.99s\n",
      "564:\tlearn: 0.0674156\ttest: 0.1991923\tbest: 0.1991923 (564)\ttotal: 9.06s\tremaining: 6.98s\n",
      "565:\tlearn: 0.0673023\ttest: 0.1991397\tbest: 0.1991397 (565)\ttotal: 9.07s\tremaining: 6.96s\n",
      "566:\tlearn: 0.0671968\ttest: 0.1990105\tbest: 0.1990105 (566)\ttotal: 9.09s\tremaining: 6.94s\n",
      "567:\tlearn: 0.0670490\ttest: 0.1991200\tbest: 0.1990105 (566)\ttotal: 9.11s\tremaining: 6.92s\n",
      "568:\tlearn: 0.0669288\ttest: 0.1989646\tbest: 0.1989646 (568)\ttotal: 9.12s\tremaining: 6.91s\n",
      "569:\tlearn: 0.0667445\ttest: 0.1990331\tbest: 0.1989646 (568)\ttotal: 9.14s\tremaining: 6.89s\n",
      "570:\tlearn: 0.0666384\ttest: 0.1989974\tbest: 0.1989646 (568)\ttotal: 9.15s\tremaining: 6.88s\n",
      "571:\tlearn: 0.0664747\ttest: 0.1988394\tbest: 0.1988394 (571)\ttotal: 9.17s\tremaining: 6.86s\n",
      "572:\tlearn: 0.0663404\ttest: 0.1987678\tbest: 0.1987678 (572)\ttotal: 9.19s\tremaining: 6.85s\n",
      "573:\tlearn: 0.0661870\ttest: 0.1988265\tbest: 0.1987678 (572)\ttotal: 9.2s\tremaining: 6.83s\n",
      "574:\tlearn: 0.0660771\ttest: 0.1987450\tbest: 0.1987450 (574)\ttotal: 9.21s\tremaining: 6.81s\n",
      "575:\tlearn: 0.0659489\ttest: 0.1986583\tbest: 0.1986583 (575)\ttotal: 9.23s\tremaining: 6.79s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576:\tlearn: 0.0657891\ttest: 0.1987706\tbest: 0.1986583 (575)\ttotal: 9.25s\tremaining: 6.78s\n",
      "577:\tlearn: 0.0656829\ttest: 0.1987793\tbest: 0.1986583 (575)\ttotal: 9.26s\tremaining: 6.76s\n",
      "578:\tlearn: 0.0655503\ttest: 0.1987281\tbest: 0.1986583 (575)\ttotal: 9.28s\tremaining: 6.75s\n",
      "579:\tlearn: 0.0654326\ttest: 0.1987309\tbest: 0.1986583 (575)\ttotal: 9.3s\tremaining: 6.73s\n",
      "580:\tlearn: 0.0653087\ttest: 0.1986370\tbest: 0.1986370 (580)\ttotal: 9.31s\tremaining: 6.71s\n",
      "581:\tlearn: 0.0651735\ttest: 0.1986026\tbest: 0.1986026 (581)\ttotal: 9.33s\tremaining: 6.7s\n",
      "582:\tlearn: 0.0650857\ttest: 0.1986022\tbest: 0.1986022 (582)\ttotal: 9.34s\tremaining: 6.68s\n",
      "583:\tlearn: 0.0649964\ttest: 0.1985450\tbest: 0.1985450 (583)\ttotal: 9.36s\tremaining: 6.66s\n",
      "584:\tlearn: 0.0648877\ttest: 0.1983474\tbest: 0.1983474 (584)\ttotal: 9.37s\tremaining: 6.65s\n",
      "585:\tlearn: 0.0647759\ttest: 0.1982338\tbest: 0.1982338 (585)\ttotal: 9.38s\tremaining: 6.63s\n",
      "586:\tlearn: 0.0646469\ttest: 0.1982134\tbest: 0.1982134 (586)\ttotal: 9.4s\tremaining: 6.61s\n",
      "587:\tlearn: 0.0645349\ttest: 0.1981427\tbest: 0.1981427 (587)\ttotal: 9.41s\tremaining: 6.6s\n",
      "588:\tlearn: 0.0644454\ttest: 0.1981873\tbest: 0.1981427 (587)\ttotal: 9.43s\tremaining: 6.58s\n",
      "589:\tlearn: 0.0643396\ttest: 0.1981668\tbest: 0.1981427 (587)\ttotal: 9.44s\tremaining: 6.56s\n",
      "590:\tlearn: 0.0642414\ttest: 0.1981239\tbest: 0.1981239 (590)\ttotal: 9.46s\tremaining: 6.55s\n",
      "591:\tlearn: 0.0641005\ttest: 0.1982806\tbest: 0.1981239 (590)\ttotal: 9.48s\tremaining: 6.53s\n",
      "592:\tlearn: 0.0639388\ttest: 0.1982751\tbest: 0.1981239 (590)\ttotal: 9.49s\tremaining: 6.51s\n",
      "593:\tlearn: 0.0638124\ttest: 0.1982384\tbest: 0.1981239 (590)\ttotal: 9.51s\tremaining: 6.5s\n",
      "594:\tlearn: 0.0636637\ttest: 0.1981386\tbest: 0.1981239 (590)\ttotal: 9.53s\tremaining: 6.48s\n",
      "595:\tlearn: 0.0635863\ttest: 0.1981312\tbest: 0.1981239 (590)\ttotal: 9.54s\tremaining: 6.47s\n",
      "596:\tlearn: 0.0634441\ttest: 0.1982831\tbest: 0.1981239 (590)\ttotal: 9.56s\tremaining: 6.45s\n",
      "597:\tlearn: 0.0633468\ttest: 0.1983435\tbest: 0.1981239 (590)\ttotal: 9.57s\tremaining: 6.43s\n",
      "598:\tlearn: 0.0632285\ttest: 0.1982847\tbest: 0.1981239 (590)\ttotal: 9.59s\tremaining: 6.42s\n",
      "599:\tlearn: 0.0631496\ttest: 0.1982053\tbest: 0.1981239 (590)\ttotal: 9.6s\tremaining: 6.4s\n",
      "600:\tlearn: 0.0630019\ttest: 0.1982414\tbest: 0.1981239 (590)\ttotal: 9.62s\tremaining: 6.38s\n",
      "601:\tlearn: 0.0628683\ttest: 0.1983194\tbest: 0.1981239 (590)\ttotal: 9.63s\tremaining: 6.37s\n",
      "602:\tlearn: 0.0627556\ttest: 0.1983121\tbest: 0.1981239 (590)\ttotal: 9.65s\tremaining: 6.35s\n",
      "603:\tlearn: 0.0626183\ttest: 0.1980888\tbest: 0.1980888 (603)\ttotal: 9.66s\tremaining: 6.33s\n",
      "604:\tlearn: 0.0624789\ttest: 0.1981946\tbest: 0.1980888 (603)\ttotal: 9.68s\tremaining: 6.32s\n",
      "605:\tlearn: 0.0623653\ttest: 0.1984403\tbest: 0.1980888 (603)\ttotal: 9.69s\tremaining: 6.3s\n",
      "606:\tlearn: 0.0622181\ttest: 0.1984050\tbest: 0.1980888 (603)\ttotal: 9.71s\tremaining: 6.29s\n",
      "607:\tlearn: 0.0621195\ttest: 0.1984402\tbest: 0.1980888 (603)\ttotal: 9.72s\tremaining: 6.27s\n",
      "608:\tlearn: 0.0620127\ttest: 0.1983927\tbest: 0.1980888 (603)\ttotal: 9.74s\tremaining: 6.25s\n",
      "609:\tlearn: 0.0618757\ttest: 0.1983902\tbest: 0.1980888 (603)\ttotal: 9.75s\tremaining: 6.24s\n",
      "610:\tlearn: 0.0617495\ttest: 0.1983637\tbest: 0.1980888 (603)\ttotal: 9.77s\tremaining: 6.22s\n",
      "611:\tlearn: 0.0616126\ttest: 0.1985754\tbest: 0.1980888 (603)\ttotal: 9.78s\tremaining: 6.2s\n",
      "612:\tlearn: 0.0614758\ttest: 0.1986164\tbest: 0.1980888 (603)\ttotal: 9.8s\tremaining: 6.19s\n",
      "613:\tlearn: 0.0613402\ttest: 0.1984322\tbest: 0.1980888 (603)\ttotal: 9.81s\tremaining: 6.17s\n",
      "614:\tlearn: 0.0612101\ttest: 0.1985324\tbest: 0.1980888 (603)\ttotal: 9.83s\tremaining: 6.15s\n",
      "615:\tlearn: 0.0611408\ttest: 0.1984299\tbest: 0.1980888 (603)\ttotal: 9.85s\tremaining: 6.14s\n",
      "616:\tlearn: 0.0610231\ttest: 0.1985376\tbest: 0.1980888 (603)\ttotal: 9.86s\tremaining: 6.12s\n",
      "617:\tlearn: 0.0608888\ttest: 0.1983596\tbest: 0.1980888 (603)\ttotal: 9.88s\tremaining: 6.11s\n",
      "618:\tlearn: 0.0607712\ttest: 0.1983065\tbest: 0.1980888 (603)\ttotal: 9.89s\tremaining: 6.09s\n",
      "619:\tlearn: 0.0606535\ttest: 0.1983062\tbest: 0.1980888 (603)\ttotal: 9.91s\tremaining: 6.07s\n",
      "620:\tlearn: 0.0605451\ttest: 0.1984752\tbest: 0.1980888 (603)\ttotal: 9.92s\tremaining: 6.05s\n",
      "621:\tlearn: 0.0604233\ttest: 0.1983850\tbest: 0.1980888 (603)\ttotal: 9.94s\tremaining: 6.04s\n",
      "622:\tlearn: 0.0602946\ttest: 0.1983939\tbest: 0.1980888 (603)\ttotal: 9.96s\tremaining: 6.02s\n",
      "623:\tlearn: 0.0601827\ttest: 0.1982429\tbest: 0.1980888 (603)\ttotal: 9.97s\tremaining: 6.01s\n",
      "624:\tlearn: 0.0600243\ttest: 0.1980639\tbest: 0.1980639 (624)\ttotal: 9.98s\tremaining: 5.99s\n",
      "625:\tlearn: 0.0599101\ttest: 0.1979834\tbest: 0.1979834 (625)\ttotal: 10s\tremaining: 5.97s\n",
      "626:\tlearn: 0.0598398\ttest: 0.1980316\tbest: 0.1979834 (625)\ttotal: 10s\tremaining: 5.96s\n",
      "627:\tlearn: 0.0597422\ttest: 0.1981217\tbest: 0.1979834 (625)\ttotal: 10s\tremaining: 5.94s\n",
      "628:\tlearn: 0.0596304\ttest: 0.1980047\tbest: 0.1979834 (625)\ttotal: 10s\tremaining: 5.93s\n",
      "629:\tlearn: 0.0594990\ttest: 0.1980207\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.91s\n",
      "630:\tlearn: 0.0593512\ttest: 0.1980735\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.9s\n",
      "631:\tlearn: 0.0592250\ttest: 0.1980798\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.88s\n",
      "632:\tlearn: 0.0591112\ttest: 0.1980905\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.86s\n",
      "633:\tlearn: 0.0589856\ttest: 0.1983023\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.85s\n",
      "634:\tlearn: 0.0588517\ttest: 0.1982180\tbest: 0.1979834 (625)\ttotal: 10.1s\tremaining: 5.83s\n",
      "635:\tlearn: 0.0587572\ttest: 0.1981893\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.82s\n",
      "636:\tlearn: 0.0586804\ttest: 0.1980980\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.8s\n",
      "637:\tlearn: 0.0585960\ttest: 0.1980474\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.78s\n",
      "638:\tlearn: 0.0584826\ttest: 0.1981821\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.77s\n",
      "639:\tlearn: 0.0583704\ttest: 0.1982000\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.75s\n",
      "640:\tlearn: 0.0582514\ttest: 0.1982327\tbest: 0.1979834 (625)\ttotal: 10.2s\tremaining: 5.74s\n",
      "641:\tlearn: 0.0581128\ttest: 0.1983741\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.72s\n",
      "642:\tlearn: 0.0579665\ttest: 0.1982963\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.7s\n",
      "643:\tlearn: 0.0578170\ttest: 0.1981560\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.69s\n",
      "644:\tlearn: 0.0577553\ttest: 0.1981460\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.67s\n",
      "645:\tlearn: 0.0576314\ttest: 0.1981241\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.65s\n",
      "646:\tlearn: 0.0574992\ttest: 0.1980417\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.64s\n",
      "647:\tlearn: 0.0573644\ttest: 0.1981348\tbest: 0.1979834 (625)\ttotal: 10.3s\tremaining: 5.62s\n",
      "648:\tlearn: 0.0572706\ttest: 0.1981134\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.6s\n",
      "649:\tlearn: 0.0571577\ttest: 0.1981121\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.59s\n",
      "650:\tlearn: 0.0570727\ttest: 0.1981692\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.57s\n",
      "651:\tlearn: 0.0569748\ttest: 0.1980682\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.55s\n",
      "652:\tlearn: 0.0568403\ttest: 0.1980145\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.54s\n",
      "653:\tlearn: 0.0567610\ttest: 0.1980078\tbest: 0.1979834 (625)\ttotal: 10.4s\tremaining: 5.52s\n",
      "654:\tlearn: 0.0566080\ttest: 0.1978913\tbest: 0.1978913 (654)\ttotal: 10.5s\tremaining: 5.5s\n",
      "655:\tlearn: 0.0565010\ttest: 0.1977883\tbest: 0.1977883 (655)\ttotal: 10.5s\tremaining: 5.49s\n",
      "656:\tlearn: 0.0564099\ttest: 0.1977816\tbest: 0.1977816 (656)\ttotal: 10.5s\tremaining: 5.47s\n",
      "657:\tlearn: 0.0563354\ttest: 0.1978190\tbest: 0.1977816 (656)\ttotal: 10.5s\tremaining: 5.46s\n",
      "658:\tlearn: 0.0562583\ttest: 0.1978303\tbest: 0.1977816 (656)\ttotal: 10.5s\tremaining: 5.44s\n",
      "659:\tlearn: 0.0561525\ttest: 0.1979378\tbest: 0.1977816 (656)\ttotal: 10.5s\tremaining: 5.42s\n",
      "660:\tlearn: 0.0560174\ttest: 0.1980766\tbest: 0.1977816 (656)\ttotal: 10.5s\tremaining: 5.41s\n",
      "661:\tlearn: 0.0558997\ttest: 0.1979678\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.39s\n",
      "662:\tlearn: 0.0558121\ttest: 0.1978889\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.37s\n",
      "663:\tlearn: 0.0557432\ttest: 0.1979296\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.36s\n",
      "664:\tlearn: 0.0556622\ttest: 0.1979025\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.34s\n",
      "665:\tlearn: 0.0555717\ttest: 0.1978487\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.32s\n",
      "666:\tlearn: 0.0554875\ttest: 0.1978558\tbest: 0.1977816 (656)\ttotal: 10.6s\tremaining: 5.3s\n",
      "667:\tlearn: 0.0554288\ttest: 0.1977537\tbest: 0.1977537 (667)\ttotal: 10.6s\tremaining: 5.29s\n",
      "668:\tlearn: 0.0553106\ttest: 0.1977342\tbest: 0.1977342 (668)\ttotal: 10.7s\tremaining: 5.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669:\tlearn: 0.0552161\ttest: 0.1977098\tbest: 0.1977098 (669)\ttotal: 10.7s\tremaining: 5.25s\n",
      "670:\tlearn: 0.0551282\ttest: 0.1976571\tbest: 0.1976571 (670)\ttotal: 10.7s\tremaining: 5.24s\n",
      "671:\tlearn: 0.0549918\ttest: 0.1977479\tbest: 0.1976571 (670)\ttotal: 10.7s\tremaining: 5.22s\n",
      "672:\tlearn: 0.0548961\ttest: 0.1976726\tbest: 0.1976571 (670)\ttotal: 10.7s\tremaining: 5.2s\n",
      "673:\tlearn: 0.0548138\ttest: 0.1976372\tbest: 0.1976372 (673)\ttotal: 10.7s\tremaining: 5.19s\n",
      "674:\tlearn: 0.0546965\ttest: 0.1977984\tbest: 0.1976372 (673)\ttotal: 10.7s\tremaining: 5.17s\n",
      "675:\tlearn: 0.0545671\ttest: 0.1978818\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.16s\n",
      "676:\tlearn: 0.0545027\ttest: 0.1978368\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.14s\n",
      "677:\tlearn: 0.0544125\ttest: 0.1978466\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.13s\n",
      "678:\tlearn: 0.0543304\ttest: 0.1978144\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.11s\n",
      "679:\tlearn: 0.0542112\ttest: 0.1978089\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.09s\n",
      "680:\tlearn: 0.0541351\ttest: 0.1977934\tbest: 0.1976372 (673)\ttotal: 10.8s\tremaining: 5.08s\n",
      "681:\tlearn: 0.0540222\ttest: 0.1978864\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 5.06s\n",
      "682:\tlearn: 0.0539557\ttest: 0.1978840\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 5.05s\n",
      "683:\tlearn: 0.0538970\ttest: 0.1977969\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 5.03s\n",
      "684:\tlearn: 0.0537965\ttest: 0.1978395\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 5.01s\n",
      "685:\tlearn: 0.0537259\ttest: 0.1979918\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 5s\n",
      "686:\tlearn: 0.0536238\ttest: 0.1980383\tbest: 0.1976372 (673)\ttotal: 10.9s\tremaining: 4.98s\n",
      "687:\tlearn: 0.0535103\ttest: 0.1979545\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.97s\n",
      "688:\tlearn: 0.0534263\ttest: 0.1979955\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.95s\n",
      "689:\tlearn: 0.0533016\ttest: 0.1980463\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.94s\n",
      "690:\tlearn: 0.0532008\ttest: 0.1982514\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.92s\n",
      "691:\tlearn: 0.0531184\ttest: 0.1983519\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.9s\n",
      "692:\tlearn: 0.0530357\ttest: 0.1982529\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.89s\n",
      "693:\tlearn: 0.0529457\ttest: 0.1984134\tbest: 0.1976372 (673)\ttotal: 11s\tremaining: 4.87s\n",
      "694:\tlearn: 0.0528559\ttest: 0.1983936\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.86s\n",
      "695:\tlearn: 0.0527482\ttest: 0.1983986\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.84s\n",
      "696:\tlearn: 0.0526290\ttest: 0.1984103\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.82s\n",
      "697:\tlearn: 0.0524939\ttest: 0.1981918\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.81s\n",
      "698:\tlearn: 0.0523841\ttest: 0.1981317\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.79s\n",
      "699:\tlearn: 0.0523063\ttest: 0.1980483\tbest: 0.1976372 (673)\ttotal: 11.1s\tremaining: 4.78s\n",
      "700:\tlearn: 0.0521985\ttest: 0.1983152\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.76s\n",
      "701:\tlearn: 0.0520838\ttest: 0.1982247\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.74s\n",
      "702:\tlearn: 0.0520168\ttest: 0.1982287\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.73s\n",
      "703:\tlearn: 0.0519000\ttest: 0.1981527\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.71s\n",
      "704:\tlearn: 0.0518150\ttest: 0.1983244\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.7s\n",
      "705:\tlearn: 0.0517167\ttest: 0.1984356\tbest: 0.1976372 (673)\ttotal: 11.2s\tremaining: 4.68s\n",
      "706:\tlearn: 0.0516175\ttest: 0.1985069\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.66s\n",
      "707:\tlearn: 0.0514987\ttest: 0.1985711\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.65s\n",
      "708:\tlearn: 0.0513842\ttest: 0.1985560\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.63s\n",
      "709:\tlearn: 0.0512960\ttest: 0.1984903\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.62s\n",
      "710:\tlearn: 0.0511944\ttest: 0.1986016\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.6s\n",
      "711:\tlearn: 0.0511192\ttest: 0.1985024\tbest: 0.1976372 (673)\ttotal: 11.3s\tremaining: 4.58s\n",
      "712:\tlearn: 0.0510233\ttest: 0.1984887\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.57s\n",
      "713:\tlearn: 0.0509124\ttest: 0.1983514\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.55s\n",
      "714:\tlearn: 0.0508037\ttest: 0.1984119\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.54s\n",
      "715:\tlearn: 0.0507007\ttest: 0.1983399\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.52s\n",
      "716:\tlearn: 0.0505755\ttest: 0.1983052\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.5s\n",
      "717:\tlearn: 0.0504895\ttest: 0.1981217\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.49s\n",
      "718:\tlearn: 0.0504153\ttest: 0.1981324\tbest: 0.1976372 (673)\ttotal: 11.4s\tremaining: 4.47s\n",
      "719:\tlearn: 0.0503151\ttest: 0.1979394\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.46s\n",
      "720:\tlearn: 0.0501881\ttest: 0.1979677\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.44s\n",
      "721:\tlearn: 0.0500901\ttest: 0.1980863\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.42s\n",
      "722:\tlearn: 0.0500049\ttest: 0.1979864\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.41s\n",
      "723:\tlearn: 0.0498820\ttest: 0.1980290\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.39s\n",
      "724:\tlearn: 0.0498029\ttest: 0.1980786\tbest: 0.1976372 (673)\ttotal: 11.5s\tremaining: 4.38s\n",
      "725:\tlearn: 0.0497454\ttest: 0.1980359\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.36s\n",
      "726:\tlearn: 0.0496469\ttest: 0.1980097\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.34s\n",
      "727:\tlearn: 0.0495221\ttest: 0.1980319\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.33s\n",
      "728:\tlearn: 0.0494163\ttest: 0.1980494\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.32s\n",
      "729:\tlearn: 0.0493619\ttest: 0.1979878\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.3s\n",
      "730:\tlearn: 0.0492826\ttest: 0.1979151\tbest: 0.1976372 (673)\ttotal: 11.6s\tremaining: 4.29s\n",
      "731:\tlearn: 0.0491710\ttest: 0.1979357\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.27s\n",
      "732:\tlearn: 0.0490705\ttest: 0.1979038\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.25s\n",
      "733:\tlearn: 0.0489917\ttest: 0.1979526\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.24s\n",
      "734:\tlearn: 0.0489175\ttest: 0.1978311\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.22s\n",
      "735:\tlearn: 0.0488445\ttest: 0.1977812\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.21s\n",
      "736:\tlearn: 0.0487757\ttest: 0.1979109\tbest: 0.1976372 (673)\ttotal: 11.7s\tremaining: 4.19s\n",
      "737:\tlearn: 0.0487046\ttest: 0.1979802\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.18s\n",
      "738:\tlearn: 0.0485928\ttest: 0.1979966\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.16s\n",
      "739:\tlearn: 0.0485242\ttest: 0.1979388\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.14s\n",
      "740:\tlearn: 0.0484009\ttest: 0.1978134\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.13s\n",
      "741:\tlearn: 0.0482979\ttest: 0.1977690\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.11s\n",
      "742:\tlearn: 0.0481899\ttest: 0.1977515\tbest: 0.1976372 (673)\ttotal: 11.8s\tremaining: 4.09s\n",
      "743:\tlearn: 0.0481166\ttest: 0.1977912\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4.08s\n",
      "744:\tlearn: 0.0480387\ttest: 0.1978865\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4.06s\n",
      "745:\tlearn: 0.0479387\ttest: 0.1979280\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4.05s\n",
      "746:\tlearn: 0.0478399\ttest: 0.1979294\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4.03s\n",
      "747:\tlearn: 0.0477430\ttest: 0.1978980\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4.01s\n",
      "748:\tlearn: 0.0476336\ttest: 0.1978400\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 4s\n",
      "749:\tlearn: 0.0475415\ttest: 0.1976487\tbest: 0.1976372 (673)\ttotal: 11.9s\tremaining: 3.98s\n",
      "750:\tlearn: 0.0474579\ttest: 0.1976847\tbest: 0.1976372 (673)\ttotal: 12s\tremaining: 3.97s\n",
      "751:\tlearn: 0.0473800\ttest: 0.1976163\tbest: 0.1976163 (751)\ttotal: 12s\tremaining: 3.95s\n",
      "752:\tlearn: 0.0473169\ttest: 0.1974873\tbest: 0.1974873 (752)\ttotal: 12s\tremaining: 3.93s\n",
      "753:\tlearn: 0.0472129\ttest: 0.1975512\tbest: 0.1974873 (752)\ttotal: 12s\tremaining: 3.92s\n",
      "754:\tlearn: 0.0471252\ttest: 0.1973830\tbest: 0.1973830 (754)\ttotal: 12s\tremaining: 3.9s\n",
      "755:\tlearn: 0.0470374\ttest: 0.1972491\tbest: 0.1972491 (755)\ttotal: 12s\tremaining: 3.89s\n",
      "756:\tlearn: 0.0469402\ttest: 0.1971583\tbest: 0.1971583 (756)\ttotal: 12.1s\tremaining: 3.87s\n",
      "757:\tlearn: 0.0468320\ttest: 0.1971553\tbest: 0.1971553 (757)\ttotal: 12.1s\tremaining: 3.86s\n",
      "758:\tlearn: 0.0467786\ttest: 0.1971989\tbest: 0.1971553 (757)\ttotal: 12.1s\tremaining: 3.84s\n",
      "759:\tlearn: 0.0466900\ttest: 0.1972826\tbest: 0.1971553 (757)\ttotal: 12.1s\tremaining: 3.83s\n",
      "760:\tlearn: 0.0466214\ttest: 0.1973304\tbest: 0.1971553 (757)\ttotal: 12.1s\tremaining: 3.81s\n",
      "761:\tlearn: 0.0465191\ttest: 0.1975420\tbest: 0.1971553 (757)\ttotal: 12.1s\tremaining: 3.79s\n",
      "762:\tlearn: 0.0464386\ttest: 0.1975995\tbest: 0.1971553 (757)\ttotal: 12.2s\tremaining: 3.78s\n",
      "763:\tlearn: 0.0463541\ttest: 0.1975697\tbest: 0.1971553 (757)\ttotal: 12.2s\tremaining: 3.76s\n",
      "764:\tlearn: 0.0462678\ttest: 0.1976503\tbest: 0.1971553 (757)\ttotal: 12.2s\tremaining: 3.75s\n",
      "765:\tlearn: 0.0461709\ttest: 0.1974822\tbest: 0.1971553 (757)\ttotal: 12.2s\tremaining: 3.73s\n",
      "766:\tlearn: 0.0461076\ttest: 0.1975836\tbest: 0.1971553 (757)\ttotal: 12.2s\tremaining: 3.72s\n",
      "767:\tlearn: 0.0460218\ttest: 0.1976368\tbest: 0.1971553 (757)\ttotal: 12.3s\tremaining: 3.7s\n",
      "768:\tlearn: 0.0459688\ttest: 0.1976451\tbest: 0.1971553 (757)\ttotal: 12.3s\tremaining: 3.69s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769:\tlearn: 0.0458933\ttest: 0.1976159\tbest: 0.1971553 (757)\ttotal: 12.3s\tremaining: 3.67s\n",
      "770:\tlearn: 0.0458090\ttest: 0.1976278\tbest: 0.1971553 (757)\ttotal: 12.3s\tremaining: 3.66s\n",
      "771:\tlearn: 0.0457312\ttest: 0.1974820\tbest: 0.1971553 (757)\ttotal: 12.3s\tremaining: 3.64s\n",
      "772:\tlearn: 0.0456535\ttest: 0.1973917\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.63s\n",
      "773:\tlearn: 0.0455737\ttest: 0.1973337\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.61s\n",
      "774:\tlearn: 0.0454890\ttest: 0.1973893\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.6s\n",
      "775:\tlearn: 0.0453770\ttest: 0.1973583\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.58s\n",
      "776:\tlearn: 0.0452802\ttest: 0.1972566\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.56s\n",
      "777:\tlearn: 0.0452068\ttest: 0.1974076\tbest: 0.1971553 (757)\ttotal: 12.4s\tremaining: 3.55s\n",
      "778:\tlearn: 0.0451423\ttest: 0.1974596\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.53s\n",
      "779:\tlearn: 0.0450826\ttest: 0.1975256\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.52s\n",
      "780:\tlearn: 0.0450055\ttest: 0.1975351\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.5s\n",
      "781:\tlearn: 0.0449440\ttest: 0.1975159\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.49s\n",
      "782:\tlearn: 0.0448464\ttest: 0.1975029\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.47s\n",
      "783:\tlearn: 0.0447643\ttest: 0.1976523\tbest: 0.1971553 (757)\ttotal: 12.5s\tremaining: 3.46s\n",
      "784:\tlearn: 0.0446879\ttest: 0.1976293\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.44s\n",
      "785:\tlearn: 0.0446124\ttest: 0.1976663\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.42s\n",
      "786:\tlearn: 0.0445226\ttest: 0.1976611\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.41s\n",
      "787:\tlearn: 0.0444347\ttest: 0.1976604\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.39s\n",
      "788:\tlearn: 0.0443656\ttest: 0.1975030\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.38s\n",
      "789:\tlearn: 0.0442710\ttest: 0.1977091\tbest: 0.1971553 (757)\ttotal: 12.6s\tremaining: 3.36s\n",
      "790:\tlearn: 0.0441940\ttest: 0.1976287\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.34s\n",
      "791:\tlearn: 0.0441077\ttest: 0.1976762\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.33s\n",
      "792:\tlearn: 0.0440439\ttest: 0.1975952\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.31s\n",
      "793:\tlearn: 0.0439858\ttest: 0.1976858\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.29s\n",
      "794:\tlearn: 0.0438922\ttest: 0.1977648\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.28s\n",
      "795:\tlearn: 0.0438237\ttest: 0.1975864\tbest: 0.1971553 (757)\ttotal: 12.7s\tremaining: 3.26s\n",
      "796:\tlearn: 0.0437354\ttest: 0.1974588\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.25s\n",
      "797:\tlearn: 0.0436531\ttest: 0.1974922\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.23s\n",
      "798:\tlearn: 0.0435477\ttest: 0.1974750\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.22s\n",
      "799:\tlearn: 0.0434750\ttest: 0.1975373\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.2s\n",
      "800:\tlearn: 0.0433841\ttest: 0.1975615\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.19s\n",
      "801:\tlearn: 0.0433076\ttest: 0.1974400\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.17s\n",
      "802:\tlearn: 0.0432407\ttest: 0.1974086\tbest: 0.1971553 (757)\ttotal: 12.8s\tremaining: 3.15s\n",
      "803:\tlearn: 0.0431588\ttest: 0.1975076\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.13s\n",
      "804:\tlearn: 0.0430953\ttest: 0.1974518\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.12s\n",
      "805:\tlearn: 0.0430120\ttest: 0.1973680\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.1s\n",
      "806:\tlearn: 0.0429503\ttest: 0.1974810\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.09s\n",
      "807:\tlearn: 0.0428726\ttest: 0.1975764\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.07s\n",
      "808:\tlearn: 0.0428023\ttest: 0.1975930\tbest: 0.1971553 (757)\ttotal: 12.9s\tremaining: 3.06s\n",
      "809:\tlearn: 0.0427288\ttest: 0.1975171\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 3.04s\n",
      "810:\tlearn: 0.0426344\ttest: 0.1976892\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 3.02s\n",
      "811:\tlearn: 0.0425542\ttest: 0.1975990\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 3.01s\n",
      "812:\tlearn: 0.0425045\ttest: 0.1975570\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 2.99s\n",
      "813:\tlearn: 0.0424752\ttest: 0.1975272\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 2.98s\n",
      "814:\tlearn: 0.0423959\ttest: 0.1976290\tbest: 0.1971553 (757)\ttotal: 13s\tremaining: 2.96s\n",
      "815:\tlearn: 0.0423104\ttest: 0.1977129\tbest: 0.1971553 (757)\ttotal: 13.1s\tremaining: 2.94s\n",
      "816:\tlearn: 0.0422482\ttest: 0.1977032\tbest: 0.1971553 (757)\ttotal: 13.1s\tremaining: 2.93s\n",
      "817:\tlearn: 0.0421544\ttest: 0.1976461\tbest: 0.1971553 (757)\ttotal: 13.1s\tremaining: 2.91s\n",
      "818:\tlearn: 0.0421097\ttest: 0.1977044\tbest: 0.1971553 (757)\ttotal: 13.1s\tremaining: 2.9s\n",
      "819:\tlearn: 0.0420323\ttest: 0.1976760\tbest: 0.1971553 (757)\ttotal: 13.1s\tremaining: 2.88s\n",
      "820:\tlearn: 0.0419554\ttest: 0.1977927\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.87s\n",
      "821:\tlearn: 0.0418430\ttest: 0.1978529\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.85s\n",
      "822:\tlearn: 0.0417729\ttest: 0.1978167\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.84s\n",
      "823:\tlearn: 0.0417078\ttest: 0.1978767\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.82s\n",
      "824:\tlearn: 0.0416391\ttest: 0.1978349\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.8s\n",
      "825:\tlearn: 0.0415421\ttest: 0.1977949\tbest: 0.1971553 (757)\ttotal: 13.2s\tremaining: 2.79s\n",
      "826:\tlearn: 0.0414590\ttest: 0.1978244\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.77s\n",
      "827:\tlearn: 0.0413643\ttest: 0.1977274\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.76s\n",
      "828:\tlearn: 0.0412881\ttest: 0.1978041\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.74s\n",
      "829:\tlearn: 0.0411884\ttest: 0.1978721\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.72s\n",
      "830:\tlearn: 0.0411122\ttest: 0.1979409\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.71s\n",
      "831:\tlearn: 0.0410592\ttest: 0.1979371\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.69s\n",
      "832:\tlearn: 0.0409699\ttest: 0.1979806\tbest: 0.1971553 (757)\ttotal: 13.3s\tremaining: 2.68s\n",
      "833:\tlearn: 0.0408823\ttest: 0.1979348\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.66s\n",
      "834:\tlearn: 0.0407878\ttest: 0.1977490\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.64s\n",
      "835:\tlearn: 0.0407135\ttest: 0.1977913\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.63s\n",
      "836:\tlearn: 0.0406543\ttest: 0.1977714\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.61s\n",
      "837:\tlearn: 0.0405937\ttest: 0.1977993\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.6s\n",
      "838:\tlearn: 0.0405285\ttest: 0.1977859\tbest: 0.1971553 (757)\ttotal: 13.4s\tremaining: 2.58s\n",
      "839:\tlearn: 0.0404660\ttest: 0.1978870\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.56s\n",
      "840:\tlearn: 0.0403996\ttest: 0.1978668\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.55s\n",
      "841:\tlearn: 0.0403467\ttest: 0.1978669\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.53s\n",
      "842:\tlearn: 0.0402604\ttest: 0.1978316\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.51s\n",
      "843:\tlearn: 0.0401923\ttest: 0.1977150\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.5s\n",
      "844:\tlearn: 0.0400920\ttest: 0.1976811\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.48s\n",
      "845:\tlearn: 0.0400428\ttest: 0.1977813\tbest: 0.1971553 (757)\ttotal: 13.5s\tremaining: 2.46s\n",
      "846:\tlearn: 0.0399790\ttest: 0.1976643\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.45s\n",
      "847:\tlearn: 0.0399566\ttest: 0.1976342\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.43s\n",
      "848:\tlearn: 0.0399033\ttest: 0.1976363\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.42s\n",
      "849:\tlearn: 0.0398336\ttest: 0.1977059\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.4s\n",
      "850:\tlearn: 0.0397610\ttest: 0.1978470\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.39s\n",
      "851:\tlearn: 0.0396889\ttest: 0.1978742\tbest: 0.1971553 (757)\ttotal: 13.6s\tremaining: 2.37s\n",
      "852:\tlearn: 0.0396205\ttest: 0.1978946\tbest: 0.1971553 (757)\ttotal: 13.7s\tremaining: 2.35s\n",
      "853:\tlearn: 0.0395570\ttest: 0.1977296\tbest: 0.1971553 (757)\ttotal: 13.7s\tremaining: 2.34s\n",
      "854:\tlearn: 0.0394634\ttest: 0.1977940\tbest: 0.1971553 (757)\ttotal: 13.7s\tremaining: 2.32s\n",
      "855:\tlearn: 0.0394123\ttest: 0.1978017\tbest: 0.1971553 (757)\ttotal: 13.7s\tremaining: 2.31s\n",
      "856:\tlearn: 0.0393097\ttest: 0.1977796\tbest: 0.1971553 (757)\ttotal: 13.7s\tremaining: 2.29s\n",
      "857:\tlearn: 0.0392538\ttest: 0.1978160\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.28s\n",
      "858:\tlearn: 0.0391708\ttest: 0.1980154\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.26s\n",
      "859:\tlearn: 0.0391287\ttest: 0.1980233\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.24s\n",
      "860:\tlearn: 0.0390483\ttest: 0.1980476\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.23s\n",
      "861:\tlearn: 0.0389886\ttest: 0.1979148\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.21s\n",
      "862:\tlearn: 0.0389067\ttest: 0.1979862\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.19s\n",
      "863:\tlearn: 0.0388574\ttest: 0.1979087\tbest: 0.1971553 (757)\ttotal: 13.8s\tremaining: 2.18s\n",
      "864:\tlearn: 0.0387709\ttest: 0.1979698\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.16s\n",
      "865:\tlearn: 0.0387121\ttest: 0.1981162\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.15s\n",
      "866:\tlearn: 0.0386155\ttest: 0.1980406\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.13s\n",
      "867:\tlearn: 0.0385365\ttest: 0.1981206\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.12s\n",
      "868:\tlearn: 0.0384782\ttest: 0.1981077\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.1s\n",
      "869:\tlearn: 0.0384286\ttest: 0.1980663\tbest: 0.1971553 (757)\ttotal: 13.9s\tremaining: 2.08s\n",
      "870:\tlearn: 0.0383436\ttest: 0.1978516\tbest: 0.1971553 (757)\ttotal: 14s\tremaining: 2.07s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871:\tlearn: 0.0382684\ttest: 0.1979159\tbest: 0.1971553 (757)\ttotal: 14s\tremaining: 2.05s\n",
      "872:\tlearn: 0.0382073\ttest: 0.1978913\tbest: 0.1971553 (757)\ttotal: 14s\tremaining: 2.04s\n",
      "873:\tlearn: 0.0381376\ttest: 0.1979637\tbest: 0.1971553 (757)\ttotal: 14s\tremaining: 2.02s\n",
      "874:\tlearn: 0.0380621\ttest: 0.1979340\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 2.01s\n",
      "875:\tlearn: 0.0379925\ttest: 0.1979871\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 1.99s\n",
      "876:\tlearn: 0.0379238\ttest: 0.1980826\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 1.98s\n",
      "877:\tlearn: 0.0378173\ttest: 0.1982534\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 1.96s\n",
      "878:\tlearn: 0.0377433\ttest: 0.1981496\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 1.94s\n",
      "879:\tlearn: 0.0376771\ttest: 0.1981372\tbest: 0.1971553 (757)\ttotal: 14.1s\tremaining: 1.93s\n",
      "880:\tlearn: 0.0376166\ttest: 0.1982187\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.91s\n",
      "881:\tlearn: 0.0375337\ttest: 0.1983320\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.9s\n",
      "882:\tlearn: 0.0374635\ttest: 0.1984144\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.88s\n",
      "883:\tlearn: 0.0373808\ttest: 0.1983997\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.86s\n",
      "884:\tlearn: 0.0373046\ttest: 0.1984444\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.85s\n",
      "885:\tlearn: 0.0372575\ttest: 0.1985197\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.83s\n",
      "886:\tlearn: 0.0371957\ttest: 0.1984589\tbest: 0.1971553 (757)\ttotal: 14.2s\tremaining: 1.81s\n",
      "887:\tlearn: 0.0371580\ttest: 0.1984134\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.8s\n",
      "888:\tlearn: 0.0370835\ttest: 0.1985469\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.78s\n",
      "889:\tlearn: 0.0370384\ttest: 0.1985218\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.76s\n",
      "890:\tlearn: 0.0369665\ttest: 0.1985788\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.75s\n",
      "891:\tlearn: 0.0368855\ttest: 0.1986358\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.73s\n",
      "892:\tlearn: 0.0368233\ttest: 0.1986087\tbest: 0.1971553 (757)\ttotal: 14.3s\tremaining: 1.72s\n",
      "893:\tlearn: 0.0367511\ttest: 0.1985815\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.7s\n",
      "894:\tlearn: 0.0366752\ttest: 0.1985571\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.69s\n",
      "895:\tlearn: 0.0366306\ttest: 0.1985934\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.67s\n",
      "896:\tlearn: 0.0365763\ttest: 0.1986936\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.65s\n",
      "897:\tlearn: 0.0365306\ttest: 0.1987463\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.64s\n",
      "898:\tlearn: 0.0364602\ttest: 0.1985504\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.62s\n",
      "899:\tlearn: 0.0364202\ttest: 0.1985804\tbest: 0.1971553 (757)\ttotal: 14.4s\tremaining: 1.6s\n",
      "900:\tlearn: 0.0363519\ttest: 0.1986668\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.59s\n",
      "901:\tlearn: 0.0362636\ttest: 0.1988350\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.57s\n",
      "902:\tlearn: 0.0361674\ttest: 0.1988783\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.56s\n",
      "903:\tlearn: 0.0361097\ttest: 0.1989694\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.54s\n",
      "904:\tlearn: 0.0360503\ttest: 0.1989996\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.52s\n",
      "905:\tlearn: 0.0359806\ttest: 0.1991000\tbest: 0.1971553 (757)\ttotal: 14.5s\tremaining: 1.51s\n",
      "906:\tlearn: 0.0359126\ttest: 0.1991106\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.49s\n",
      "907:\tlearn: 0.0358340\ttest: 0.1991992\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.48s\n",
      "908:\tlearn: 0.0357579\ttest: 0.1991369\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.46s\n",
      "909:\tlearn: 0.0356743\ttest: 0.1991843\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.45s\n",
      "910:\tlearn: 0.0355893\ttest: 0.1991417\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.43s\n",
      "911:\tlearn: 0.0355247\ttest: 0.1991890\tbest: 0.1971553 (757)\ttotal: 14.6s\tremaining: 1.41s\n",
      "912:\tlearn: 0.0354832\ttest: 0.1992105\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.4s\n",
      "913:\tlearn: 0.0354170\ttest: 0.1991497\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.38s\n",
      "914:\tlearn: 0.0353434\ttest: 0.1992404\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.36s\n",
      "915:\tlearn: 0.0352662\ttest: 0.1992338\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.35s\n",
      "916:\tlearn: 0.0351793\ttest: 0.1990150\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.33s\n",
      "917:\tlearn: 0.0350987\ttest: 0.1990862\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.32s\n",
      "918:\tlearn: 0.0350357\ttest: 0.1990907\tbest: 0.1971553 (757)\ttotal: 14.7s\tremaining: 1.3s\n",
      "919:\tlearn: 0.0349916\ttest: 0.1989285\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.28s\n",
      "920:\tlearn: 0.0349429\ttest: 0.1989057\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.27s\n",
      "921:\tlearn: 0.0348850\ttest: 0.1987391\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.25s\n",
      "922:\tlearn: 0.0348322\ttest: 0.1987864\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.24s\n",
      "923:\tlearn: 0.0347754\ttest: 0.1989219\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.22s\n",
      "924:\tlearn: 0.0347183\ttest: 0.1989270\tbest: 0.1971553 (757)\ttotal: 14.8s\tremaining: 1.2s\n",
      "925:\tlearn: 0.0346599\ttest: 0.1988391\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.19s\n",
      "926:\tlearn: 0.0346211\ttest: 0.1989035\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.17s\n",
      "927:\tlearn: 0.0345486\ttest: 0.1988963\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.16s\n",
      "928:\tlearn: 0.0344803\ttest: 0.1988436\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.14s\n",
      "929:\tlearn: 0.0344623\ttest: 0.1988605\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.12s\n",
      "930:\tlearn: 0.0343998\ttest: 0.1988602\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.11s\n",
      "931:\tlearn: 0.0343633\ttest: 0.1989718\tbest: 0.1971553 (757)\ttotal: 14.9s\tremaining: 1.09s\n",
      "932:\tlearn: 0.0343046\ttest: 0.1988738\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 1.07s\n",
      "933:\tlearn: 0.0342662\ttest: 0.1988476\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 1.06s\n",
      "934:\tlearn: 0.0342140\ttest: 0.1989029\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 1.04s\n",
      "935:\tlearn: 0.0341736\ttest: 0.1988993\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 1.03s\n",
      "936:\tlearn: 0.0341241\ttest: 0.1988813\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 1.01s\n",
      "937:\tlearn: 0.0340724\ttest: 0.1989354\tbest: 0.1971553 (757)\ttotal: 15s\tremaining: 994ms\n",
      "938:\tlearn: 0.0340215\ttest: 0.1990860\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 978ms\n",
      "939:\tlearn: 0.0339581\ttest: 0.1990640\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 962ms\n",
      "940:\tlearn: 0.0339063\ttest: 0.1991049\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 946ms\n",
      "941:\tlearn: 0.0338812\ttest: 0.1990425\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 930ms\n",
      "942:\tlearn: 0.0338208\ttest: 0.1990235\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 914ms\n",
      "943:\tlearn: 0.0337740\ttest: 0.1991333\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 898ms\n",
      "944:\tlearn: 0.0337300\ttest: 0.1991080\tbest: 0.1971553 (757)\ttotal: 15.1s\tremaining: 881ms\n",
      "945:\tlearn: 0.0336755\ttest: 0.1991385\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 865ms\n",
      "946:\tlearn: 0.0336243\ttest: 0.1991638\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 849ms\n",
      "947:\tlearn: 0.0335569\ttest: 0.1990855\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 833ms\n",
      "948:\tlearn: 0.0334926\ttest: 0.1991261\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 817ms\n",
      "949:\tlearn: 0.0334205\ttest: 0.1993045\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 801ms\n",
      "950:\tlearn: 0.0333684\ttest: 0.1993359\tbest: 0.1971553 (757)\ttotal: 15.2s\tremaining: 785ms\n",
      "951:\tlearn: 0.0333101\ttest: 0.1993601\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 769ms\n",
      "952:\tlearn: 0.0332517\ttest: 0.1994167\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 753ms\n",
      "953:\tlearn: 0.0331919\ttest: 0.1994772\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 737ms\n",
      "954:\tlearn: 0.0331237\ttest: 0.1993051\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 721ms\n",
      "955:\tlearn: 0.0330703\ttest: 0.1992621\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 705ms\n",
      "956:\tlearn: 0.0330152\ttest: 0.1992982\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 689ms\n",
      "957:\tlearn: 0.0329715\ttest: 0.1992187\tbest: 0.1971553 (757)\ttotal: 15.3s\tremaining: 673ms\n",
      "958:\tlearn: 0.0328980\ttest: 0.1992153\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 657ms\n",
      "959:\tlearn: 0.0328205\ttest: 0.1989613\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 641ms\n",
      "960:\tlearn: 0.0327795\ttest: 0.1991346\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 625ms\n",
      "961:\tlearn: 0.0327060\ttest: 0.1991658\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 609ms\n",
      "962:\tlearn: 0.0326713\ttest: 0.1991734\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 593ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963:\tlearn: 0.0326026\ttest: 0.1992496\tbest: 0.1971553 (757)\ttotal: 15.4s\tremaining: 577ms\n",
      "964:\tlearn: 0.0325685\ttest: 0.1991269\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 561ms\n",
      "965:\tlearn: 0.0325250\ttest: 0.1992098\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 545ms\n",
      "966:\tlearn: 0.0324850\ttest: 0.1992911\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 529ms\n",
      "967:\tlearn: 0.0324202\ttest: 0.1993553\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 513ms\n",
      "968:\tlearn: 0.0323702\ttest: 0.1992778\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 496ms\n",
      "969:\tlearn: 0.0323270\ttest: 0.1992025\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 480ms\n",
      "970:\tlearn: 0.0322661\ttest: 0.1992196\tbest: 0.1971553 (757)\ttotal: 15.5s\tremaining: 464ms\n",
      "971:\tlearn: 0.0322113\ttest: 0.1992704\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 448ms\n",
      "972:\tlearn: 0.0321627\ttest: 0.1993059\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 432ms\n",
      "973:\tlearn: 0.0321161\ttest: 0.1993865\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 416ms\n",
      "974:\tlearn: 0.0320562\ttest: 0.1993278\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 400ms\n",
      "975:\tlearn: 0.0320328\ttest: 0.1992958\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 384ms\n",
      "976:\tlearn: 0.0319875\ttest: 0.1993762\tbest: 0.1971553 (757)\ttotal: 15.6s\tremaining: 368ms\n",
      "977:\tlearn: 0.0319398\ttest: 0.1993314\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 352ms\n",
      "978:\tlearn: 0.0318854\ttest: 0.1993073\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 336ms\n",
      "979:\tlearn: 0.0318200\ttest: 0.1994303\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 320ms\n",
      "980:\tlearn: 0.0317687\ttest: 0.1995257\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 304ms\n",
      "981:\tlearn: 0.0317117\ttest: 0.1994248\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 288ms\n",
      "982:\tlearn: 0.0316615\ttest: 0.1993915\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 272ms\n",
      "983:\tlearn: 0.0315798\ttest: 0.1993462\tbest: 0.1971553 (757)\ttotal: 15.7s\tremaining: 256ms\n",
      "984:\tlearn: 0.0315312\ttest: 0.1993598\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 240ms\n",
      "985:\tlearn: 0.0314579\ttest: 0.1994821\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 224ms\n",
      "986:\tlearn: 0.0313941\ttest: 0.1995471\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 208ms\n",
      "987:\tlearn: 0.0313548\ttest: 0.1995306\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 192ms\n",
      "988:\tlearn: 0.0313069\ttest: 0.1995177\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 176ms\n",
      "989:\tlearn: 0.0312557\ttest: 0.1996222\tbest: 0.1971553 (757)\ttotal: 15.8s\tremaining: 160ms\n",
      "990:\tlearn: 0.0312071\ttest: 0.1995968\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 144ms\n",
      "991:\tlearn: 0.0311790\ttest: 0.1995501\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 128ms\n",
      "992:\tlearn: 0.0311206\ttest: 0.1995517\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 112ms\n",
      "993:\tlearn: 0.0310732\ttest: 0.1994304\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 95.9ms\n",
      "994:\tlearn: 0.0310295\ttest: 0.1994680\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 79.9ms\n",
      "995:\tlearn: 0.0310029\ttest: 0.1995166\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 63.9ms\n",
      "996:\tlearn: 0.0309448\ttest: 0.1995178\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 48ms\n",
      "997:\tlearn: 0.0308844\ttest: 0.1993983\tbest: 0.1971553 (757)\ttotal: 15.9s\tremaining: 32ms\n",
      "998:\tlearn: 0.0308311\ttest: 0.1994678\tbest: 0.1971553 (757)\ttotal: 16s\tremaining: 16ms\n",
      "999:\tlearn: 0.0307862\ttest: 0.1995043\tbest: 0.1971553 (757)\ttotal: 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1971553495\n",
      "bestIteration = 757\n",
      "\n",
      "Shrink model to first 758 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1545a8040>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.CatBoostClassifier(custom_loss='AUC').fit(\n",
    "    X=train_proj_emb_dataset.samples,\n",
    "    y=(train_proj_emb_dataset.labels[:, 0] == 'NR').astype(int),\n",
    "    eval_set=(\n",
    "        val_proj_emb_dataset.samples,\n",
    "        (val_proj_emb_dataset.labels[:, 0] == 'NR').astype(int)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "\n",
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 secondsconvergence after 7 epochs took 0 seconds\n",
      "\n",
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 8 epochs took 0 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 secondsmax_iter reached after 2 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 1 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done   3 out of  10 | elapsed:   12.4s remaining:   29.0s\n",
      "[Parallel(n_jobs=7)]: Done   5 out of  10 | elapsed:   12.5s remaining:   12.5s\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done   7 out of  10 | elapsed:   12.5s remaining:    5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9 epochs took 1 seconds\n",
      "convergence after 7 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 2 seconds\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:   19.5s finished\n"
     ]
    }
   ],
   "source": [
    "cv_label1 = LogisticRegressionCV(**params).fit(\n",
    "    X=proj_emb_dataset.samples,\n",
    "    y=(proj_emb_dataset.labels[:, 0] == 'NR').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('cv_label1_mobilenet_crop_64.pkl','wb') as f:\n",
    "    pickle.dump(cv_label1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , 0.5       , 0.93023088,\n",
       "       0.96280139, 0.97065471, 0.97365269, 0.97517425, 0.9761071 ])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop256 normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , 0.66592514, 0.90761749,\n",
       "       0.94244116, 0.9550157 , 0.96012365, 0.9631246 , 0.96507756])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop128 normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , 0.5       , 0.93023088,\n",
       "       0.96280139, 0.97065471, 0.97365269, 0.97517425, 0.9761071 ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop64 normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , 0.70546698, 0.9175677 ,\n",
       "       0.95809902, 0.96694732, 0.97029197, 0.9720148 , 0.97301826])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop64 normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.5       , 0.70550071, 0.91753139,\n",
       "       0.95811081, 0.96693674, 0.97036226, 0.97211698, 0.97315119])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop64 normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.78958939, 0.93599517, 0.96792367, 0.97494673,\n",
       "       0.97596747, 0.97633959, 0.97650932, 0.97657727, 0.97661092])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1],axis=0)  # with crop64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.76982608, 0.86866077, 0.9326519 ,\n",
       "       0.94429291, 0.94827148, 0.95034892, 0.95169425, 0.9526548 ])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1], axis=0)  # new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.7952889 , 0.87402804, 0.94469283,\n",
       "       0.95739159, 0.96157609, 0.96381906, 0.96529288, 0.96639186])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label1.scores_[1], axis=0)  # old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cs': 10,\n",
       " 'class_weight': None,\n",
       " 'cv': StratifiedKFold(n_splits=10, random_state=0, shuffle=True),\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1.0,\n",
       " 'l1_ratios': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': 7,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 0,\n",
       " 'refit': False,\n",
       " 'scoring': 'roc_auc',\n",
       " 'solver': 'saga',\n",
       " 'tol': 1e-05,\n",
       " 'verbose': 10}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_label1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scals = np.sum(cv_label1.coef_ * proj_emb_dataset.samples, axis=1) \\\n",
    "    / np.sum(cv_label1.coef_ ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  12.,   52.,  246.,  634., 1243., 1907., 3041., 4049., 2039.,\n",
       "         181.]),\n",
       " array([-0.05156572, -0.04595174, -0.04033775, -0.03472377, -0.02910979,\n",
       "        -0.0234958 , -0.01788182, -0.01226784, -0.00665385, -0.00103987,\n",
       "         0.00457412]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.24.4-cp39-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 8.8 MB/s eta 0:00:01    |███                             | 1.1 MB 2.3 MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/site-packages (from catboost) (1.20.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/site-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from catboost) (3.3.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.9/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=7142ea69f2bdc9e51212c74b906d77f6f989793d634af1c973839d25de34a510\n",
      "  Stored in directory: /Users/sergmiller/Library/Caches/pip/wheels/ce/18/7f/e9527e3e66db1456194ac7f61eb3211068c409edceecff2d31\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly, graphviz, catboost\n",
      "Successfully installed catboost-0.24.4 graphviz-0.16 plotly-4.14.3 retrying-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [1, 10, 20, 3, 30, 6]\n",
    "\n",
    "def mae_scorer(estimator, X, y):\n",
    "#     y_pred = np.array([sum(z * classes[i] for i,z in enumerate(_y)) for _y in estimator.predict_proba(X)])\n",
    "    y_pred = np.array([classes[int(_y)] for _y in estimator.predict(X)])\n",
    "    y = np.array([classes[_y] for _y in y])\n",
    "    return -np.mean(np.abs(y_pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend ThreadingBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "\n",
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 secondsconvergence after 3 epochs took 0 seconds\n",
      "\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 98 epochs took 5 seconds\n",
      "max_iter reached after 5 seconds\n",
      "convergence after 100 epochs took 5 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 5 seconds\n",
      "convergence after 100 epochs took 5 seconds\n",
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 100 epochs took 5 seconds\n",
      "max_iter reached after 5 secondsmax_iter reached after 5 seconds\n",
      "\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n",
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n",
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 8 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "max_iter reached after 7 seconds\n",
      "convergence after 1 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 7 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "max_iter reached after 7 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "max_iter reached after 7 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "max_iter reached after 7 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "max_iter reached after 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done   3 out of  10 | elapsed:   44.1s remaining:  1.7min\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done   5 out of  10 | elapsed:   44.2s remaining:   44.2s\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done   7 out of  10 | elapsed:   44.3s remaining:   19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 100 epochs took 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "convergence after 99 epochs took 3 seconds\n",
      "convergence after 99 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n",
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "params2 = copy.copy(params)\n",
    "\n",
    "params2['cv'] = build_fold(1)\n",
    "params2['scoring'] = mae_scorer\n",
    "# params2['penalty'] = 'l1'\n",
    "\n",
    "# params2['class_weight'] = {str(c) : c for c in classes}\n",
    "cv_label2 = LogisticRegressionCV(**params2).fit(\n",
    "    proj_emb_dataset.samples,\n",
    "    proj_emb_dataset.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.92192026, -12.54789041, -11.3617167 ,  -8.64103086,\n",
       "        -0.98582629,  -0.62228327,  -0.50388906,  -0.45047264,\n",
       "        -0.42391132,  -0.40250114])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop256 proj normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.92192026, -12.54789041, -11.46380625,  -2.33884554,\n",
       "        -0.89279687,  -0.42972036,  -0.31498113,  -0.27156138,\n",
       "        -0.25029834,  -0.23664502])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop128 proj normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.92192026, -12.54789041, -10.79639387,  -4.73322721,\n",
       "        -1.67205266,  -0.88369868,  -0.61855282,  -0.53164407,\n",
       "        -0.49270126,  -0.46286109])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop64 proj normalized random cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('cv_label2_mobilenet_crop_64.pkl','wb') as f:\n",
    "    pickle.dump(cv_label2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.42117233, -10.81699934,  -8.40923982,  -3.90688966,\n",
       "        -1.49081772,  -0.79319794,  -0.61772669,  -0.56096464,\n",
       "        -0.53365644,  -0.51455953])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop64 proj normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.76203842,  -9.08192111,  -8.67627585,  -7.93668639,\n",
       "        -3.32040689,  -1.61058029,  -1.13415802,  -0.98432688,\n",
       "        -0.91080838,  -0.86552122])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop64 proj normalized prob weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.42117233, -10.81699934,  -8.40923982,  -3.90688966,\n",
       "        -1.49081772,  -0.79319794,  -0.61772669,  -0.56096464,\n",
       "        -0.53365644,  -0.51455953])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop64 proj normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.3034167 , -2.87024781, -1.16681787, -0.68667234, -0.50216841,\n",
       "       -0.46188559, -0.43882784, -0.42890286, -0.42718655, -0.43352677])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # crop64 proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.7, 5.7, 5.7, 5.7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # mini weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.31475597, -8.29894242, -2.84744388, -1.16951128, -0.74142058,\n",
       "       -0.62891488, -0.60055984, -0.58071633, -0.56407921, -0.55960338])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # not weighted proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.68017027, 10.68017027, 10.09729052,  9.80483741,  9.63690119,\n",
       "        9.57527796,  9.54491318,  9.53208126,  9.52514296,  9.51149031])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # not weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.59965186,  9.4570564 ,  9.96051226, 10.08321655,  9.88160343,\n",
       "        9.84861552,  9.80512292,  9.85751204,  9.71321238,  9.77365697])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_label2.scores_['1'],axis=0) # weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_test_dataset = dataset.build_dataset(\n",
    "    [os.path.join(data_path, \"public_test\")],\n",
    "    sample_processor=domain.process_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_dataset = dataset.build_dataset(\n",
    "    [os.path.join(data_path, \"private_test\")],\n",
    "    sample_processor=domain.process_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['1', '10', '20', '3', '30', '6']  # alphabet order\n",
    "class2id = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "class ModelWithProjection:\n",
    "    def __init__(self, model, side):\n",
    "        self.model = model\n",
    "        self.side = side\n",
    "    def predict(self, x):\n",
    "        x_proj = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        return self.model.predict(x_proj)\n",
    "    def predict_proba(self, x):\n",
    "        x_proj = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        probs = self.model.predict_proba(x_proj)\n",
    "        probs_zero = probs[:, class2id['1']] \\\n",
    "            + probs[:, class2id['6']] + probs[:, class2id['20']]\n",
    "        probs_one = 1 - probs_zero\n",
    "        if self.side == 0:\n",
    "            return probs_one\n",
    "        return probs_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['1', '10', '20', '3', '30', '6']  # alphabet order\n",
    "class2id = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "class KNNModelWithProjection:\n",
    "    def __init__(self, model, mode):\n",
    "        self.model = model\n",
    "        assert mode in [\"train\", \"test\"]\n",
    "        self.mode = mode\n",
    "    def predict(self, x):\n",
    "        x_proj = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        return self.model.predict(x_proj)\n",
    "    def predict_proba(self, x):\n",
    "        x_proj = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        probs = self.model.predict_proba(x_proj)\n",
    "        probs_zero = probs[:, class2id['1']] \\\n",
    "            + probs[:, class2id['6']] + probs[:, class2id['20']]\n",
    "        probs_one = 1 - probs_zero\n",
    "        if self.mode == \"train\":\n",
    "            return probs_one\n",
    "        return probs_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLightModel:\n",
    "    def __init__(self, energy_model, particle_model):\n",
    "        self.energy_model = energy_model\n",
    "        self.particle_model = particle_model\n",
    "        \n",
    "    def predict_particle(self, x):\n",
    "        x = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        return self.particle_model.predict_proba(x)[:, 0]\n",
    "    \n",
    "    def predict_energy(self, x):\n",
    "        x = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        return self.energy_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLightModel:\n",
    "    # X is for 1 and 6, also 30 have 2 clusters\n",
    "    CLUSTER_TO_ENERGY = ['X', '20', '30', '3', '10', '30']\n",
    "    CLUSTER_1_6_MEDIAN = 0.8917\n",
    "    CLASSES = ['1', '10', '20', '3', '30', '6']  # alphabet order\n",
    "    CLASS2ID = {c:i for i,c in enumerate(CLASSES)}\n",
    "    def __init__(self, energy_model, cluster_model):\n",
    "        self.energy_model = energy_model\n",
    "        self.cluster_model = cluster_model\n",
    "        \n",
    "    def predict_particle(self, x):\n",
    "        x = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        probs = self.energy_model.predict_proba(x)\n",
    "        probs_zero = probs[:, self.CLASS2ID['1']] \\\n",
    "            + probs[:, self.CLASS2ID['6']] + probs[:, self.CLASS2ID['20']]\n",
    "        return probs_zero\n",
    "        \n",
    "    def predict_energy(self, x):\n",
    "        x = apply_random_projection_and_normalize(x, to_dim=64)\n",
    "        clusters = self.cluster_model.predict(x)\n",
    "        probs = self.energy_model.predict_proba(x)[:, 0]  # 0 is for '1' energy\n",
    "        is_energy_class_1 = probs > self.CLUSTER_1_6_MEDIAN\n",
    "        result = np.array([self.CLUSTER_TO_ENERGY[x] for x in clusters])\n",
    "        for i, c in enumerate(result):\n",
    "            if c != \"X\":\n",
    "                continue\n",
    "            result[i] = '1' if is_energy_class_1[i] else '6'\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cv_label1_mobilenet_crop_64.pkl', 'rb') as f:\n",
    "    cv_label1 = pickle.load(f)\n",
    "    \n",
    "with open('cv_label2_mobilenet_crop_64.pkl', 'rb') as f:\n",
    "    cv_label2 = pickle.load(f)\n",
    "    \n",
    "with open('cv_label2_tsne_test_v4.pkl', 'rb') as f:\n",
    "    cv_cluster_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = TrainLightModel(cv_label2, cv_label1)\n",
    "test_model = TestLightModel(cv_label2, cv_cluster_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0576330094366866\n",
      "0.047606136121961996\n"
     ]
    }
   ],
   "source": [
    "a = cv_label1.coef_\n",
    "b = cv_label1_test.coef_\n",
    "print(np.sum(a * b) / (np.sum(a ** 2) * np.sum(b ** 2)) ** 0.5)\n",
    "\n",
    "a = cv_label2.coef_\n",
    "b = cv_label2_test.coef_\n",
    "print(np.sum(a * b) / (np.sum(a ** 2) * np.sum(b ** 2)) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ModelWithProjection(cv_label1, 0)\n",
    "model2 = ModelWithProjection(cv_label2, 0)\n",
    "model1_test = ModelWithProjection(cv_label1_test, 1)\n",
    "model2_test = ModelWithProjection(cv_label2_test, 1)\n",
    "\n",
    "train_knn = KNNModelWithProjection(train_knn_model, mode=\"train\")\n",
    "test_knn = KNNModelWithProjection(train_knn_model, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = dataset.build_batched_dataset(\n",
    "    [train_path + '/NR', train_path + '/ER'],\n",
    "    domain.process_test_sample, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sergmiller/Documents/my/IDAO-2021/data/idao_dataset/train/NR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.dataset.LabeledDataset at 0x13fe5efd0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_gen_res = pipe.apply_all_models_to_test_dataset_gen(\n",
    "    dataset.build_batched_dataset(\n",
    "        [train_path + '/NR', train_path + '/ER'],\n",
    "        domain.process_test_sample,\n",
    "        limit=30,\n",
    "        batch_size=5),\n",
    "    croped_mobilenet,\n",
    "    test_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9984526544029055', '1'],\n",
       "       ['0.3886304253671687', '10'],\n",
       "       ['0.9653752864630754', '3'],\n",
       "       ['0.9996106760828959', '1'],\n",
       "       ['0.9953614174696219', '1'],\n",
       "       ['0.8904632949332579', '6'],\n",
       "       ['0.9993765763980791', '1'],\n",
       "       ['0.999394378501643', '20'],\n",
       "       ['0.37708093844184676', '10'],\n",
       "       ['0.9987530131448602', '1'],\n",
       "       ['0.9993051636800571', '3'],\n",
       "       ['0.9155591488125162', '10'],\n",
       "       ['0.9999812026046264', '20'],\n",
       "       ['0.999578346846683', '1'],\n",
       "       ['0.9973396103020259', '20'],\n",
       "       ['0.9991084798795271', '1'],\n",
       "       ['0.7715812334624321', '6'],\n",
       "       ['0.4635263318338644', '10'],\n",
       "       ['0.9872004652991844', '1'],\n",
       "       ['0.9991286840717415', '1'],\n",
       "       ['0.9979385129938799', '1'],\n",
       "       ['0.3687776504179605', '10'],\n",
       "       ['0.45959113805697394', '10'],\n",
       "       ['0.999984002742654', '20'],\n",
       "       ['0.9992324237791333', '1'],\n",
       "       ['0.4813468244836658', '10'],\n",
       "       ['0.9982911539407354', '20'],\n",
       "       ['0.9956133848956189', '1'],\n",
       "       ['0.9990739963675669', '1'],\n",
       "       ['0.8518989080615507', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_gen_res.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.010279725486114555', '1'],\n",
       "       ['0.5568204410481309', '3'],\n",
       "       ['0.3060291514024761', '20'],\n",
       "       ['0.011139884657300647', '1'],\n",
       "       ['0.032098396519642636', '1'],\n",
       "       ['0.09628900990200828', '6'],\n",
       "       ['0.006483422501263769', '1'],\n",
       "       ['0.0006112361570782543', '20'],\n",
       "       ['0.5851755514489945', '3'],\n",
       "       ['0.01542081391474992', '1'],\n",
       "       ['0.002050209814641324', '20'],\n",
       "       ['0.11915368040374896', '6'],\n",
       "       ['7.352136998317604e-06', '20'],\n",
       "       ['0.020646139737896863', '1'],\n",
       "       ['0.010103005007861987', '20'],\n",
       "       ['0.018564567352344352', '1'],\n",
       "       ['0.13214453175246943', '6'],\n",
       "       ['0.6527747072954038', '3'],\n",
       "       ['0.03184283434211699', '1'],\n",
       "       ['0.004951170825228224', '1'],\n",
       "       ['0.03214299068082416', '1'],\n",
       "       ['0.518769798491739', '3'],\n",
       "       ['0.31974648569357567', '3'],\n",
       "       ['7.95666890115454e-05', '20'],\n",
       "       ['0.03715001142309382', '1'],\n",
       "       ['0.6985056287157032', '3'],\n",
       "       ['0.0021957169942580235', '20'],\n",
       "       ['0.02220269091252891', '1'],\n",
       "       ['0.002056443621007986', '1'],\n",
       "       ['0.053916900093964326', '20']], dtype='<U32')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_gen_res.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1178.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0001223936709412919 0.03147750951722001\n",
      "-0.0001223936709412919 0.03147750951722001\n"
     ]
    }
   ],
   "source": [
    "sample_res = pipe.apply_all_models_to_test_dataset(\n",
    "    sample_dataset,\n",
    "    croped_mobilenet,\n",
    "    \n",
    "    'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20,), (20, 1000))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res.tags.shape, sample_res.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_test_predictions = pipe.apply_all_models_to_test_dataset(\n",
    "    pub_test_dataset, croped_mobilenet, train_model, 'pub_test_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 7.39 s, total: 32 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pub_test_predictions = pipe.apply_all_models_to_test_dataset_gen(\n",
    "    dataset.build_batched_dataset(\n",
    "        [os.path.join(data_path, \"public_test\")],\n",
    "        domain.process_test_sample,\n",
    "#         limit=30,\n",
    "        batch_size=48),\n",
    "    croped_mobilenet_v2,\n",
    "    model1,\n",
    "    model2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, 2)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_test_predictions.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_predictions = pipe.apply_all_models_to_test_dataset(\n",
    "    private_test_dataset, croped_mobilenet, test_model, 'private_test_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15058, 2)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 2476, '20': 2580, '3': 2588, '30': 2475, '10': 2390, '6': 2549})"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(private_test_predictions.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 2476, '20': 2580, '10': 2588, '30': 2475, '3': 2390, '6': 2549})"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(private_test_predictions.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.26182865573803904', '6'],\n",
       "       ['0.9999469809004441', '30'],\n",
       "       ['0.994685582236025', '30'],\n",
       "       ['0.9996005861276018', '30'],\n",
       "       ['0.2689433565112792', '6'],\n",
       "       ['0.003515667459942362', '20'],\n",
       "       ['0.9612760169881223', '30'],\n",
       "       ['0.0009252600656490806', '20'],\n",
       "       ['0.9149720511722139', '3'],\n",
       "       ['0.010044656387843687', '1']], dtype='<U32')"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_test_predictions.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'6': 283, '30': 232, '20': 252, '3': 227, '1': 257, '10': 251})"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pub_test_predictions.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9792358554695156', '1'],\n",
       "       ['0.9919915891993591', '1'],\n",
       "       ['0.9994226944804909', '20'],\n",
       "       ['0.9966748749618295', '1'],\n",
       "       ['0.0012142244601400707', '10'],\n",
       "       ['1.3964989114112017e-07', '30'],\n",
       "       ['0.9960912836469804', '1'],\n",
       "       ['1.1879640650859424e-07', '30'],\n",
       "       ['0.9922731706903584', '1'],\n",
       "       ['0.02099422101495153', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9792358554695156', '1'],\n",
       "       ['0.9919915891993591', '1'],\n",
       "       ['0.9994226944804909', '20'],\n",
       "       ['0.9966748749618295', '1'],\n",
       "       ['0.0012142244601400707', '10'],\n",
       "       ['1.3964989114112017e-07', '30'],\n",
       "       ['0.9960912836469804', '1'],\n",
       "       ['1.1879640650859424e-07', '30'],\n",
       "       ['0.9922731706903584', '1'],\n",
       "       ['0.02099422101495153', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9792358554695156', '1'],\n",
       "       ['0.9919915891993591', '1'],\n",
       "       ['0.9994226944804909', '20'],\n",
       "       ['0.9966748749618295', '1'],\n",
       "       ['0.0012142244601400707', '3'],\n",
       "       ['1.3964989114112017e-07', '30'],\n",
       "       ['0.9960912836469804', '1'],\n",
       "       ['1.1879640650859424e-07', '30'],\n",
       "       ['0.9922731706903584', '1'],\n",
       "       ['0.02099422101495153', '10']], dtype='<U32')"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = np.argmax(cv_label2_test.predict_proba(\n",
    "    apply_random_projection_and_normalize(\n",
    "        private_test_predictions_v2.samples, 64)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = [x[0] for x in \\\n",
    " sorted([(x,y) for x,y in Counter(class_probs).items()], key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 5043, 20: 2588, 3: 2554, 10: 1067, 30: 1398, 6: 2408})"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([classes[x] for x in class_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x, T=1: np.exp(x/T) / np.sum(np.exp(x/T), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = softmax(cv_label2_test.predict_log_proba(\n",
    "    apply_random_projection_and_normalize(\n",
    "        private_test_predictions_v2.samples, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.86185202e-01, 2.77022095e-04, 1.00252324e-03, 1.29241909e-03,\n",
       "        2.16445927e-03, 9.07837444e-03],\n",
       "       [9.94023786e-01, 8.09590934e-05, 2.57404657e-04, 7.39539821e-04,\n",
       "        1.25168709e-03, 3.64662377e-03],\n",
       "       [1.06847905e-12, 1.57469843e-03, 9.97773041e-01, 1.20464159e-06,\n",
       "        5.00376042e-04, 1.50680338e-04],\n",
       "       ...,\n",
       "       [7.06865148e-07, 2.03489030e-02, 1.44733084e-04, 9.73087099e-01,\n",
       "        4.46271615e-03, 1.95584237e-03],\n",
       "       [9.93922180e-01, 1.90513468e-04, 4.38566173e-04, 6.22447723e-04,\n",
       "        1.39403185e-03, 3.43226064e-03],\n",
       "       [1.41693140e-07, 7.68104047e-01, 3.75737975e-03, 2.00075804e-03,\n",
       "        2.25674680e-01, 4.62993196e-04]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32796521, 0.0761533 , 0.17277551, 0.17387258, 0.09140459,\n",
       "       0.1578288 ])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:, 0] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs /= np.mean(probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.95176143e+00, 6.86729899e-08, 6.90495882e-03, 8.10521011e-03,\n",
       "       1.77041445e-04, 4.85137528e-02])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs /= np.sum(probs, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08383862, 0.06227651, 0.17835935, 0.17839079, 0.09267871,\n",
       "       0.15294015])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4953, 2: 2588, 3: 2554, 1: 1067, 5: 2498, 4: 1398})"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 2513, 2.0: 2509, 1.0: 2509, 3.0: 2509, 4.0: 2509, 5.0: 2509})"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(normalize_probs(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_predictions_v2 = applier.build_embd_dataset(\n",
    "    private_test_dataset, croped_mobilenet_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_predictions_v2.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_predictions_v2.save('../data/private_test_predictions_embeds_crop_128_proj_64.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 8s, sys: 1min 15s, total: 5min 23s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "private_test_predictions = pipe.apply_all_models_to_test_dataset_gen(\n",
    "    dataset.build_batched_dataset(\n",
    "        [os.path.join(data_path, \"private_test\")],\n",
    "        domain.process_test_sample,\n",
    "#         limit=30,\n",
    "        batch_size=48),\n",
    "    croped_mobilenet_v2,\n",
    "    model1_test,\n",
    "    model2_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15058, 2)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels.shape\n",
    "# private_test_predictions.save('../data/private_test_predictions_embeds_crop_64_proj_64_logreg_gold.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [09:44<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 56.2 s, total: 3min 6s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "private_test_predictions = pipe.apply_all_models_to_test_dataset_gen(\n",
    "    dataset.build_batched_dataset(\n",
    "        [os.path.join(data_path, \"private_test\")],\n",
    "        domain.process_test_sample,\n",
    "#         limit=30,\n",
    "        batch_size=256),\n",
    "    croped_mobilenet,\n",
    "    model1,\n",
    "    model2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_test_predictions.save('../data/pub_test_predictions_embeds_crop_64_proj_64_logreg_gold_cluster.npz')\n",
    "private_test_predictions.save('../data/private_test_predictions_embeds_crop_64_proj_64_logreg_gold_cluster.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.3378901908102402', '6'],\n",
       "       ['0.9999999919483673', '30'],\n",
       "       ['0.9999065738685704', '30'],\n",
       "       ['0.9999999999791894', '30'],\n",
       "       ['0.3759892870655247', '6'],\n",
       "       ['0.004666365980876663', '20'],\n",
       "       ['0.9999976413778514', '30'],\n",
       "       ['0.030180854349445396', '20'],\n",
       "       ['0.7870471909789434', '3'],\n",
       "       ['0.0993337189800595', '1'],\n",
       "       ['0.539335781531699', '3'],\n",
       "       ['0.14496419666149574', '1'],\n",
       "       ['0.997725842475252', '10'],\n",
       "       ['0.9683279685545914', '3'],\n",
       "       ['0.9999972174859065', '30'],\n",
       "       ['0.025447901959109287', '20'],\n",
       "       ['0.0010731573218798474', '20'],\n",
       "       ['0.7988548109020216', '3'],\n",
       "       ['0.18921205947785824', '6'],\n",
       "       ['0.9848724374736006', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_test_predictions.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.26182865573803904', '6'],\n",
       "       ['0.9999469809004441', '30'],\n",
       "       ['0.994685582236025', '30'],\n",
       "       ['0.9996005861276018', '30'],\n",
       "       ['0.2689433565112792', '6'],\n",
       "       ['0.003515667459942362', '20'],\n",
       "       ['0.9612760169881223', '30'],\n",
       "       ['0.0009252600656490806', '20'],\n",
       "       ['0.9149720511722139', '3'],\n",
       "       ['0.010044656387843687', '1'],\n",
       "       ['0.23983726364156244', '6'],\n",
       "       ['0.020735506351094224', '1'],\n",
       "       ['0.9999999504782926', '30'],\n",
       "       ['0.956706470441371', '3'],\n",
       "       ['0.99999989161482', '30'],\n",
       "       ['8.372011058233042e-05', '20'],\n",
       "       ['0.002204674637787951', '20'],\n",
       "       ['0.7208994073369936', '3'],\n",
       "       ['0.7634096433805673', '3'],\n",
       "       ['0.9631948283583563', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_test_predictions.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9792358554695156', '1'],\n",
       "       ['0.9919915891993591', '1'],\n",
       "       ['0.9994226944804909', '20'],\n",
       "       ['0.9966748749618295', '1'],\n",
       "       ['0.0012142244601400707', '10'],\n",
       "       ['1.3964989114112017e-07', '30'],\n",
       "       ['0.9960912836469804', '1'],\n",
       "       ['1.1879640650859424e-07', '30'],\n",
       "       ['0.9922731706903584', '1'],\n",
       "       ['0.02099422101495153', '3'],\n",
       "       ['0.6750038854497894', '6'],\n",
       "       ['0.004365346519615135', '10'],\n",
       "       ['0.9891714148855616', '1'],\n",
       "       ['0.1528313444550557', '3'],\n",
       "       ['0.022262392206576328', '10'],\n",
       "       ['0.025202973985660498', '10'],\n",
       "       ['0.8630700657809736', '6'],\n",
       "       ['0.9970432159909094', '20'],\n",
       "       ['0.000985656550775173', '10'],\n",
       "       ['0.039770778478267516', '3']], dtype='<U32')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9911522615699119', '1'],\n",
       "       ['0.9898863167618781', '1'],\n",
       "       ['0.9975694862960423', '20'],\n",
       "       ['0.994469590082026', '1'],\n",
       "       ['0.001587912312541111', '3'],\n",
       "       ['0.004563403274278065', '10'],\n",
       "       ['0.9894291765804616', '1'],\n",
       "       ['2.9201224088725173e-05', '30'],\n",
       "       ['0.9943325573597149', '1'],\n",
       "       ['0.8266391504277366', '6'],\n",
       "       ['0.9939690036360291', '1'],\n",
       "       ['0.009624929708425413', '3'],\n",
       "       ['0.9864045860065688', '1'],\n",
       "       ['0.9060428678304986', '6'],\n",
       "       ['0.0477362240982497', '3'],\n",
       "       ['0.10869237969293082', '3'],\n",
       "       ['0.9816241261918957', '1'],\n",
       "       ['0.9905146524467872', '20'],\n",
       "       ['0.03342019591126544', '3'],\n",
       "       ['0.8334123526160188', '6']], dtype='<U32')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.9959382927115767', '10'],\n",
       "       ['0.34786341947131505', '20'],\n",
       "       ['0.05196240581725098', '1'],\n",
       "       ['0.00018201494640013305', '20'],\n",
       "       ['0.05203463857686008', '1'],\n",
       "       ['0.2177242842992685', '6'],\n",
       "       ['0.9999999998696617', '30'],\n",
       "       ['0.9718452052039402', '3'],\n",
       "       ['0.9211651566940707', '10'],\n",
       "       ['0.7965147791960825', '3'],\n",
       "       ['0.058037786211757036', '1'],\n",
       "       ['0.5909350742715967', '3'],\n",
       "       ['6.420147295393974e-05', '20'],\n",
       "       ['0.30202234373113057', '6'],\n",
       "       ['0.034833417597421645', '20'],\n",
       "       ['0.0052965988099766825', '20'],\n",
       "       ['0.9999980441823341', '30'],\n",
       "       ['0.00032812345435850876', '20'],\n",
       "       ['0.00017769293317138057', '20'],\n",
       "       ['0.02835726140848327', '1']], dtype='<U32')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NR', '20'], dtype='<U21')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_dataset.labels[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03047804, -0.00299443,  0.00421359, -0.00104387,  0.01232895,\n",
       "       -0.04698811,  0.01365007,  0.00984104, -0.01438479,  0.00709643,\n",
       "       -0.01260175,  0.01113308,  0.01550436,  0.01529617,  0.02958233,\n",
       "        0.01846632,  0.00673424,  0.00285218, -0.02472172, -0.00087346,\n",
       "       -0.00712186,  0.01051676,  0.01336658, -0.01391483, -0.02263418,\n",
       "       -0.01763663, -0.01081363,  0.0033536 , -0.00226466,  0.01420989,\n",
       "       -0.01401142,  0.00011301, -0.01173379,  0.00068134, -0.00210718,\n",
       "        0.00525672,  0.04584639,  0.05256893, -0.03822729, -0.00809548,\n",
       "       -0.00366252,  0.0191488 ,  0.01710513, -0.04430108, -0.0026584 ,\n",
       "        0.02376626, -0.04213992, -0.00872008,  0.04732761, -0.00681707,\n",
       "       -0.01645056,  0.00433374,  0.00466219,  0.0413122 , -0.02365083,\n",
       "       -0.00524169,  0.00728909, -0.00242737,  0.02394251,  0.01028041,\n",
       "       -0.01143752, -0.01046035, -0.02952652,  0.01807905])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_emb_dataset.samples[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01972202, -0.01178834, -0.00035343,  0.01486317,  0.0181566 ,\n",
       "        0.00706721,  0.01408706,  0.00091763,  0.0050736 ,  0.00428946,\n",
       "       -0.00723214,  0.02368503,  0.01099412,  0.01939142,  0.01678304,\n",
       "        0.00334494, -0.00132331, -0.01432781,  0.02936942,  0.00916131,\n",
       "        0.0539712 ,  0.01643607,  0.03480771,  0.00625478, -0.02917419,\n",
       "       -0.00212405, -0.0255396 , -0.0062858 , -0.01322827,  0.0272788 ,\n",
       "       -0.0080818 ,  0.0130678 ,  0.01331722, -0.01461027,  0.02729295,\n",
       "       -0.03326168,  0.04900266,  0.04481307, -0.01114589, -0.01921125,\n",
       "       -0.00745997, -0.00225918,  0.00881823,  0.00020083,  0.01906651,\n",
       "        0.00079661, -0.01195286, -0.02045391,  0.03209557, -0.00191046,\n",
       "       -0.01645168,  0.02137357, -0.02717195,  0.00501937, -0.00775522,\n",
       "        0.02002678,  0.01298958, -0.00305611,  0.00933072, -0.00010928,\n",
       "       -0.04163213,  0.01473438,  0.00952219,  0.02497678])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_emb_dataset.samples[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   3.,  13.,  50., 229.,  65.,  18.,   5.]),\n",
       " array([-447.53084161, -379.54630135, -311.56176108, -243.57722081,\n",
       "        -175.59268055, -107.60814028,  -39.62360001,   28.36094025,\n",
       "          96.34548052,  164.33002079,  232.31456106]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv_label2.coef_.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  20.96312716,  -79.07128255,   11.66483233,   80.89987241,\n",
       "         -43.80537113,   64.25767144,  219.23530437,   22.93554177,\n",
       "         265.36746854,  -33.54146824, -196.88350417,   35.95572866,\n",
       "          99.85359265,   23.16084763,  -91.41195093,   22.29117439,\n",
       "         -55.74464263,    7.28333537,  -51.68657628,   20.49341137,\n",
       "        -105.09392732,   -1.84311876,  -78.87131962,  -42.52253822,\n",
       "         -62.60578366, -149.05189341,  -83.43678992,    1.67566844,\n",
       "         -60.10865765,  -56.06082565,  -63.95800266,   73.28256726,\n",
       "          -7.44540734,  182.74363946, -139.9036988 ,   -6.16706125,\n",
       "         304.17830098,  -18.9391462 ,  -95.16912285,  -74.88951623,\n",
       "         158.21065363,   17.16033088,  -83.99724088,  184.48995308,\n",
       "        -192.13903726, -114.3753671 ,   46.24572781,  128.37314703,\n",
       "          81.23557407,  -73.74160903,  372.75343435,   37.51757257,\n",
       "          -2.45943445,   46.63488526,   92.40010019,  121.45467201,\n",
       "         -72.95402334,   -3.38002643,  202.00664418,  -37.18832029,\n",
       "        -418.86967402, -174.3773371 , -182.58691319,  -23.94621789]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.63695404])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0033285900019394223 0.12290091089093758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99272931, 0.00727069]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict_proba(proj_emb_dataset.samples[4].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0033285900019394223 0.12290091089093758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.03398938e-22, 3.10317335e-13, 2.11941341e-07, 5.54606938e-15,\n",
       "        9.99999788e-01, 1.97000441e-12]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_proba(proj_emb_dataset.samples[2].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = dataset.LabeledDataset.merge(\n",
    "    pub_test_predictions, private_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'6': 263, '30': 249, '20': 252, '3': 223, '1': 266, '10': 249})"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pub_test_predictions.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 2476, '20': 2580, '10': 2588, '30': 2475, '3': 2390, '6': 2549})"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(private_test_predictions.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 2180, '6': 2256, '20': 2210, '3': 2245, '30': 2239, '10': 2274})"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_dataset.labels[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'NR': 6646, 'ER': 6758}),\n",
       " Counter({'0.9911522615699119': 1,\n",
       "          '0.9898863167618781': 1,\n",
       "          '0.9975694862960423': 1,\n",
       "          '0.994469590082026': 1,\n",
       "          '0.001587912312541111': 1,\n",
       "          '0.004563403274278065': 1,\n",
       "          '0.9894291765804616': 1,\n",
       "          '2.9201224088725173e-05': 1,\n",
       "          '0.9943325573597149': 1,\n",
       "          '0.8266391504277366': 1,\n",
       "          '0.9939690036360291': 1,\n",
       "          '0.009624929708425413': 1,\n",
       "          '0.9864045860065688': 1,\n",
       "          '0.9060428678304986': 1,\n",
       "          '0.0477362240982497': 1,\n",
       "          '0.10869237969293082': 1,\n",
       "          '0.9816241261918957': 1,\n",
       "          '0.9905146524467872': 1,\n",
       "          '0.03342019591126544': 1,\n",
       "          '0.8334123526160188': 1,\n",
       "          '0.9211991164183413': 1,\n",
       "          '0.9798029301985187': 1,\n",
       "          '0.12408633062281865': 1,\n",
       "          '0.9911936593314615': 1,\n",
       "          '0.9778787760308744': 1,\n",
       "          '0.012747974338416967': 1,\n",
       "          '0.001682139771370493': 1,\n",
       "          '0.02756117858458861': 1,\n",
       "          '0.9901687267547215': 1,\n",
       "          '0.04050513553493237': 1,\n",
       "          '0.9441218400044359': 1,\n",
       "          '0.005218759916166831': 1,\n",
       "          '0.9884995138388224': 1,\n",
       "          '0.0027432869387125232': 1,\n",
       "          '0.09215586246081858': 1,\n",
       "          '0.0016284651099972055': 1,\n",
       "          '0.10747673365824936': 1,\n",
       "          '0.94638343353632': 1,\n",
       "          '0.03940949740680436': 1,\n",
       "          '0.0049058085445176595': 1,\n",
       "          '0.9966037164035126': 1,\n",
       "          '0.9152515140371833': 1,\n",
       "          '0.9959717794706417': 1,\n",
       "          '0.980216943937057': 1,\n",
       "          '0.9882531063768054': 1,\n",
       "          '0.9922080837404015': 1,\n",
       "          '0.8934070280326133': 1,\n",
       "          '0.9925488152818632': 1,\n",
       "          '0.9962787184663844': 1,\n",
       "          '0.9929631185179396': 1,\n",
       "          '0.9774285977569135': 1,\n",
       "          '0.99391283433061': 1,\n",
       "          '0.9918244929085744': 1,\n",
       "          '0.9840200875500104': 1,\n",
       "          '0.9975211000498697': 1,\n",
       "          '0.9804553472393898': 1,\n",
       "          '0.023368270979184567': 1,\n",
       "          '0.9913192753740079': 1,\n",
       "          '0.8542938377944324': 1,\n",
       "          '0.28910447104882203': 1,\n",
       "          '0.8192949825632133': 1,\n",
       "          '0.9913081119702652': 1,\n",
       "          '0.9509090759097387': 1,\n",
       "          '0.7786342021987636': 1,\n",
       "          '0.9900884586264781': 1,\n",
       "          '0.9885248988081516': 1,\n",
       "          '0.007264617280171997': 1,\n",
       "          '0.7465888824087733': 1,\n",
       "          '0.9917283478074401': 1,\n",
       "          '0.932660740114313': 1,\n",
       "          '0.9932054030404365': 1,\n",
       "          '0.9893132834549191': 1,\n",
       "          '0.028862835990100498': 1,\n",
       "          '0.02209191567332839': 1,\n",
       "          '0.9794078144759649': 1,\n",
       "          '0.3250061438588566': 1,\n",
       "          '0.9323668530362003': 1,\n",
       "          '0.026758164859509572': 1,\n",
       "          '0.01959330340330436': 1,\n",
       "          '0.9838692517706822': 1,\n",
       "          '0.9904855028470176': 1,\n",
       "          '0.9924204561494796': 1,\n",
       "          '0.7032633209875954': 1,\n",
       "          '0.9734147709044312': 1,\n",
       "          '0.01489095080423642': 1,\n",
       "          '0.0022678996861791056': 1,\n",
       "          '0.1316458560761504': 1,\n",
       "          '0.9954496832966047': 1,\n",
       "          '0.8070842874250498': 1,\n",
       "          '0.9945758473040782': 1,\n",
       "          '0.9574521521408891': 1,\n",
       "          '0.01147497526368582': 1,\n",
       "          '0.9941213496828007': 1,\n",
       "          '0.9899650691578139': 1,\n",
       "          '0.9871434642469015': 1,\n",
       "          '0.9847673868349035': 1,\n",
       "          '0.9964373897786806': 1,\n",
       "          '0.9850491172901645': 1,\n",
       "          '0.9950343331095135': 1,\n",
       "          '0.04470788363868459': 1,\n",
       "          '0.9894755717948699': 1,\n",
       "          '0.9817948116683374': 1,\n",
       "          '0.9933793544055951': 1,\n",
       "          '0.9947460349442169': 1,\n",
       "          '0.9940944066465026': 1,\n",
       "          '0.9939245173965017': 1,\n",
       "          '0.9920655980331077': 1,\n",
       "          '0.9906810585333352': 1,\n",
       "          '0.942455327898898': 1,\n",
       "          '0.032654210894945135': 1,\n",
       "          '0.44548556752344326': 1,\n",
       "          '0.9571079538133349': 1,\n",
       "          '0.010993502154352805': 1,\n",
       "          '0.997964200873944': 1,\n",
       "          '0.9902022870994689': 1,\n",
       "          '0.9609490380816326': 1,\n",
       "          '0.9880046625755587': 1,\n",
       "          '0.9884425433893332': 1,\n",
       "          '0.9347315699427454': 1,\n",
       "          '0.9923782970036107': 1,\n",
       "          '0.9891228842748027': 1,\n",
       "          '0.1614697408668117': 1,\n",
       "          '0.04986748649619663': 1,\n",
       "          '0.9959678069949801': 1,\n",
       "          '0.9321468401232044': 1,\n",
       "          '0.9938544714177691': 1,\n",
       "          '0.9899026923778205': 1,\n",
       "          '0.9891474750591573': 1,\n",
       "          '0.016397059663300146': 1,\n",
       "          '6.253874408538612e-05': 1,\n",
       "          '0.9922452553273036': 1,\n",
       "          '0.9949694610101363': 1,\n",
       "          '0.9951165948473163': 1,\n",
       "          '0.990406569112513': 1,\n",
       "          '0.002575846740162422': 1,\n",
       "          '0.0011240224526262374': 1,\n",
       "          '0.9963452720501171': 1,\n",
       "          '0.9980211727222015': 1,\n",
       "          '0.991701312921599': 1,\n",
       "          '0.01198857676560281': 1,\n",
       "          '0.02751004257590238': 1,\n",
       "          '0.04896087643737572': 1,\n",
       "          '0.02238525311793599': 1,\n",
       "          '0.9942363529089826': 1,\n",
       "          '0.02168164179121993': 1,\n",
       "          '0.12585848929844387': 1,\n",
       "          '0.1514017419448732': 1,\n",
       "          '0.9947505356805831': 1,\n",
       "          '0.03139604118263098': 1,\n",
       "          '0.9903581481309581': 1,\n",
       "          '0.0058047297156735445': 1,\n",
       "          '0.008291981412711624': 1,\n",
       "          '0.9909074113417907': 1,\n",
       "          '0.0007629270636711691': 1,\n",
       "          '0.9950245207220353': 1,\n",
       "          '0.9961671960408982': 1,\n",
       "          '0.9201921389269113': 1,\n",
       "          '0.9859682456467292': 1,\n",
       "          '0.6952214968603742': 1,\n",
       "          '0.9864444429088098': 1,\n",
       "          '0.9952122009348143': 1,\n",
       "          '0.9941347001958811': 1,\n",
       "          '0.9905354312855041': 1,\n",
       "          '0.9989069372456074': 1,\n",
       "          '0.9884750200281276': 1,\n",
       "          '0.9875342896989524': 1,\n",
       "          '0.9958865017956547': 1,\n",
       "          '0.9906954414570106': 1,\n",
       "          '0.9825707836012122': 1,\n",
       "          '0.0004930012343093604': 1,\n",
       "          '0.0054559990810339265': 1,\n",
       "          '0.9945236839733459': 1,\n",
       "          '0.9895053397822552': 1,\n",
       "          '0.997039644554188': 1,\n",
       "          '0.1413296886459413': 1,\n",
       "          '0.8755155503534489': 1,\n",
       "          '0.38689869559910384': 1,\n",
       "          '0.005810755157052172': 1,\n",
       "          '0.9946274014095893': 1,\n",
       "          '0.9935703836751187': 1,\n",
       "          '0.9897093887974348': 1,\n",
       "          '0.9899167755182331': 1,\n",
       "          '0.9700362456796034': 1,\n",
       "          '0.979477337674583': 1,\n",
       "          '0.9961414179203917': 1,\n",
       "          '0.05012298067763909': 1,\n",
       "          '0.9956861986479695': 1,\n",
       "          '0.9916122036715695': 1,\n",
       "          '0.98649082012488': 1,\n",
       "          '0.9918122472882264': 1,\n",
       "          '0.9933661717261513': 1,\n",
       "          '0.014064023329453978': 1,\n",
       "          '0.9809657202070019': 1,\n",
       "          '0.9884228741779101': 1,\n",
       "          '0.9869954778146073': 1,\n",
       "          '0.04108010505469672': 1,\n",
       "          '0.9943061972666906': 1,\n",
       "          '0.989758184948811': 1,\n",
       "          '0.23021741893373804': 1,\n",
       "          '0.010910749022218724': 1,\n",
       "          '0.3114570891166275': 1,\n",
       "          '0.9969078849751352': 1,\n",
       "          '0.9945239510393499': 1,\n",
       "          '0.994227584675757': 1,\n",
       "          '0.9970439500830148': 1,\n",
       "          '0.30937224822893716': 1,\n",
       "          '0.9878266535031188': 1,\n",
       "          '0.0019457851938310656': 1,\n",
       "          '0.0005117050196386862': 1,\n",
       "          '0.013722756846152411': 1,\n",
       "          '0.9925519106957208': 1,\n",
       "          '0.18136233650092456': 1,\n",
       "          '0.9892819249542775': 1,\n",
       "          '0.9923523874482629': 1,\n",
       "          '0.9846656019932926': 1,\n",
       "          '0.9945251138173511': 1,\n",
       "          '0.9938578244480596': 1,\n",
       "          '0.9959941087483483': 1,\n",
       "          '5.4499429977365325e-05': 1,\n",
       "          '0.9893164311597694': 1,\n",
       "          '0.9947471509473061': 1,\n",
       "          '0.8711217462667107': 1,\n",
       "          '0.9974577899281755': 1,\n",
       "          '0.00242644724446035': 1,\n",
       "          '0.9881286115513161': 1,\n",
       "          '0.9848034040811314': 1,\n",
       "          '0.9875696415545341': 1,\n",
       "          '0.0017706316876155617': 1,\n",
       "          '0.10445997320513879': 1,\n",
       "          '0.9939428042116454': 1,\n",
       "          '0.9957955743306981': 1,\n",
       "          '0.9906045966062923': 1,\n",
       "          '0.08109854057742132': 1,\n",
       "          '0.005484888693032016': 1,\n",
       "          '0.05754535015267073': 1,\n",
       "          '0.9858249383231033': 1,\n",
       "          '0.9967621440054037': 1,\n",
       "          '0.9961582244752116': 1,\n",
       "          '0.009184729357314765': 1,\n",
       "          '0.9929029447846862': 1,\n",
       "          '0.03632881967115884': 1,\n",
       "          '0.9684360158409965': 1,\n",
       "          '0.008864039660207929': 1,\n",
       "          '0.12429838467488724': 1,\n",
       "          '0.9895963791292115': 1,\n",
       "          '0.9857626619473666': 1,\n",
       "          '0.9840653774892022': 1,\n",
       "          '0.9955730312872764': 1,\n",
       "          '0.000980925812952138': 1,\n",
       "          '0.928806350681509': 1,\n",
       "          '0.0020027287625575814': 1,\n",
       "          '0.9899697009667283': 1,\n",
       "          '0.9952279384916748': 1,\n",
       "          '0.9507464409209138': 1,\n",
       "          '0.001490736972517134': 1,\n",
       "          '0.9915090769254584': 1,\n",
       "          '0.9917894304860971': 1,\n",
       "          '0.9883523930185617': 1,\n",
       "          '0.0012518193521457645': 1,\n",
       "          '0.9928673526981159': 1,\n",
       "          '0.01836342949909234': 1,\n",
       "          '0.02637475045677792': 1,\n",
       "          '0.9923254662208939': 1,\n",
       "          '0.02108246108512023': 1,\n",
       "          '0.9930605533165848': 1,\n",
       "          '0.9237198585979166': 1,\n",
       "          '0.998746556982359': 1,\n",
       "          '0.01971251944962596': 1,\n",
       "          '0.9216250755830089': 1,\n",
       "          '0.06003245999206148': 1,\n",
       "          '0.9729869173711724': 1,\n",
       "          '0.00439949202143126': 1,\n",
       "          '0.004289131344031108': 1,\n",
       "          '0.09125772238308874': 1,\n",
       "          '0.10779212825987614': 1,\n",
       "          '0.9828108851007681': 1,\n",
       "          '0.03835320056807487': 1,\n",
       "          '0.18517932656823616': 1,\n",
       "          '0.9928828638801025': 1,\n",
       "          '0.9934035520205089': 1,\n",
       "          '0.007958912478017834': 1,\n",
       "          '0.9767719388730474': 1,\n",
       "          '0.004733474883536263': 1,\n",
       "          '0.17012775737976568': 1,\n",
       "          '0.9989987672171561': 1,\n",
       "          '0.9948574100252903': 1,\n",
       "          '0.9923157326514895': 1,\n",
       "          '0.9941829404632652': 1,\n",
       "          '0.5578781717719112': 1,\n",
       "          '0.9902665930363116': 1,\n",
       "          '0.0009127362114117728': 1,\n",
       "          '0.8776690648647718': 1,\n",
       "          '0.06872947881865668': 1,\n",
       "          '0.9884429530545706': 1,\n",
       "          '0.1777534884248222': 1,\n",
       "          '0.9885996579747355': 1,\n",
       "          '0.001611221177240772': 1,\n",
       "          '0.01591578620795798': 1,\n",
       "          '0.0013440137555807564': 1,\n",
       "          '0.031366625357422705': 1,\n",
       "          '0.6813509289994103': 1,\n",
       "          '0.00703836239892392': 1,\n",
       "          '0.9949730512829956': 1,\n",
       "          '0.9946095139612009': 1,\n",
       "          '0.00014881094433633277': 1,\n",
       "          '0.9953828991341483': 1,\n",
       "          '0.27665217515377183': 1,\n",
       "          '0.9920361551206835': 1,\n",
       "          '0.5913500087284848': 1,\n",
       "          '0.9905900969825318': 1,\n",
       "          '0.9893855820832402': 1,\n",
       "          '0.9955422909647699': 1,\n",
       "          '0.9903707885608345': 1,\n",
       "          '0.996024466766947': 1,\n",
       "          '0.9891300121526984': 1,\n",
       "          '0.9910055801133625': 1,\n",
       "          '0.6385660243724881': 1,\n",
       "          '0.026813353491053765': 1,\n",
       "          '0.0009901758361263975': 1,\n",
       "          '0.014901367406999159': 1,\n",
       "          '0.9931569098315686': 1,\n",
       "          '0.9934655840722658': 1,\n",
       "          '0.9925595531287175': 1,\n",
       "          '0.029530191558852347': 1,\n",
       "          '0.9929041702195406': 1,\n",
       "          '0.994683236170999': 1,\n",
       "          '0.9919544466621297': 1,\n",
       "          '0.9935904261839165': 1,\n",
       "          '0.9874348118370141': 1,\n",
       "          '0.9239969152032997': 1,\n",
       "          '0.00457895045742289': 1,\n",
       "          '0.9044630563480885': 1,\n",
       "          '0.9932819174291808': 1,\n",
       "          '0.8984222989678424': 1,\n",
       "          '0.1332501080306795': 1,\n",
       "          '0.988595028404951': 1,\n",
       "          '0.9917948244251001': 1,\n",
       "          '0.032256915006134444': 1,\n",
       "          '0.019752514245676027': 1,\n",
       "          '0.9909790886584372': 1,\n",
       "          '0.9843745485289128': 1,\n",
       "          '0.008977429105429433': 1,\n",
       "          '0.006709188263903038': 1,\n",
       "          '0.2803244526548167': 1,\n",
       "          '0.9913646748133735': 1,\n",
       "          '0.8836208131654572': 1,\n",
       "          '0.9963229438571636': 1,\n",
       "          '0.009616952341183229': 1,\n",
       "          '0.9900107941260476': 1,\n",
       "          '0.9813281068223585': 1,\n",
       "          '0.0018578204766063985': 1,\n",
       "          '0.9977491837758188': 1,\n",
       "          '0.9975347153032402': 1,\n",
       "          '0.9964782107259567': 1,\n",
       "          '0.9078419011801349': 1,\n",
       "          '0.9922819934865894': 1,\n",
       "          '0.977885416116291': 1,\n",
       "          '0.9976856461926417': 1,\n",
       "          '0.9850336057802722': 1,\n",
       "          '0.0023214389449481877': 1,\n",
       "          '0.6016293498016712': 1,\n",
       "          '0.9949448035807712': 1,\n",
       "          '0.0609015838874155': 1,\n",
       "          '0.060854578836287816': 1,\n",
       "          '0.989650523444207': 1,\n",
       "          '0.9918638851873266': 1,\n",
       "          '0.8332404131181765': 1,\n",
       "          '0.011697862943344515': 1,\n",
       "          '0.9981223306888417': 1,\n",
       "          '0.9944562223699643': 1,\n",
       "          '0.993488180999538': 1,\n",
       "          '0.4103273270123103': 1,\n",
       "          '0.010909278235899284': 1,\n",
       "          '0.7056085553703347': 1,\n",
       "          '0.8193192997289904': 1,\n",
       "          '0.9959314744073928': 1,\n",
       "          '0.9811596587927526': 1,\n",
       "          '0.9949023656094307': 1,\n",
       "          '0.0034315415891252544': 1,\n",
       "          '0.9902733281517617': 1,\n",
       "          '0.6480585561760946': 1,\n",
       "          '0.9892958557366367': 1,\n",
       "          '0.17952632813442482': 1,\n",
       "          '0.995229732777974': 1,\n",
       "          '0.9890926122595571': 1,\n",
       "          '0.9552208646028': 1,\n",
       "          '0.7277451097298928': 1,\n",
       "          '0.020524397058912482': 1,\n",
       "          '0.9429820418804589': 1,\n",
       "          '0.011584701944127666': 1,\n",
       "          '0.04935496945571116': 1,\n",
       "          '0.00038416949099779154': 1,\n",
       "          '0.00463322609466786': 1,\n",
       "          '0.9990235806712122': 1,\n",
       "          '0.9941383959121041': 1,\n",
       "          '0.989281355961575': 1,\n",
       "          '0.9245504176875765': 1,\n",
       "          '0.9881295365288473': 1,\n",
       "          '0.9000908434439061': 1,\n",
       "          '0.9774667023464215': 1,\n",
       "          '0.0034790152910445537': 1,\n",
       "          '0.9347947621273318': 1,\n",
       "          '0.9818294812817036': 1,\n",
       "          '0.9919844309996797': 1,\n",
       "          '0.003646039159208896': 1,\n",
       "          '0.0152175811034997': 1,\n",
       "          '0.2116837816776698': 1,\n",
       "          '0.9906940822860415': 1,\n",
       "          '0.9850581458776658': 1,\n",
       "          '0.8612212521904707': 1,\n",
       "          '0.9615775667045671': 1,\n",
       "          '0.9526666696669086': 1,\n",
       "          '0.9814981435744045': 1,\n",
       "          '0.0017056946163674965': 1,\n",
       "          '0.986118561221763': 1,\n",
       "          '0.9880664679410627': 1,\n",
       "          '0.021249163313404967': 1,\n",
       "          '0.00668082549311832': 1,\n",
       "          '0.45527027432082834': 1,\n",
       "          '0.9412756708227107': 1,\n",
       "          '0.9968083876281958': 1,\n",
       "          '0.00015884985006436801': 1,\n",
       "          '0.9921113604921901': 1,\n",
       "          '0.99135337933561': 1,\n",
       "          '0.0004604743845295233': 1,\n",
       "          '0.026573776426525746': 1,\n",
       "          '0.9939496105871884': 1,\n",
       "          '0.9957055146282507': 1,\n",
       "          '0.0006951248064795047': 1,\n",
       "          '0.7050348680399416': 1,\n",
       "          '0.718510940314754': 1,\n",
       "          '0.9954792161226572': 1,\n",
       "          '0.4319006957996668': 1,\n",
       "          '0.9913251114409747': 1,\n",
       "          '0.9895997130543941': 1,\n",
       "          '0.9827700274455442': 1,\n",
       "          '0.9933999019384255': 1,\n",
       "          '0.9880164530898918': 1,\n",
       "          '0.00505747768230139': 1,\n",
       "          '0.13916126995323938': 1,\n",
       "          '0.0052815322497736265': 1,\n",
       "          '0.9889585415024648': 1,\n",
       "          '0.9914665694148292': 1,\n",
       "          '0.9962543016603607': 1,\n",
       "          '0.9514332777716993': 1,\n",
       "          '0.004284438931762958': 1,\n",
       "          '0.9909246289555751': 1,\n",
       "          '0.9922531582563573': 1,\n",
       "          '0.952787751443105': 1,\n",
       "          '0.9891617002644146': 1,\n",
       "          '0.998379890283861': 1,\n",
       "          '0.03372433177698535': 1,\n",
       "          '0.018301717649811377': 1,\n",
       "          '0.9889563756644892': 1,\n",
       "          '0.9941214005546438': 1,\n",
       "          '0.9936634010428732': 1,\n",
       "          '0.12043767299279949': 1,\n",
       "          '0.9971315576923346': 1,\n",
       "          '0.05885361862596915': 1,\n",
       "          '0.9661047509230775': 1,\n",
       "          '0.9038813061084416': 1,\n",
       "          '0.9897990399528556': 1,\n",
       "          '0.9944899450532121': 1,\n",
       "          '0.04495040799499465': 1,\n",
       "          '0.9902771894956913': 1,\n",
       "          '0.9943261145240025': 1,\n",
       "          '0.9568319379994213': 1,\n",
       "          '0.0003519430018624784': 1,\n",
       "          '0.9837613316935124': 1,\n",
       "          '0.004554870002920717': 1,\n",
       "          '0.9876195455980126': 1,\n",
       "          '0.9878375676545617': 1,\n",
       "          '0.9946724997768847': 1,\n",
       "          '0.9917452020271766': 1,\n",
       "          '0.041657613649420194': 1,\n",
       "          '0.9940531239134366': 1,\n",
       "          '0.9939148220003498': 1,\n",
       "          '8.527819732185005e-05': 1,\n",
       "          '0.9927361541395927': 1,\n",
       "          '0.9608404922937963': 1,\n",
       "          '0.897201230060685': 1,\n",
       "          '0.12776099563175444': 1,\n",
       "          '0.9930098015155912': 1,\n",
       "          '0.9491594758933278': 1,\n",
       "          '0.7500618875860156': 1,\n",
       "          '0.995376733277525': 1,\n",
       "          '0.9843029685467265': 1,\n",
       "          '0.9912238028188741': 1,\n",
       "          '0.0010989750817409214': 1,\n",
       "          '0.14946511489657763': 1,\n",
       "          '0.9946033762053559': 1,\n",
       "          '0.9604178549805464': 1,\n",
       "          '0.9942022590398965': 1,\n",
       "          '0.9895400343661472': 1,\n",
       "          '0.9366242569807289': 1,\n",
       "          '0.9883622397234785': 1,\n",
       "          '0.9859513366561133': 1,\n",
       "          '0.9883476655313116': 1,\n",
       "          '0.9896509094902003': 1,\n",
       "          '0.9985903881322175': 1,\n",
       "          '0.9670325271077698': 1,\n",
       "          '0.030158723053105053': 1,\n",
       "          '0.026052661615037217': 1,\n",
       "          '0.9784901199646155': 1,\n",
       "          '0.001659016036357155': 1,\n",
       "          '0.991060653506983': 1,\n",
       "          '0.00047751455721902787': 1,\n",
       "          '0.9938449574563126': 1,\n",
       "          '0.013296064316249375': 1,\n",
       "          '0.9919564318441686': 1,\n",
       "          '0.9524910051013276': 1,\n",
       "          '0.9962836330917576': 1,\n",
       "          '0.9936600117607476': 1,\n",
       "          '0.08760390995878622': 1,\n",
       "          '0.00025953105925409725': 1,\n",
       "          '0.9917408042652308': 1,\n",
       "          '0.9987482761023342': 1,\n",
       "          '0.0008998942134789458': 1,\n",
       "          '0.9920925466143882': 1,\n",
       "          '0.005534981893806781': 1,\n",
       "          '0.0023892877907959738': 1,\n",
       "          '0.9200640775015645': 1,\n",
       "          '0.9929352275076635': 1,\n",
       "          '0.07368271772138897': 1,\n",
       "          '0.008598553344812711': 1,\n",
       "          '0.9852770775668325': 1,\n",
       "          '0.8258427192225402': 1,\n",
       "          '0.9954716852375127': 1,\n",
       "          '0.03360070208173529': 1,\n",
       "          '0.9884134094828128': 1,\n",
       "          '0.9861990146569619': 1,\n",
       "          '0.011972819839278583': 1,\n",
       "          '0.9923264958808532': 1,\n",
       "          '0.7402404363629254': 1,\n",
       "          '0.9744347556223082': 1,\n",
       "          '0.995667519827047': 1,\n",
       "          '0.9943071409107772': 1,\n",
       "          '0.06309716140791329': 1,\n",
       "          '0.0022064909079274704': 1,\n",
       "          '0.9918864290174944': 1,\n",
       "          '0.9881351495915605': 1,\n",
       "          '0.9932125669141766': 1,\n",
       "          '0.01917517341601979': 1,\n",
       "          '0.010720431019724898': 1,\n",
       "          '0.9937923701720679': 1,\n",
       "          '0.9948133763844984': 1,\n",
       "          '0.9904763721551608': 1,\n",
       "          '0.9586827449896181': 1,\n",
       "          '0.9729039585400779': 1,\n",
       "          '0.9928647484288111': 1,\n",
       "          '0.5328813434749959': 1,\n",
       "          '0.9652890323535531': 1,\n",
       "          '0.9939771871832982': 1,\n",
       "          '0.12720086785411358': 1,\n",
       "          '0.9930077366600867': 1,\n",
       "          '0.992994594786408': 1,\n",
       "          '0.9259576522620395': 1,\n",
       "          '0.996073239384865': 1,\n",
       "          '0.9874394023370565': 1,\n",
       "          '0.9945711940959895': 1,\n",
       "          '0.03500811646689115': 1,\n",
       "          '0.9732730663821382': 1,\n",
       "          '0.027713160901255193': 1,\n",
       "          '0.016012170575618413': 1,\n",
       "          '0.9919736737608924': 1,\n",
       "          '0.9538463625423784': 1,\n",
       "          '0.8546292097001824': 1,\n",
       "          '0.9506196922246565': 1,\n",
       "          '0.0665490752038202': 1,\n",
       "          '0.9987041451319096': 1,\n",
       "          '0.9967959088121549': 1,\n",
       "          '0.9960835993200358': 1,\n",
       "          '0.9477150609973606': 1,\n",
       "          '0.9948858249333422': 1,\n",
       "          '0.9916566204223498': 1,\n",
       "          '0.9926801922539835': 1,\n",
       "          '0.989979013349311': 1,\n",
       "          '0.013146929606022094': 1,\n",
       "          '0.9917651607508575': 1,\n",
       "          '0.998342839182202': 1,\n",
       "          '0.9949787463182271': 1,\n",
       "          '0.0003699029579444577': 1,\n",
       "          '0.024109381917096436': 1,\n",
       "          '0.003006408009310389': 1,\n",
       "          '0.011374801973797467': 1,\n",
       "          '3.434949915719994e-05': 1,\n",
       "          '0.018837993275703527': 1,\n",
       "          '0.992593236614841': 1,\n",
       "          '0.9951264993252558': 1,\n",
       "          '0.013207217388348385': 1,\n",
       "          '0.9810536239718403': 1,\n",
       "          '0.9915949883474948': 1,\n",
       "          '0.027383760757388645': 1,\n",
       "          '0.005517160347238242': 1,\n",
       "          '0.9975681849219599': 1,\n",
       "          '0.9853763187037383': 1,\n",
       "          '0.9928534223478807': 1,\n",
       "          '0.00010959117111264494': 1,\n",
       "          '0.9926511835494449': 1,\n",
       "          '0.9962170813758184': 1,\n",
       "          '0.9464533243214667': 1,\n",
       "          '0.014467286254934531': 1,\n",
       "          '0.9934424066384508': 1,\n",
       "          '0.008046576941534208': 1,\n",
       "          '0.030651983183005972': 1,\n",
       "          '0.987239137699725': 1,\n",
       "          '0.9952202788643871': 1,\n",
       "          '0.9958059342983985': 1,\n",
       "          '0.9935404644429299': 1,\n",
       "          '0.9894777619221787': 1,\n",
       "          '0.9925260519514627': 1,\n",
       "          '0.990700136140771': 1,\n",
       "          '0.9811698514241204': 1,\n",
       "          '0.9912067037358995': 1,\n",
       "          '0.9792195052728977': 1,\n",
       "          '0.9951805687669278': 1,\n",
       "          '0.00923515591556912': 1,\n",
       "          '0.0021516746143244937': 1,\n",
       "          '0.994605786550235': 1,\n",
       "          '0.9962531196034136': 1,\n",
       "          '0.9330278253474207': 1,\n",
       "          '0.9886744479656997': 1,\n",
       "          '0.9942120647448257': 1,\n",
       "          '0.01932100376824257': 1,\n",
       "          '0.9925203064308891': 1,\n",
       "          '0.9908970435523223': 1,\n",
       "          '0.053547210048945575': 1,\n",
       "          '0.8742350242894661': 1,\n",
       "          '0.9899407509771416': 1,\n",
       "          '0.207858219506709': 1,\n",
       "          '0.9924496915793304': 1,\n",
       "          '0.8369022467225645': 1,\n",
       "          '0.9827868896692455': 1,\n",
       "          '0.9899371215536688': 1,\n",
       "          '0.9856518719650899': 1,\n",
       "          '0.004246927530118411': 1,\n",
       "          '0.9960167006134276': 1,\n",
       "          '0.00038688659634875604': 1,\n",
       "          '0.023449057018472438': 1,\n",
       "          '0.7865883079150963': 1,\n",
       "          '0.9911241407324498': 1,\n",
       "          '0.9917529075138563': 1,\n",
       "          '0.06721891159577965': 1,\n",
       "          '0.993786895287371': 1,\n",
       "          '0.975733331507396': 1,\n",
       "          '0.9922832996737063': 1,\n",
       "          '0.528676218902285': 1,\n",
       "          '0.9941996226656801': 1,\n",
       "          '0.9884617137952642': 1,\n",
       "          '0.005964193336274262': 1,\n",
       "          '0.08824839770677313': 1,\n",
       "          '0.9835573289622656': 1,\n",
       "          '0.7479598486181658': 1,\n",
       "          '0.9943354726025572': 1,\n",
       "          '0.0003544245951395': 1,\n",
       "          '0.9904989364427677': 1,\n",
       "          '0.9865077833818343': 1,\n",
       "          '0.9902179032343678': 1,\n",
       "          '0.9960651618209071': 1,\n",
       "          '0.9881266825104096': 1,\n",
       "          '0.9956078867821734': 1,\n",
       "          '0.9297253183042298': 1,\n",
       "          '0.10325061162119821': 1,\n",
       "          '0.6629248234384785': 1,\n",
       "          '0.9952097339112949': 1,\n",
       "          '0.00029777005716815003': 1,\n",
       "          '0.9956712221731912': 1,\n",
       "          '0.9907941127263121': 1,\n",
       "          '0.28913758498423286': 1,\n",
       "          '0.2056445228055834': 1,\n",
       "          '0.0010145640546845118': 1,\n",
       "          '0.6104256552259968': 1,\n",
       "          '0.04859157710276995': 1,\n",
       "          '0.9937248634827258': 1,\n",
       "          '0.9905178137131465': 1,\n",
       "          '0.9920723349757108': 1,\n",
       "          '0.9925551812430115': 1,\n",
       "          '0.9868796226111686': 1,\n",
       "          '0.9928354598643666': 1,\n",
       "          '0.9983064719177589': 1,\n",
       "          '0.6394867980104176': 1,\n",
       "          '0.9910617867701357': 1,\n",
       "          '0.9878752284505065': 1,\n",
       "          '0.00041693179985372974': 1,\n",
       "          '0.9928346779501207': 1,\n",
       "          '0.9882846930636405': 1,\n",
       "          '0.025631080373066824': 1,\n",
       "          '0.9976734579193529': 1,\n",
       "          '0.9965426125215457': 1,\n",
       "          '0.2859729645621438': 1,\n",
       "          '0.4690217470102227': 1,\n",
       "          '0.9912273535484599': 1,\n",
       "          '0.9883621952864404': 1,\n",
       "          '0.6109836589852999': 1,\n",
       "          '0.9958785095773436': 1,\n",
       "          '0.001243709293231219': 1,\n",
       "          '0.9957263613794024': 1,\n",
       "          '0.9934437838191514': 1,\n",
       "          '0.9683633074078867': 1,\n",
       "          '0.9899361437849518': 1,\n",
       "          '0.9925266746151905': 1,\n",
       "          '0.9924821321883633': 1,\n",
       "          '0.9931050843004641': 1,\n",
       "          '0.9521692996122176': 1,\n",
       "          '0.994277052486105': 1,\n",
       "          '0.9944757229291293': 1,\n",
       "          '0.003023454688704438': 1,\n",
       "          '0.9954711274295751': 1,\n",
       "          '0.9894883171550446': 1,\n",
       "          '0.9915419966291328': 1,\n",
       "          '0.9870861092508774': 1,\n",
       "          '0.96799372687192': 1,\n",
       "          '0.9862777886401296': 1,\n",
       "          '0.6632239436487058': 1,\n",
       "          '0.9889546060915242': 1,\n",
       "          '0.003994948000685833': 1,\n",
       "          '0.025382740491514254': 1,\n",
       "          '0.993865039936772': 1,\n",
       "          '0.9978911340963874': 1,\n",
       "          '0.9856149066487747': 1,\n",
       "          '0.997779760876354': 1,\n",
       "          '0.9951973586947074': 1,\n",
       "          '0.9919514727277922': 1,\n",
       "          '0.09933119619491297': 1,\n",
       "          '0.07984729200042794': 1,\n",
       "          '0.07865436628850983': 1,\n",
       "          '0.9922094132589733': 1,\n",
       "          '0.9942643487153185': 1,\n",
       "          '0.0461398613231674': 1,\n",
       "          '0.9903070939570785': 1,\n",
       "          '0.9812920934130984': 1,\n",
       "          '0.9935374503494367': 1,\n",
       "          '0.990618549213004': 1,\n",
       "          '0.9902016984248541': 1,\n",
       "          '0.9910798019083931': 1,\n",
       "          '0.8155553329716902': 1,\n",
       "          '0.9954351050170864': 1,\n",
       "          '0.9925213163593156': 1,\n",
       "          '0.9936866793468451': 1,\n",
       "          '0.0799434006899387': 1,\n",
       "          '0.9974657908563243': 1,\n",
       "          '0.9900735189402743': 1,\n",
       "          '0.9853947086244427': 1,\n",
       "          '0.7814071778725108': 1,\n",
       "          '0.4748899809724163': 1,\n",
       "          '0.2354037215089317': 1,\n",
       "          '0.9877240527039365': 1,\n",
       "          '0.9921755185726424': 1,\n",
       "          '0.6406688464689501': 1,\n",
       "          '0.007113219952403048': 1,\n",
       "          '0.047419878948556475': 1,\n",
       "          '0.8572712379577025': 1,\n",
       "          '0.003831944720152162': 1,\n",
       "          '0.990148669465917': 1,\n",
       "          '0.9926375110746979': 1,\n",
       "          '0.05927360619401688': 1,\n",
       "          '0.9917669843552549': 1,\n",
       "          '0.9933365486878084': 1,\n",
       "          '0.9918697300375455': 1,\n",
       "          '0.010956592039328703': 1,\n",
       "          '0.35614798240449996': 1,\n",
       "          '0.9887436394954601': 1,\n",
       "          '0.9952889206964338': 1,\n",
       "          '0.8032096726794257': 1,\n",
       "          '0.990173033980027': 1,\n",
       "          '0.9404287238916619': 1,\n",
       "          '0.9888444720137175': 1,\n",
       "          '0.9989034873488956': 1,\n",
       "          '0.9966945089046685': 1,\n",
       "          '0.9693497940462342': 1,\n",
       "          '0.0005422490842345988': 1,\n",
       "          '0.05897217785926762': 1,\n",
       "          '0.9919127707117785': 1,\n",
       "          '0.9830725028860239': 1,\n",
       "          '0.46577468795088056': 1,\n",
       "          '0.051555628495989846': 1,\n",
       "          '0.994913066272644': 1,\n",
       "          '0.9968310322360882': 1,\n",
       "          '0.9907746337880781': 1,\n",
       "          '0.04657084245613173': 1,\n",
       "          '0.9940225412432927': 1,\n",
       "          '0.9653448557757688': 1,\n",
       "          '0.4891066400840366': 1,\n",
       "          '0.9881285730482607': 1,\n",
       "          '0.014510563684257854': 1,\n",
       "          '0.915270833047337': 1,\n",
       "          '0.9906276867175242': 1,\n",
       "          '0.8161908035704247': 1,\n",
       "          '0.9624074436275358': 1,\n",
       "          '0.10589481090896206': 1,\n",
       "          '0.983970775467959': 1,\n",
       "          '0.009046600233097413': 1,\n",
       "          '0.8471075381113069': 1,\n",
       "          '0.336894281501495': 1,\n",
       "          '0.9905908572368496': 1,\n",
       "          '0.0797683083096409': 1,\n",
       "          '0.9986858537346615': 1,\n",
       "          '0.9942684623234839': 1,\n",
       "          '0.9976007073824268': 1,\n",
       "          '0.01009840782659447': 1,\n",
       "          '0.9543819932206477': 1,\n",
       "          '0.0032909631825243954': 1,\n",
       "          '0.0011565488205432122': 1,\n",
       "          '0.009290318192451071': 1,\n",
       "          '0.9942956703287221': 1,\n",
       "          '0.0025935939710160253': 1,\n",
       "          '0.9882116930632827': 1,\n",
       "          '0.005729856382968158': 1,\n",
       "          '0.15466116244579572': 1,\n",
       "          '0.00013790858510754134': 1,\n",
       "          '0.9924614747320831': 1,\n",
       "          '0.9940464914696304': 1,\n",
       "          '0.9933384778422495': 1,\n",
       "          '0.014951547100658906': 1,\n",
       "          '0.9884174800461643': 1,\n",
       "          '0.0049698790545956014': 1,\n",
       "          '0.9353083479762171': 1,\n",
       "          '0.9414540132543675': 1,\n",
       "          '0.0024805859571258074': 1,\n",
       "          '0.006904223713278141': 1,\n",
       "          '0.04522742089709665': 1,\n",
       "          '0.008166298353138136': 1,\n",
       "          '0.9885565901289672': 1,\n",
       "          '0.9926426857661751': 1,\n",
       "          '0.9912623965113105': 1,\n",
       "          '0.9876823755087382': 1,\n",
       "          '0.9922058579066865': 1,\n",
       "          '0.9882622296072406': 1,\n",
       "          '0.9903263504543043': 1,\n",
       "          '0.010791572883730866': 1,\n",
       "          '0.6309266758170345': 1,\n",
       "          '0.9983544721002934': 1,\n",
       "          '0.9869383837272534': 1,\n",
       "          '0.00589912281152505': 1,\n",
       "          '0.0010384241532746218': 1,\n",
       "          '0.008899536140994436': 1,\n",
       "          '0.9825009850763687': 1,\n",
       "          '0.004161082387787873': 1,\n",
       "          '0.9858890997497405': 1,\n",
       "          '0.9928515671812448': 1,\n",
       "          '0.9926996836737959': 1,\n",
       "          '0.0015072553008650294': 1,\n",
       "          '0.022122482607145298': 1,\n",
       "          '0.06498283724713771': 1,\n",
       "          '0.02323852824090349': 1,\n",
       "          '0.9961029708835442': 1,\n",
       "          '0.9615304169722908': 1,\n",
       "          '0.03252527429976361': 1,\n",
       "          '0.9866909322787448': 1,\n",
       "          '0.9954541808733869': 1,\n",
       "          '0.1520238360615707': 1,\n",
       "          '0.9075858131884852': 1,\n",
       "          '0.9860989821673425': 1,\n",
       "          '0.9591863482379844': 1,\n",
       "          '0.9927385614272097': 1,\n",
       "          '0.0019147402591042607': 1,\n",
       "          '0.9924477337389706': 1,\n",
       "          '0.07396652518103172': 1,\n",
       "          '0.9831637329899042': 1,\n",
       "          '0.017242239164352764': 1,\n",
       "          '0.9965591426050889': 1,\n",
       "          '0.9832912511638832': 1,\n",
       "          '0.30456730883704125': 1,\n",
       "          '0.9933586110804509': 1,\n",
       "          '0.0013957496314959737': 1,\n",
       "          '0.9966442920291141': 1,\n",
       "          '0.9992395858062993': 1,\n",
       "          '0.19320857597366087': 1,\n",
       "          '0.08853329910768847': 1,\n",
       "          '0.9848527470241101': 1,\n",
       "          '0.9844402937846708': 1,\n",
       "          '0.9861232853639683': 1,\n",
       "          '0.7884551577616683': 1,\n",
       "          '0.6665745382174559': 1,\n",
       "          '0.9869521792613855': 1,\n",
       "          '0.008854803717800615': 1,\n",
       "          '0.9959563556796468': 1,\n",
       "          '0.0008120234054183189': 1,\n",
       "          '0.0048397515303949135': 1,\n",
       "          '0.0003172190664658328': 1,\n",
       "          '0.01818002421239027': 1,\n",
       "          '0.0005858448083263749': 1,\n",
       "          '0.9981255796661094': 1,\n",
       "          '0.9885746169065903': 1,\n",
       "          '0.12897963808333338': 1,\n",
       "          '0.3936749667893118': 1,\n",
       "          '0.9927056652263482': 1,\n",
       "          '0.05414292687822716': 1,\n",
       "          '0.9897802272148032': 1,\n",
       "          '0.9569615842957329': 1,\n",
       "          '0.02327789955848836': 1,\n",
       "          '0.9906212723789904': 1,\n",
       "          '0.9957292613328043': 1,\n",
       "          '0.9934387466664842': 1,\n",
       "          '0.9788706118913691': 1,\n",
       "          '0.9937587502933369': 1,\n",
       "          '0.9956582904396268': 1,\n",
       "          '0.9926445484566662': 1,\n",
       "          '0.985637278083335': 1,\n",
       "          '0.9862940719537225': 1,\n",
       "          '0.8682193045597251': 1,\n",
       "          '0.9783440047132853': 1,\n",
       "          '0.9815942827953056': 1,\n",
       "          '0.9932872951357901': 1,\n",
       "          '0.9965367960782342': 1,\n",
       "          '0.022817997713773106': 1,\n",
       "          '0.20714185994589113': 1,\n",
       "          '0.016905005289456224': 1,\n",
       "          '0.9916649568749049': 1,\n",
       "          '0.9925996570262464': 1,\n",
       "          '0.996529693241771': 1,\n",
       "          '0.0013307004051808433': 1,\n",
       "          '0.9432219091184584': 1,\n",
       "          '0.8503720881707576': 1,\n",
       "          '0.9552863216945033': 1,\n",
       "          '0.19351845881617194': 1,\n",
       "          '0.9895494718743569': 1,\n",
       "          '0.9968826798166387': 1,\n",
       "          '0.03591214101426751': 1,\n",
       "          '0.9899715177592744': 1,\n",
       "          '0.9936900945675579': 1,\n",
       "          '0.9951366857871015': 1,\n",
       "          '0.995557746156709': 1,\n",
       "          '0.06200795122969675': 1,\n",
       "          '0.21320517909984804': 1,\n",
       "          '0.0045565807245929995': 1,\n",
       "          '0.9926688392902306': 1,\n",
       "          '0.9941256014222387': 1,\n",
       "          '0.982326295834037': 1,\n",
       "          '0.9989410173699564': 1,\n",
       "          '0.9907601167174601': 1,\n",
       "          '0.03700707532951505': 1,\n",
       "          '0.0014137564296677972': 1,\n",
       "          '0.9902925938391131': 1,\n",
       "          '0.9902245183388501': 1,\n",
       "          '0.9959109146014746': 1,\n",
       "          '0.9923547454628556': 1,\n",
       "          '0.9235268645903288': 1,\n",
       "          '0.9456664972997586': 1,\n",
       "          '0.010234421957561515': 1,\n",
       "          '0.9629801324475854': 1,\n",
       "          '0.996565854313112': 1,\n",
       "          '0.0005252123121151608': 1,\n",
       "          '0.9848010075499883': 1,\n",
       "          '0.9743464544108719': 1,\n",
       "          '0.9353313139836194': 1,\n",
       "          '0.9930115547782948': 1,\n",
       "          '0.99040358986527': 1,\n",
       "          '0.9887819226260423': 1,\n",
       "          '0.0007083036211688727': 1,\n",
       "          '0.9931873564804526': 1,\n",
       "          '0.006052849632702371': 1,\n",
       "          '0.990215702924477': 1,\n",
       "          '0.965655986048947': 1,\n",
       "          '0.018940006065186227': 1,\n",
       "          '0.9550194539350996': 1,\n",
       "          '0.0015258212237676068': 1,\n",
       "          '0.9938956838663717': 1,\n",
       "          '0.00017404105481340658': 1,\n",
       "          '0.9917421680798343': 1,\n",
       "          '0.9711343964193793': 1,\n",
       "          '0.9954866506395746': 1,\n",
       "          '0.9923062640735849': 1,\n",
       "          '0.030840623691407047': 1,\n",
       "          '0.4988284487823441': 1,\n",
       "          '0.022428801152542102': 1,\n",
       "          '0.574219855226926': 1,\n",
       "          '0.9879463592031836': 1,\n",
       "          '0.41531807897185286': 1,\n",
       "          '0.9796532172992363': 1,\n",
       "          '0.9847971796267423': 1,\n",
       "          '0.9925766445994195': 1,\n",
       "          '0.004294280013409405': 1,\n",
       "          '0.404031601591043': 1,\n",
       "          '0.000371038603592276': 1,\n",
       "          '0.000580876793193119': 1,\n",
       "          '0.033609378848241': 1,\n",
       "          '0.0010860878268038924': 1,\n",
       "          '0.013539449003119555': 1,\n",
       "          '0.9945849256514409': 1,\n",
       "          '0.9959679536167894': 1,\n",
       "          '0.0017888673152484024': 1,\n",
       "          '0.9940930723080706': 1,\n",
       "          '0.7619845427250381': 1,\n",
       "          '0.9942096618699615': 1,\n",
       "          '0.002099154824488744': 1,\n",
       "          '0.9911766998994704': 1,\n",
       "          '0.9881847873046161': 1,\n",
       "          '0.965886266377852': 1,\n",
       "          '0.9893775568645383': 1,\n",
       "          '0.05751612051073666': 1,\n",
       "          '0.9921743754377624': 1,\n",
       "          '0.0033827320115274177': 1,\n",
       "          '0.0020268482873006016': 1,\n",
       "          '0.9953904031924166': 1,\n",
       "          '0.6288910100059829': 1,\n",
       "          '0.0015256180773170682': 1,\n",
       "          '0.9928014932459417': 1,\n",
       "          '0.012548787897374826': 1,\n",
       "          '0.9430069813936813': 1,\n",
       "          ...}))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_dataset.labels[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.labels[:, 0] = np.array([1 - float(x) for x in submit.labels[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NR', '1'],\n",
       "       ['NR', '6'],\n",
       "       ['NR', '20'],\n",
       "       ['NR', '1'],\n",
       "       ['NR', '1'],\n",
       "       ['NR', '6'],\n",
       "       ['NR', '1'],\n",
       "       ['NR', '20'],\n",
       "       ['NR', '6'],\n",
       "       ['NR', '1']], dtype='<U21')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.3378901908102402', '6'],\n",
       "       ['0.9999999919483673', '30'],\n",
       "       ['0.9999065738685704', '30'],\n",
       "       ['0.9999999999791894', '30'],\n",
       "       ['0.3759892870655247', '6'],\n",
       "       ['0.004666365980876663', '20'],\n",
       "       ['0.9999976413778514', '30'],\n",
       "       ['0.030180854349445396', '20'],\n",
       "       ['0.7870471909789434', '3'],\n",
       "       ['0.0993337189800595', '1']], dtype='<U32')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.0029086430412417047', '10'],\n",
       "       ['0.1642472372709603', '3'],\n",
       "       ['0.00677612485397937', '3'],\n",
       "       ['0.9914814839997017', '1'],\n",
       "       ['0.06762213011820803', '3'],\n",
       "       ['0.988736987488687', '20'],\n",
       "       ['0.9403409436639254', '6'],\n",
       "       ['0.002110631328905138', '3'],\n",
       "       ['0.9883986403366508', '1'],\n",
       "       ['0.00372251092176057', '10']], dtype='<U32')"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.labels[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset2submit_csv(submit,\n",
    "    \"../submits/1:log_reg2:log_reg_on_tsne_label_over_proj64_plus_trainset_logreg_for_1_6_normalized_crop_64_seed_0_mobilenet_v3_small_embds_refit_false_cv_10_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16564,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16564, 1000)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1502,), (1502, 1000))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_test_predictions.tags.shape, pub_test_predictions.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15062,), (15062, 1000))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_predictions.tags.shape, private_test_predictions.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): ConvBNActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = applier.mobilenet_v3_small\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mobilenet_state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model2 = mobilenet_v3_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(\"mobilenet_state_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002803215266387 0.2887019402063319\n",
      "0.46069193 1.7000295\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "t = np.random.random((1,3,500,500))\n",
    "model2.train(False)\n",
    "print(np.mean(t), np.std(t))\n",
    "with torch.no_grad():\n",
    "    res = model2(torch.Tensor(t)).detach().numpy()\n",
    "print(np.mean(res), np.std(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002803215266387 0.2887019402063319\n",
      "0.46069193 1.7000295\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "t = np.random.random((1,3,500,500))\n",
    "model.train(False)\n",
    "print(np.mean(t), np.std(t))\n",
    "with torch.no_grad():\n",
    "    res = model(torch.Tensor(t)).detach().numpy()\n",
    "print(np.mean(res), np.std(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): ConvBNActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002803215266387 0.2887019402063319\n",
      "3.4595482 0.81053764\n",
      "OK, run 25.1478328704834s\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "mobilenet = torchvision.models.mobilenet_v3_small()\n",
    "mobilenet.load_state_dict(torch.load(\"mobilenet_state_dict\"))\n",
    "\n",
    "np.random.seed(0)\n",
    "t = np.random.random((1,3,500,500))\n",
    "model2.train(False)\n",
    "print(np.mean(t), np.std(t))\n",
    "with torch.no_grad():\n",
    "    res = mobilenet(torch.Tensor(t)).detach().numpy()\n",
    "print(np.mean(res), np.std(res))\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for i in np.arange(10):\n",
    "    t = np.random.random((32,3,500,500))\n",
    "    with torch.no_grad():\n",
    "        res = mobilenet(torch.Tensor(t)).detach().numpy()\n",
    "    \n",
    "print('OK, run {}s'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from submition_track2.test_in_submit.mobilenet_v3 import mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = mobilenet_v3_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
